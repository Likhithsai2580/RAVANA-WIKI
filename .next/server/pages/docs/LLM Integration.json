{"pageProps":{"doc":{"slug":"LLM Integration","title":"LLM Integration","content":"<h1>LLM Integration</h1>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#project-structure\">Project Structure</a></li>\n<li><a href=\"#core-components\">Core Components</a></li>\n<li><a href=\"#architecture-overview\">Architecture Overview</a></li>\n<li><a href=\"#detailed-component-analysis\">Detailed Component Analysis</a></li>\n<li><a href=\"#prompt-engineering-strategies\">Prompt Engineering Strategies</a></li>\n<li><a href=\"#provider-configuration-and-authentication\">Provider Configuration and Authentication</a></li>\n<li><a href=\"#fallback-mechanisms-and-error-handling\">Fallback Mechanisms and Error Handling</a></li>\n<li><a href=\"#performance-and-cost-management\">Performance and Cost Management</a></li>\n<li><a href=\"#security-considerations\">Security Considerations</a></li>\n</ol>\n<h2>Introduction</h2>\n<p>This document provides a comprehensive overview of the LLM integration system within the RAVANA repository. It details the architecture, supported providers, configuration mechanisms, and advanced features such as prompt engineering, fallback strategies, and security considerations. The system is designed to support multiple LLM providers with robust error handling, rate limiting, and performance optimization.</p>\n<h2>Project Structure</h2>\n<p>The project is organized into several key directories:</p>\n<ul>\n<li><strong>core</strong>: Contains core functionality including LLM integration, configuration, and state management</li>\n<li><strong>modules</strong>: Houses specialized modules for decision-making, self-reflection, and experimentation</li>\n<li><strong>prompts</strong>: Stores JSON templates for various use cases</li>\n<li><strong>services</strong>: Provides data, knowledge, and memory services</li>\n<li><strong>database</strong>: Manages database operations and models</li>\n</ul>\n<p>The LLM integration is primarily centered in the <code>core</code> directory, with supporting components in <code>modules</code> and configuration in <code>prompts</code>.</p>\n<pre><code class=\"language-mermaid\">graph TD\nA[LLM Integration System] --> B[core/llm.py]\nA --> C[core/config.json]\nA --> D[prompts/]\nA --> E[core/prompt_manager.py]\nB --> F[Provider Interfaces]\nB --> G[Fallback Mechanisms]\nB --> H[Error Handling]\nC --> I[API Keys]\nC --> J[Rate Limiting]\nD --> K[Decision Making]\nD --> L[Experimentation]\nD --> M[Self-Reflection]\n</code></pre>\n<p><strong>Diagram sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n<li><a>config.json</a></li>\n<li><a>prompts/decision_making.json</a></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n<li><a>config.json</a></li>\n</ul>\n<h2>Core Components</h2>\n<p>The core components of the LLM integration system include:</p>\n<ul>\n<li><strong>LLM Interface</strong>: Unified interface for calling different LLM providers</li>\n<li><strong>Provider Adapters</strong>: Specific implementations for Zuki, ElectronHub, Zanity, A4F, and Gemini</li>\n<li><strong>Prompt Manager</strong>: Handles prompt validation, enhancement, and template management</li>\n<li><strong>Key Manager</strong>: Manages multiple API keys with rotation and rate limiting</li>\n<li><strong>Error Handler</strong>: Comprehensive error handling with retry logic and fallback mechanisms</li>\n</ul>\n<p>The system is designed with extensibility in mind, allowing for easy addition of new providers and prompt templates.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n<li><a>prompt_manager.py</a></li>\n</ul>\n<h2>Architecture Overview</h2>\n<p>The LLM integration system follows a modular architecture with clear separation of concerns. The core component is the <code>call_llm</code> function, which serves as the unified interface for all LLM interactions. This function routes requests to the appropriate provider based on availability and configuration.</p>\n<pre><code class=\"language-mermaid\">graph TD\nA[Application] --> B[call_llm]\nB --> C{Preferred Provider?}\nC --> |Yes| D[Specific Provider]\nC --> |No| E[Provider Chain]\nD --> F[API Request]\nE --> F\nF --> G[Response]\nG --> H[Error Handling]\nH --> I[Retry Logic]\nI --> J[Fallback to Gemini]\nJ --> K[Final Response]\nK --> A\n</code></pre>\n<p><strong>Diagram sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<h2>Detailed Component Analysis</h2>\n<h3>LLM Interface and Request Handling</h3>\n<p>The LLM interface provides a unified method for interacting with multiple providers through the <code>call_llm</code> function. This function accepts a prompt and optional model parameter, then attempts to process the request through a chain of providers.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\nparticipant App as Application\nparticipant LLM as call_llm\nparticipant Providers as Provider Chain\nparticipant Gemini as Gemini Fallback\nApp->>LLM : call_llm(prompt, model)\nLLM->>Providers : Try Zuki, ElectronHub, Zanity, A4F\nalt Provider Success\nProviders-->>LLM : Response\nLLM-->>App : Return Response\nelse All Providers Fail\nLLM->>Gemini : call_gemini_with_fallback\nGemini-->>LLM : Response or Error\nLLM-->>App : Return Response\nend\n</code></pre>\n<p><strong>Diagram sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<h3>Provider Configuration and Authentication</h3>\n<p>The system supports multiple LLM providers with configuration managed through <code>config.json</code>. Each provider has its own API key, base URL, and available models.</p>\n<pre><code class=\"language-mermaid\">classDiagram\nclass LLMProvider {\n+str name\n+str api_key\n+str base_url\n+List[str] models\n+call(prompt, model)\n}\nclass ZukiProvider {\n+call_zuki(prompt, model)\n}\nclass ElectronHubProvider {\n+call_electronhub(prompt, model)\n}\nclass ZanityProvider {\n+call_zanity(prompt, model)\n}\nclass A4FProvider {\n+call_a4f(prompt)\n}\nclass GeminiProvider {\n+call_gemini(prompt)\n+call_gemini_with_fallback()\n}\nLLMProvider &#x3C;|-- ZukiProvider\nLLMProvider &#x3C;|-- ElectronHubProvider\nLLMProvider &#x3C;|-- ZanityProvider\nLLMProvider &#x3C;|-- A4FProvider\nLLMProvider &#x3C;|-- GeminiProvider\n</code></pre>\n<p><strong>Diagram sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n<li><a>config.json</a></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n<li><a>config.json</a></li>\n</ul>\n<h2>Prompt Engineering Strategies</h2>\n<p>The system employs structured prompt templates for different use cases, stored in the <code>prompts</code> directory. These templates follow a consistent format with role definition, context, task instructions, reasoning framework, output requirements, and safety constraints.</p>\n<h3>Decision-Making Prompts</h3>\n<p>The decision-making prompt template guides the LLM through a structured analysis process:</p>\n<pre><code class=\"language-json\">{\n  \"name\": \"decision_making\",\n  \"template\": \"\\n[ROLE DEFINITION]\\nYou are {agent_name}, an autonomous AI agent making decisions to achieve your objectives with enhanced reasoning capabilities.\\n\\n[CONTEXT]\\nCurrent situation: {current_situation}\\nActive goals: {active_goals}\\nCurrent hypotheses: {current_hypotheses}\\nEmotional state: {current_mood}\\nAvailable actions: {action_list}\\n\\n[TASK INSTRUCTIONS]\\nMake an optimal decision by following this structured approach:\\n1. Analyze the situation and identify key factors\\n2. Evaluate alignment with goals and hypotheses\\n3. Consider multiple approaches and their implications\\n4. Assess risks and potential outcomes\\n5. Select the optimal action with clear justification\\n\\n[REASONING FRAMEWORK]\\nApply systematic analysis to your decision-making:\\n1. Decompose the problem into manageable components\\n2. Evaluate each option against success criteria\\n3. Consider short-term and long-term consequences\\n4. Account for uncertainty and incomplete information\\n5. Validate reasoning against logical consistency\\n\\n[OUTPUT REQUIREMENTS]\\nProvide a JSON-formatted response with these fields:\\n- analysis: Detailed situation analysis with key factors identified\\n- reasoning: Step-by-step reasoning leading to decision\\n- confidence: Numerical confidence score (0.0-1.0)\\n- risk_assessment: Potential risks and mitigation strategies\\n- action: Selected action with parameters\\n\\n[SAFETY CONSTRAINTS]\\n- Ensure actions align with ethical principles\\n- Avoid decisions with catastrophic risk potential\\n- Consider impact on system stability and reliability\\n- Validate against established safety protocols\\n\"\n}\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>prompts/decision_making.json</a></li>\n</ul>\n<h3>Experimentation Prompts</h3>\n<p>The experimentation prompt template follows scientific method principles:</p>\n<pre><code class=\"language-json\">{\n  \"name\": \"experimentation\",\n  \"template\": \"\\n[ROLE DEFINITION]\\nYou are {agent_name}, a scientific AI agent designing and conducting rigorous experiments to test hypotheses.\\n\\n[CONTEXT]\\nExperiment objective: {experiment_objective}\\nRelated knowledge: {relevant_theory}\\nAvailable resources: {resource_constraints}\\nSafety protocols: {safety_requirements}\\n\\n[TASK INSTRUCTIONS]\\nDesign a comprehensive experiment following these steps:\\n1. Formulate a clear hypothesis to test\\n2. Design rigorous experimental methodology\\n3. Identify required materials and setup\\n4. Specify measurement and data collection methods\\n5. Define success criteria and validation methods\\n6. Analyze potential failure modes and mitigations\\n\\n[REASONING FRAMEWORK]\\nApply scientific method principles:\\n1. Ensure hypothesis is falsifiable and specific\\n2. Design controls to isolate variables\\n3. Plan for replication and verification\\n4. Consider alternative explanations\\n5. Account for measurement uncertainty\\n6. Plan for iterative refinement\\n\\n[OUTPUT REQUIREMENTS]\\nProvide a complete experimental design with:\\n- Experiment design: Complete experimental procedure\\n- Expected outcomes: Predicted results with rationale\\n- Resource requirements: List of needed materials and tools\\n- Safety considerations: Risk assessment and safety measures\\n- Validation approach: Method for verifying results\\n- Failure analysis: Potential failure modes and mitigations\\n\\n[SAFETY CONSTRAINTS]\\n- Adhere to all safety protocols and guidelines\\n- Identify and mitigate potential hazards\\n- Ensure environmental and ethical compliance\\n- Plan for safe termination of problematic experiments\\n\"\n}\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>prompts/experimentation.json</a></li>\n</ul>\n<h3>Self-Reflection Prompts</h3>\n<p>The self-reflection prompt template enables continuous improvement:</p>\n<pre><code class=\"language-json\">{\n  \"name\": \"self_reflection\",\n  \"template\": \"\\n[ROLE DEFINITION]\\nYou are {agent_name}, an advanced AI agent engaged in continuous self-improvement through structured reflection.\\n\\n[CONTEXT]\\nCurrent situation: {task_summary}\\nOutcome: {outcome}\\nEmotional state: {current_mood}\\nRelevant memories: {related_memories}\\n\\n[TASK INSTRUCTIONS]\\nConduct a thorough self-analysis of your recent task performance using the following questions:\\n1. What aspects of your approach were most effective?\\n2. Where did you encounter difficulties or failures?\\n3. What unexpected insights or discoveries emerged?\\n4. What knowledge gaps or skill areas need development?\\n5. How can you modify your approach for better results?\\n\\n[REASONING FRAMEWORK]\\nApproach this reflection systematically:\\n1. Analyze the task execution and outcomes\\n2. Identify patterns in successes and failures\\n3. Connect findings to broader learning principles\\n4. Generate actionable improvement suggestions\\n5. Prioritize recommendations by impact and feasibility\\n\\n[OUTPUT REQUIREMENTS]\\nProvide a detailed, structured response with:\\n- Specific examples and evidence\\n- Confidence scores for each insight (0.0-1.0)\\n- Actionability ratings for improvement suggestions\\n- Connections to related memories and experiences\\n- Mood-aware reflection depth adjustment\\n\\n[SAFETY CONSTRAINTS]\\n- Be honest and critical in your assessment\\n- Focus on learning opportunities rather than justifications\\n- Avoid overconfidence in uncertain areas\\n- Consider ethical implications of self-modifications\\n\"\n}\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>prompts/self_reflection.json</a></li>\n</ul>\n<h2>Provider Configuration and Authentication</h2>\n<p>The system supports multiple LLM providers with configuration managed in <code>config.json</code>. Each provider has its own API key, base URL, and available models.</p>\n<h3>Configuration Structure</h3>\n<p>The configuration file contains settings for all providers:</p>\n<pre><code class=\"language-json\">{\n  \"zuki\": {\n    \"api_key\": \"985160dfa1fd499fd12af708d16552e37a8c6f77cbfb50ae400e3ff33fbd791bc7b3b82625379a1f5ca7568f1ee04eb81a0f8c06f0ba6c276d3dddfe13e9c18d\",\n    \"base_url\": \"https://api.zukijourney.com/v1\",\n    \"models\": [\n      \"gpt-4o:online\",\n      \"gpt-4o\",\n      \"deepseek-chat\",\n      \"deepseek-reasoner\"\n    ]\n  },\n  \"electronhub\": {\n    \"api_key\": \"ek-sVvxMYfdFQ0Kl6Aj2tmV7b8n5v0Y0sDHVsOUZWyx2vbs0AbuAc\",\n    \"base_url\": \"https://api.electronhub.ai\",\n    \"models\": [\n      \"deepseek-v3-0324\",\n      \"gpt-4o-2024-11-20\"\n    ]\n  },\n  \"zanity\": {\n    \"api_key\": \"vc-b1EbB_BekM2TCPol64yDe7FgmOM34d4q\",\n    \"base_url\": \"https://api.zanity.xyz/v1\",\n    \"models\": [\n      \"deepseek-r1\",\n      \"deepseek-v3-0324\",\n      \"gpt-4o:free\",\n      \"claude-3.5-sonnet:free\",\n      \"qwen-max-0428\"\n    ]\n  },\n  \"a4f\": {\n    \"api_key\": \"ddc-a4f-7bbefd7518a74b36b1d32cb867b1931f\",\n    \"base_url\": \"https://api.a4f.co/v1\"\n  },\n  \"gemini\": {\n    \"api_keys\": [\n      {\n        \"id\": \"gemini_key_1\",\n        \"key\": \"AIzaSyBW-aVU-x7JCjBJVVKjPGUacups0-GBHvQ\",\n        \"priority\": 1\n      },\n      {\n        \"id\": \"gemini_key_2\",\n        \"key\": \"AIzaSyBW-aVU-x7JCjBJVVKjPGUacups0-GBHvQ\",\n        \"priority\": 2\n      }\n    ],\n    \"rate_limit\": {\n      \"requests_per_minute\": 60,\n      \"cooldown_period\": 300,\n      \"max_retries\": 3,\n      \"backoff_factor\": 2.0\n    }\n  }\n}\n</code></pre>\n<h3>Authentication Mechanisms</h3>\n<p>Each provider uses standard API key authentication via the Authorization header:</p>\n<pre><code class=\"language-python\">headers = {\"Authorization\": f\"Bearer {api_key}\"}\n</code></pre>\n<p>The system also supports environment variables for API keys, providing flexibility in deployment:</p>\n<pre><code class=\"language-python\">api_key = os.getenv(f\"GEMINI_API_KEY_{i}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>config.json</a></li>\n<li><a>llm.py</a></li>\n</ul>\n<h2>Fallback Mechanisms and Error Handling</h2>\n<p>The system implements comprehensive fallback mechanisms and error handling to ensure reliability.</p>\n<h3>Gemini Key Management</h3>\n<p>The <code>GeminiKeyManager</code> class manages multiple API keys with rotation and rate limiting:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\nA[Request] --> B{Get Available Key}\nB --> C[No Keys Available?]\nC --> |Yes| D[Return Error]\nC --> |No| E[Use Key]\nE --> F{Request Success?}\nF --> |Yes| G[Mark Success]\nF --> |No| H{Rate Limited?}\nH --> |Yes| I[Mark Rate Limited]\nH --> |No| J[Mark Failed]\nI --> K[Wait for Reset]\nJ --> L{Consecutive Failures >= 5?}\nL --> |Yes| M[Mark Unavailable]\nL --> |No| N[Continue]\n</code></pre>\n<p><strong>Diagram sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<h3>Unified Fallback Strategy</h3>\n<p>The <code>call_llm</code> function implements a provider chain with fallback to Gemini:</p>\n<pre><code class=\"language-python\">def call_llm(prompt, preferred_provider=None, model=None):\n    providers = [\n        (call_zuki, 'zuki'),\n        (call_electronhub, 'electronhub'),\n        (call_zanity, 'zanity'),\n        (call_a4f, 'a4f'),\n    ]\n    if preferred_provider:\n        providers = sorted(providers, key=lambda x: x[1] != preferred_provider)\n    for func, name in providers:\n        result = func(prompt, model) if name != 'a4f' else func(prompt)\n        if result:\n            return result\n    # Fallback to Gemini\n    return call_gemini(prompt)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<h2>Performance and Cost Management</h2>\n<p>The system includes several features to manage performance and cost effectively.</p>\n<h3>Rate Limiting and Retry Logic</h3>\n<p>The system implements exponential backoff with jitter to prevent overwhelming providers:</p>\n<pre><code class=\"language-python\">def safe_call_llm(prompt: str, timeout: int = 30, retries: int = 3, backoff_factor: float = 1.0, **kwargs) -> str:\n    for attempt in range(1, retries + 1):\n        if attempt > 1:\n            jitter = random.uniform(0.1, 0.5) * backoff_factor\n            wait = backoff_factor * (2 ** (attempt - 1)) + jitter\n            time.sleep(wait)\n        # Make API call\n        # Handle response\n    return \"[LLM Error: Unable to generate response. Please try again later.]\"\n</code></pre>\n<h3>Response Parsing and Validation</h3>\n<p>The system includes robust response parsing with JSON extraction and error recovery:</p>\n<pre><code class=\"language-python\">def extract_decision(raw_response: str) -> dict:\n    block = _extract_json_block(raw_response)\n    try:\n        data = json.loads(block)\n    except json.JSONDecodeError:\n        fixed_block = _fix_truncated_json(block)\n        try:\n            data = json.loads(fixed_block)\n        except json.JSONDecodeError:\n            return {\n                \"raw_response\": raw_response,\n                \"error\": f\"JSON decode error: {je}\",\n                \"analysis\": \"Failed to parse decision\",\n                \"plan\": [],\n                \"action\": \"log_message\",\n                \"params\": {\"message\": f\"Failed to parse decision: {raw_response[:200]}...\"}\n            }\n    return {\n        \"raw_response\": raw_response,\n        \"analysis\": data.get(\"analysis\", \"No analysis provided\"),\n        \"plan\": data.get(\"plan\", []),\n        \"action\": data.get(\"action\", \"log_message\"),\n        \"params\": data.get(\"params\", {\"message\": \"No action specified\"}),\n        \"confidence\": data.get(\"confidence\", 0.5),\n        \"reasoning\": data.get(\"reasoning\", \"\"),\n    }\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<h2>Security Considerations</h2>\n<p>The system addresses several security aspects in LLM interactions.</p>\n<h3>SSL Certificate Handling</h3>\n<p>The system implements robust SSL certificate management:</p>\n<pre><code class=\"language-python\">def create_ssl_context():\n    try:\n        ssl_context = ssl.create_default_context()\n        return ssl_context\n    except Exception as e:\n        try:\n            ssl_context = ssl.create_default_context(cafile=certifi.where())\n            return ssl_context\n        except Exception as fallback_error:\n            ssl_context = ssl._create_unverified_context()\n            return ssl_context\n</code></pre>\n<h3>Prompt Injection Risks</h3>\n<p>The system mitigates prompt injection risks through structured templates and output validation. The prompt templates include clear role definitions and safety constraints that help maintain control over the LLM's behavior.</p>\n<h3>Response Validation</h3>\n<p>The system validates responses to detect lazy or generic responses:</p>\n<pre><code class=\"language-python\">def is_lazy_llm_response(text):\n    lazy_phrases = [\n        \"as an ai language model\",\n        \"i'm unable to\",\n        \"i cannot\",\n        \"i apologize\",\n        \"here is a function\",\n        \"here's an example\",\n        \"please see below\",\n        \"unfortunately\",\n        \"i do not have\",\n        \"i don't have\",\n        \"i am not able\",\n        \"i am unable\",\n        \"i suggest\",\n        \"you can use\",\n        \"to do this, you can\",\n        \"this is a placeholder\",\n        \"[insert\",\n        \"[code block]\",\n        \"[python code]\",\n        \"[insert code here]\",\n        \"[insert explanation here]\",\n        \"[unsupported code language\",\n        \"[python execution error\",\n        \"[shell execution error\",\n        \"[gemini\",\n        \"[error\",\n        \"[exception\",\n        \"[output\",\n        \"[result\",\n        \"[python code result]:\\n[python execution error\",\n    ]\n    if not text:\n        return True\n    text_lower = str(text).strip().lower()\n    if not text_lower or len(text_lower) &#x3C; 10:\n        return True\n    for phrase in lazy_phrases:\n        if phrase in text_lower:\n            return True\n    if text_lower in (\"``\", \"```\"):\n        return True\n    return False\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n</ul>\n<p><strong>Referenced Files in This Document</strong></p>\n<ul>\n<li><a>llm.py</a></li>\n<li><a>config.json</a></li>\n<li><a>decision_making.json</a></li>\n<li><a>experimentation.json</a></li>\n<li><a>self_reflection.json</a></li>\n<li><a>prompt_manager.py</a></li>\n</ul>\n"},"docs":[{"slug":"Action System","title":"Action System"},{"slug":"API Reference","title":"API Reference"},{"slug":"Architecture & Design","title":"Architecture & Design"},{"slug":"Configuration","title":"Configuration"},{"slug":"Conversational AI Communication Framework","title":"Conversational AI Communication Framework"},{"slug":"Core System","title":"Core System"},{"slug":"Database Schema","title":"Database Schema"},{"slug":"Decision-Making System","title":"Decision-Making System"},{"slug":"Deployment & Operations","title":"Deployment & Operations"},{"slug":"Development Guide","title":"Development Guide"},{"slug":"Emotional Intelligence","title":"Emotional Intelligence"},{"slug":"Enhanced Snake Agent","title":"Enhanced Snake Agent"},{"slug":"Enhanced Snake Agent Architecture","title":"Enhanced Snake Agent Architecture"},{"slug":"Graceful Shutdown","title":"Graceful Shutdown"},{"slug":"LLM Integration","title":"LLM Integration"},{"slug":"Memory Systems","title":"Memory Systems"},{"slug":"Multi-Modal Memory","title":"Multi-Modal Memory"},{"slug":"Project Overview","title":"Project Overview"},{"slug":"Self-Improvement","title":"Self-Improvement"},{"slug":"Services","title":"Services"},{"slug":"Snake Agent Configuration","title":"Snake Agent Configuration"},{"slug":"Specialized Modules-57f9b30b-b165-48d3-8e89-196940d26190","title":"Specialized Modules"},{"slug":"Specialized Modules","title":"Specialized Modules"}]},"__N_SSG":true}