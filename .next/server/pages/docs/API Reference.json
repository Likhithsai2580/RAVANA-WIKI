{"pageProps":{"doc":{"slug":"API Reference","title":"API Reference","content":"<h1>API Reference</h1>\n<h2>Update Summary</h2>\n<p><strong>Changes Made</strong></p>\n<ul>\n<li>Updated Episodic Memory Client section with new methods for audio/image upload, advanced search, and batch processing</li>\n<li>Added new section for Multi-modal Memory Service with comprehensive API documentation</li>\n<li>Added new section for Memory Models with detailed data structure documentation</li>\n<li>Added new sections for PostgreSQL Store and Embedding Service implementations</li>\n<li>Updated Table of Contents to reflect new sections and organization</li>\n<li>Enhanced source tracking with specific file references and annotations</li>\n</ul>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#agisystem-class\">AGISystem Class</a></li>\n<li><a href=\"#action-abstract-base-class\">Action Abstract Base Class</a></li>\n<li><a href=\"#service-apis\">Service APIs</a>\n<ul>\n<li><a href=\"#data-service\">Data Service</a></li>\n<li><a href=\"#knowledge-service\">Knowledge Service</a></li>\n<li><a href=\"#memory-service\">Memory Service</a></li>\n<li><a href=\"#multi-modal-service\">Multi-modal Service</a></li>\n</ul>\n</li>\n<li><a href=\"#module-specific-apis\">Module-specific APIs</a>\n<ul>\n<li><a href=\"#episodic-memory-client\">Episodic Memory Client</a></li>\n<li><a href=\"#reflection-system\">Reflection System</a></li>\n</ul>\n</li>\n<li><a href=\"#multi-modal-memory-service\">Multi-modal Memory Service</a></li>\n<li><a href=\"#memory-models\">Memory Models</a></li>\n<li><a href=\"#postgresql-store\">PostgreSQL Store</a></li>\n<li><a href=\"#embedding-service\">Embedding Service</a></li>\n<li><a href=\"#initialization-and-lifecycle-management\">Initialization and Lifecycle Management</a></li>\n<li><a href=\"#thread-safety-and-async-usage\">Thread Safety and Async Usage</a></li>\n<li><a href=\"#error-handling\">Error Handling</a></li>\n<li><a href=\"#usage-examples\">Usage Examples</a></li>\n</ol>\n<h2>AGISystem Class</h2>\n<p>The <code>AGISystem</code> class is the central orchestrator of the Ravana AGI system, managing the integration of various modules, services, and decision-making processes. It implements an autonomous loop that continuously processes situations, makes decisions, executes actions, and reflects on outcomes.</p>\n<h3>Methods</h3>\n<h4><code>__init__(engine)</code></h4>\n<p>Initializes the AGI system with core components and services.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>engine</code>: Database engine instance for persistence operations</li>\n</ul>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>data_service</code>: DataService instance for data operations</li>\n<li><code>knowledge_service</code>: KnowledgeService instance for knowledge management</li>\n<li><code>memory_service</code>: MemoryService instance for memory operations</li>\n<li><code>action_manager</code>: EnhancedActionManager for action execution</li>\n<li><code>shared_state</code>: SharedState object for cross-component state</li>\n<li><code>personality</code>: Personality instance influencing behavior</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>None explicitly raised, but depends on underlying service initialization</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">from sqlalchemy import create_engine\nfrom core.system import AGISystem\n\nengine = create_engine(\"sqlite:///ravana.db\")\nagi = AGISystem(engine)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n</ul>\n<h4><code>run_autonomous_loop()</code></h4>\n<p>Starts the main autonomous loop of the AGI system, which continuously processes iterations.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>None (runs indefinitely until stopped)</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Logs critical errors but continues execution with extended sleep intervals</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">import asyncio\n\nasync def main():\n    await agi.run_autonomous_loop()\n\nasyncio.run(main())\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n</ul>\n<h4><code>run_single_task(prompt: str)</code></h4>\n<p>Executes a single task specified by a prompt, running multiple iterations if needed.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>prompt</code>: String describing the task to be performed</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>None (modifies internal state and executes actions)</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">await agi.run_single_task(\"Research quantum computing advancements\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n</ul>\n<h4><code>stop()</code></h4>\n<p>Gracefully stops the AGI system and all background tasks.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>None</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">await agi.stop()\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n</ul>\n<h4><code>get_recent_events(time_limit_seconds: int = 3600)</code></h4>\n<p>Retrieves recent events from the database within a specified time window.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>time_limit_seconds</code>: Number of seconds in the past to include (default: 3600)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>List of Event objects from the database</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">events = await agi.get_recent_events(7200)  # Get events from last 2 hours\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n</ul>\n<h2>Action Abstract Base Class</h2>\n<p>The <code>Action</code> class is an abstract base class that defines the interface for all actions that the AGI system can perform. All concrete actions must inherit from this class and implement its abstract methods.</p>\n<h3>Methods</h3>\n<h4><code>name</code> (property)</h4>\n<p>Returns the name of the action.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>String representing the action name</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/actions/action.py</a></li>\n</ul>\n<h4><code>description</code> (property)</h4>\n<p>Returns a description of what the action does.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>String describing the action's purpose</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/actions/action.py</a></li>\n</ul>\n<h4><code>parameters</code> (property)</h4>\n<p>Returns a list of parameters that the action accepts.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>List of dictionaries, each containing parameter metadata (name, type, required, etc.)</li>\n</ul>\n<p><strong>:Example Return</strong></p>\n<pre><code class=\"language-python\">[\n    {\n        \"name\": \"query\",\n        \"type\": \"string\",\n        \"required\": True,\n        \"description\": \"Search query string\"\n    }\n]\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/actions/action.py</a></li>\n</ul>\n<h4><code>execute(**kwargs: Any)</code></h4>\n<p>Abstract method that executes the action with the given parameters.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>**kwargs</code>: Arbitrary keyword arguments matching the action's parameters</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Any: Result of the action execution</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Must be implemented by subclasses</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/actions/action.py</a></li>\n</ul>\n<h4><code>validate_params(params: Dict[str, Any])</code></h4>\n<p>Validates the given parameters against the action's defined parameters.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>params</code>: Dictionary of parameter names and values</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li><code>InvalidActionParams</code>: Raised when required parameters are missing or unexpected parameters are provided</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">try:\n    action.validate_params({\"query\": \"AI research\"})\n    # Parameters are valid\nexcept InvalidActionParams as e:\n    print(f\"Invalid parameters: {e}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/actions/action.py</a></li>\n</ul>\n<h4><code>to_dict()</code></h4>\n<p>Returns a dictionary representation of the action.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary containing name, description, and parameters</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/actions/action.py</a></li>\n</ul>\n<h4><code>to_json()</code></h4>\n<p>Returns a JSON string representing the action's schema.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>String containing JSON-formatted action schema</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/actions/action.py</a></li>\n</ul>\n<h2>Service APIs</h2>\n<h3>Data Service</h3>\n<p>The <code>DataService</code> class handles data persistence operations, including articles, events, and logging.</p>\n<h4><code>__init__(engine, feed_urls, embedding_model=None, sentiment_classifier=None)</code></h4>\n<p>Initializes the data service with database connection and processing models.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>engine</code>: Database engine instance</li>\n<li><code>feed_urls</code>: List of RSS feed URLs to monitor</li>\n<li><code>embedding_model</code>: Optional sentence transformer model for embeddings</li>\n<li><code>sentiment_classifier</code>: Optional pipeline for sentiment analysis</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h4><code>fetch_and_save_articles()</code></h4>\n<p>Fetches articles from configured RSS feeds and saves new ones to the database.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Integer: Number of new articles saved</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">num_saved = await asyncio.to_thread(data_service.fetch_and_save_articles)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h4><code>detect_and_save_events()</code></h4>\n<p>Analyzes recent articles to detect and save significant events.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Integer: Number of events detected and saved</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">num_events = await asyncio.to_thread(data_service.detect_and_save_events)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h4><code>save_action_log(action_name, params, status, result)</code></h4>\n<p>Persists a record of an executed action to the database.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>action_name</code>: String name of the action</li>\n<li><code>params</code>: Dictionary of action parameters</li>\n<li><code>status</code>: String status (\"success\" or \"error\")</li>\n<li><code>result</code>: Any result data from action execution</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h4><code>save_mood_log(mood_vector)</code></h4>\n<p>Saves the current mood vector to the database.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>mood_vector</code>: Dictionary representing the current emotional state</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h4><code>save_situation_log(situation)</code></h4>\n<p>Saves a generated situation and returns its database ID.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>situation</code>: Dictionary containing situation details</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Integer: Database ID of the saved situation</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h4><code>save_decision_log(situation_id, raw_response)</code></h4>\n<p>Saves a decision made by the AGI to the database.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>situation_id</code>: Integer ID of the associated situation</li>\n<li><code>raw_response</code>: String containing the raw LLM response</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h4><code>save_experiment_log(hypothesis, *args)</code></h4>\n<p>Saves experiment results to the database with flexible calling conventions.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>hypothesis</code>: String describing the experiment hypothesis</li>\n<li><code>*args</code>: Either a single dict of results, or three arguments (test_plan, final_verdict, execution_result)</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li><code>TypeError</code>: Raised when arguments don't match expected patterns</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\"># Style 1: Dictionary of results\ndata_service.save_experiment_log(\"AI creativity improves with reflection\", {\"findings\": \"Positive correlation observed\"})\n\n# Style 2: Individual components\ndata_service.save_experiment_log(\n    \"Memory consolidation improves recall\",\n    \"Tested with 100 memory queries\",\n    \"Supported\",\n    {\"accuracy\": 0.92}\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h3>Knowledge Service</h3>\n<p>The <code>KnowledgeService</code> manages the storage, retrieval, and compression of knowledge.</p>\n<h4><code>__init__(engine, embedding_model=None)</code></h4>\n<p>Initializes the knowledge service with database connection and embedding model.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>engine</code>: Database engine instance</li>\n<li><code>embedding_model</code>: Optional SentenceTransformer instance (defaults to 'all-MiniLM-L6-v2')</li>\n</ul>\n<p><strong>:Notes</strong></p>\n<ul>\n<li>Automatically initializes FAISS index for semantic search if available</li>\n<li>Loads existing index from disk or creates new one</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h4><code>add_knowledge(content, source=\"unknown\", category=\"misc\")</code></h4>\n<p>Adds new knowledge by summarizing content and saving it with metadata.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>content</code>: String content to be added</li>\n<li><code>source</code>: String source identifier (default: \"unknown\")</li>\n<li><code>category</code>: String category (default: \"misc\")</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary containing:\n<ul>\n<li><code>timestamp</code>: ISO format timestamp</li>\n<li><code>summary</code>: Generated summary text</li>\n<li><code>source</code>: Source identifier</li>\n<li><code>category</code>: Category</li>\n<li><code>duplicate</code>: Boolean indicating if content already existed</li>\n<li><code>id</code>: Database ID (if new)</li>\n</ul>\n</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li><code>ValueError</code>: When no content is provided</li>\n<li>Logs and re-raises any other exceptions</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = await asyncio.to_thread(\n    knowledge_service.add_knowledge,\n    \"Recent advances in quantum computing have enabled...\",\n    source=\"research_paper\",\n    category=\"science\"\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h4><code>get_knowledge_by_category(category, limit=10)</code></h4>\n<p>Retrieves knowledge entries by category.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>category</code>: String category to filter by</li>\n<li><code>limit</code>: Maximum number of results to return (default: 10)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>List of dictionaries containing knowledge entry details</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h4><code>get_recent_knowledge(hours=24, limit=20)</code></h4>\n<p>Retrieves recently added knowledge entries.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>hours</code>: Number of hours in the past to include (default: 24)</li>\n<li><code>limit</code>: Maximum number of results (default: 20)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>List of knowledge entry dictionaries</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h4><code>search_knowledge(query, limit=10)</code></h4>\n<p>Performs text search in knowledge summaries.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>query</code>: Search query string</li>\n<li><code>limit</code>: Maximum results to return (default: 10)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>List of dictionaries with knowledge entries and relevance scores</li>\n</ul>\n<p><strong>:Notes</strong></p>\n<ul>\n<li>Uses simple LIKE search; could be enhanced with full-text search</li>\n<li>Includes relevance_score based on keyword matching</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h4><code>compress_and_save_knowledge()</code></h4>\n<p>Compresses recent knowledge into a summary and saves it.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary containing the generated summary</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Logs and re-raises any exceptions</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">summary = await asyncio.to_thread(knowledge_service.compress_and_save_knowledge)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h3>Memory Service</h3>\n<p>The <code>MemoryService</code> provides an interface to the episodic memory system.</p>\n<h4><code>get_relevant_memories(query_text)</code></h4>\n<p>Retrieves memories relevant to a query.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>query_text</code>: String query to find relevant memories</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable that resolves to a response object with relevant memories</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">response = await memory_service.get_relevant_memories(\"vacation plans\")\nfor memory in response.relevant_memories:\n    print(f\"{memory.text} (similarity: {memory.similarity})\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/memory_service.py</a></li>\n</ul>\n<h4><code>save_memories(memories)</code></h4>\n<p>Saves a list of memories to persistent storage.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memories</code>: List of memory strings or objects</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable (completes when save operation finishes)</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">await memory_service.save_memories([\"I planned a trip to Hawaii\", \"I enjoy hiking\"])\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/memory_service.py</a></li>\n</ul>\n<h4><code>extract_memories(user_input, ai_output)</code></h4>\n<p>Extracts memories from user-AI interaction.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>user_input</code>: String containing user message</li>\n<li><code>ai_output</code>: String containing AI response</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to an object with extracted memories</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = await memory_service.extract_memories(\n    \"I'm planning a vacation to Hawaii\", \n    \"That sounds wonderful!\"\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/memory_service.py</a></li>\n</ul>\n<h4><code>consolidate_memories()</code></h4>\n<p>Performs memory consolidation to optimize retrieval.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to consolidation results</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = await memory_service.consolidate_memories()\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/memory_service.py</a></li>\n</ul>\n<h3>Multi-modal Service</h3>\n<p>The <code>MultiModalService</code> handles processing of images, audio, and cross-modal analysis.</p>\n<h4><code>__init__()</code></h4>\n<p>Initializes the multi-modal service with supported formats and temporary directory.</p>\n<p><strong>:Notes</strong></p>\n<ul>\n<li>Creates temporary directory for processing files</li>\n<li>Defines supported image and audio formats</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/multi_modal_service.py</a></li>\n</ul>\n<h4><code>process_image(image_path, prompt=\"Analyze this image in detail\")</code></h4>\n<p>Processes an image file and returns detailed analysis.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>image_path</code>: String path to the image file</li>\n<li><code>prompt</code>: Optional custom prompt for analysis (default: \"Analyze this image in detail\")</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary containing:\n<ul>\n<li><code>type</code>: \"image\"</li>\n<li><code>path</code>: Original path</li>\n<li><code>format</code>: File extension</li>\n<li><code>size_bytes</code>: File size</li>\n<li><code>description</code>: AI-generated description</li>\n<li><code>analysis_prompt</code>: Prompt used</li>\n<li><code>success</code>: Boolean indicating success</li>\n<li><code>error</code>: Error message if unsuccessful</li>\n</ul>\n</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li><code>FileNotFoundError</code>: When image file doesn't exist</li>\n<li><code>ValueError</code>: When file format is unsupported</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = await multi_modal_service.process_image(\"/path/to/photo.jpg\")\nif result[\"success\"]:\n    print(result[\"description\"])\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/multi_modal_service.py</a></li>\n</ul>\n<h4><code>process_audio(audio_path, prompt=\"Describe and analyze this audio\")</code></h4>\n<p>Processes an audio file and returns analysis.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>audio_path</code>: String path to the audio file</li>\n<li><code>prompt</code>: Optional custom prompt for analysis (default: \"Describe and analyze this audio\")</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with similar structure to process_image result</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li><code>FileNotFoundError</code>: When audio file doesn't exist</li>\n<li><code>ValueError</code>: When file format is unsupported</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/multi_modal_service.py</a></li>\n</ul>\n<h4><code>cross_modal_analysis(content_list, analysis_prompt=None)</code></h4>\n<p>Performs analysis across multiple content types.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>content_list</code>: List of processed content objects (from process_image/process_audio)</li>\n<li><code>analysis_prompt</code>: Optional custom analysis prompt</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary containing cross-modal analysis</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">analysis = await multi_modal_service.cross_modal_analysis([\n    image_result, \n    audio_result\n])\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/multi_modal_service.py</a></li>\n</ul>\n<h4><code>generate_content_summary(processed_content)</code></h4>\n<p>Generates a comprehensive summary of multi-modal content.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>processed_content</code>: List of processed content results</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>String summary of all content</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/multi_modal_service.py</a></li>\n</ul>\n<h4><code>process_directory(directory_path, recursive=False)</code></h4>\n<p>Processes all supported files in a directory.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>directory_path</code>: Path to directory to process</li>\n<li><code>recursive</code>: Whether to include subdirectories (default: False)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>List of processing results for each file</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/multi_modal_service.py</a></li>\n</ul>\n<h4><code>cleanup_temp_files(max_age_hours=24)</code></h4>\n<p>Cleans up temporary files older than specified age.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>max_age_hours</code>: Maximum age in hours (default: 24)</li>\n</ul>\n<p><strong>:Notes</strong></p>\n<ul>\n<li>Runs synchronously (not async)</li>\n<li>Used for maintenance</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/multi_modal_service.py</a></li>\n</ul>\n<h2>Module-specific APIs</h2>\n<h3>Episodic Memory Client</h3>\n<p>The episodic memory client provides direct access to the memory database API.</p>\n<h4><code>extract_memories(user_input, ai_output)</code></h4>\n<p>Calls the /extract_memories/ endpoint to extract memories from conversation.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>user_input</code>: String user message</li>\n<li><code>ai_output</code>: String AI response</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with extracted memories or None on failure</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = extract_memories(\"I love hiking in the mountains\", \"That sounds invigorating!\")\nif result and 'memories' in result:\n    print(f\"Extracted: {result['memories']}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h4><code>save_memories(memories_list, memory_type='long-term')</code></h4>\n<p>Saves a list of memories to the server.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memories_list</code>: List of memory strings</li>\n<li><code>memory_type</code>: String type of memory (default: 'long-term')</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with save response or None on failure</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h4><code>get_relevant_memories(query_text, top_n=5, similarity_threshold=0.7)</code></h4>\n<p>Retrieves memories relevant to a query.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>query_text</code>: Search query</li>\n<li><code>top_n</code>: Maximum number of results (default: 5)</li>\n<li><code>similarity_threshold</code>: Minimum similarity score (default: 0.7)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with relevant memories or None on failure</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h4><code>health_check()</code></h4>\n<p>Checks the health of the memory database API.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with health status or None on failure</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">health = health_check()\nif health and health.get(\"status\") == \"ok\":\n    print(\"Memory API is healthy\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h4><code>upload_audio_file(file_path, context=None, extract_text=True)</code></h4>\n<p>Uploads an audio file and processes it into memory.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>file_path</code>: Path to the audio file</li>\n<li><code>context</code>: Optional context for transcription</li>\n<li><code>extract_text</code>: Whether to extract text from audio</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with processing result or None on failure</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = upload_audio_file(\"meeting_recording.mp3\", context=\"Team meeting about project timeline\")\nif result and result[\"success\"]:\n    print(f\"Audio processed with transcript: {result['transcript']}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h4><code>upload_image_file(file_path, description=None)</code></h4>\n<p>Uploads an image file and processes it into memory.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>file_path</code>: Path to the image file</li>\n<li><code>description</code>: Optional description of the image</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with processing result or None on failure</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = upload_image_file(\"vacation_photo.jpg\", description=\"Sunset at the beach\")\nif result and result[\"success\"]:\n    print(f\"Image processed with description: {result['description']}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h4><code>advanced_search(query, content_types=None, memory_types=None, search_mode=\"hybrid\")</code></h4>\n<p>Performs advanced search with multiple filtering options.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>query</code>: Search query string</li>\n<li><code>content_types</code>: List of content types to include</li>\n<li><code>memory_types</code>: List of memory types to include</li>\n<li><code>search_mode</code>: Search mode (\"text\", \"vector\", \"hybrid\")</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with search results or None on failure</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">results = advanced_search(\n    \"beach vacation\", \n    content_types=[\"image\", \"text\"], \n    memory_types=[\"episodic\"],\n    search_mode=\"hybrid\"\n)\nif results:\n    for result in results[\"results\"]:\n        print(f\"Found: {result['content_text']} (score: {result['similarity_score']})\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h4><code>batch_process_files(file_paths, content_types=None)</code></h4>\n<p>Processes multiple files in batch.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>file_paths</code>: List of file paths to process</li>\n<li><code>content_types</code>: Optional list of content types corresponding to files</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Dictionary with batch processing results or None on failure</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">results = batch_process_files([\n    \"notes.txt\", \n    \"meeting_recording.mp3\", \n    \"project_diagram.jpg\"\n])\nif results:\n    print(f\"Processed {results['successful_count']} of {results['total_processed']} files\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h3>Reflection System</h3>\n<p>The <code>ReflectionModule</code> enables self-reflection capabilities.</p>\n<h4><code>__init__(agi_system)</code></h4>\n<p>Initializes the reflection module with a reference to the AGI system.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>agi_system</code>: Reference to the main AGISystem instance</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/reflection_module.py</a></li>\n</ul>\n<h4><code>reflect_on_experiment(experiment_results)</code></h4>\n<p>Analyzes experiment results and generates insights.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>experiment_results</code>: Dictionary containing experiment data including 'hypothesis' and 'findings'</li>\n</ul>\n<p><strong>:Notes</strong></p>\n<ul>\n<li>Automatically adds generated insights to the knowledge base</li>\n<li>Uses \"reflection\" as source and \"insight\" as category</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/reflection_module.py</a></li>\n</ul>\n<h4><code>reflect(shared_state)</code></h4>\n<p>Performs general reflection based on the system's state.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>shared_state</code>: SharedState object containing mood history and other state</li>\n</ul>\n<p><strong>:Notes</strong></p>\n<ul>\n<li>Currently focuses on mood history analysis</li>\n<li>Placeholder for more sophisticated reflection logic</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/reflection_module.py</a></li>\n</ul>\n<h2>Multi-modal Memory Service</h2>\n<p>The <code>MultiModalMemoryService</code> is the main orchestration class for the multi-modal memory system, integrating PostgreSQL storage, embeddings, Whisper audio processing, and advanced search capabilities.</p>\n<h3>Methods</h3>\n<h4><code>__init__(database_url, text_model_name=\"all-MiniLM-L6-v2\", whisper_model_size=\"base\", device=None)</code></h4>\n<p>Initializes the multi-modal memory service with all required components.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>database_url</code>: PostgreSQL connection URL</li>\n<li><code>text_model_name</code>: SentenceTransformer model name for text embeddings</li>\n<li><code>whisper_model_size</code>: Whisper model size for audio processing</li>\n<li><code>device</code>: Device to use (\"cpu\", \"cuda\", \"auto\")</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">service = MultiModalMemoryService(\n    database_url=\"postgresql://user:pass@localhost:5432/ravana\",\n    text_model_name=\"all-MiniLM-L6-v2\",\n    whisper_model_size=\"base\"\n)\nawait service.initialize()\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>initialize()</code></h4>\n<p>Initializes all service components and establishes database connections.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable that completes when initialization is finished</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Raises exception if initialization fails</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">try:\n    await service.initialize()\n    print(\"Service initialized successfully\")\nexcept Exception as e:\n    print(f\"Initialization failed: {e}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>close()</code></h4>\n<p>Closes all service components gracefully and releases resources.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable that completes when shutdown is finished</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">await service.close()\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>process_text_memory(text, memory_type=\"episodic\", tags=None, emotional_valence=None)</code></h4>\n<p>Processes and stores text memory with embeddings.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>text</code>: Text content to store</li>\n<li><code>memory_type</code>: Type of memory (\"episodic\", \"semantic\", \"procedural\")</li>\n<li><code>tags</code>: Optional list of tags</li>\n<li><code>emotional_valence</code>: Emotional valence (-1.0 to 1.0)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to the stored MemoryRecord</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">record = await service.process_text_memory(\n    \"I enjoyed the concert last night\",\n    memory_type=\"episodic\",\n    tags=[\"entertainment\", \"music\"],\n    emotional_valence=0.8\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>process_audio_memory(audio_path, context=None, memory_type=\"episodic\", tags=None)</code></h4>\n<p>Processes and stores audio memory with Whisper transcription and embeddings.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>audio_path</code>: Path to the audio file</li>\n<li><code>context</code>: Optional context for transcription</li>\n<li><code>memory_type</code>: Type of memory</li>\n<li><code>tags</code>: Optional list of tags</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to the stored MemoryRecord</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">record = await service.process_audio_memory(\n    \"meeting_recording.mp3\",\n    context=\"Team meeting about project timeline\",\n    tags=[\"work\", \"meetings\"]\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>process_image_memory(image_path, description=None, memory_type=\"episodic\", tags=None)</code></h4>\n<p>Processes and stores image memory with metadata and embeddings.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>image_path</code>: Path to the image file</li>\n<li><code>description</code>: Optional image description</li>\n<li><code>memory_type</code>: Type of memory</li>\n<li><code>tags</code>: Optional list of tags</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to the stored MemoryRecord</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">record = await service.process_image_memory(\n    \"vacation_photo.jpg\",\n    description=\"Sunset at the beach\",\n    tags=[\"vacation\", \"nature\"]\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>extract_memories_from_conversation(request)</code></h4>\n<p>Extracts memories from a conversation using LLM analysis.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>request</code>: ConversationRequest object with user_input, ai_output, and context</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to MemoriesList object</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">request = ConversationRequest(\n    user_input=\"I'm planning a trip to Japan next spring\",\n    ai_output=\"That sounds like an amazing adventure!\",\n    context=\"Travel planning conversation\"\n)\nmemories = await service.extract_memories_from_conversation(request)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>save_extracted_memories(memories_list)</code></h4>\n<p>Saves a list of extracted memories to the database.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memories_list</code>: MemoriesList object containing memories to save</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of saved MemoryRecord objects</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">saved_records = await service.save_extracted_memories(memories_list)\nprint(f\"Saved {len(saved_records)} memories\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>search_memories(request)</code></h4>\n<p>Searches memories using advanced search capabilities.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>request</code>: SearchRequest object with query and search parameters</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to SearchResponse object</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">request = SearchRequest(\n    query=\"beach vacation\",\n    content_types=[ContentType.IMAGE, ContentType.TEXT],\n    memory_types=[MemoryType.EPISODIC],\n    search_mode=SearchMode.HYBRID,\n    limit=10,\n    similarity_threshold=0.7\n)\nresponse = await service.search_memories(request)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>find_similar_memories(memory_id, limit=10, similarity_threshold=0.7)</code></h4>\n<p>Finds memories similar to a given memory.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memory_id</code>: UUID of the reference memory</li>\n<li><code>limit</code>: Maximum number of similar memories to return</li>\n<li><code>similarity_threshold</code>: Minimum similarity score (0.0 to 1.0)</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of similar MemoryRecord objects</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">similar_memories = await service.find_similar_memories(\n    memory_id=\"a1b2c3d4-e5f6-7890-1234-567890abcdef\",\n    limit=5,\n    similarity_threshold=0.8\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>batch_process_files(request)</code></h4>\n<p>Processes multiple files in batch with parallel processing.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>request</code>: BatchProcessRequest object with file paths and processing options</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to BatchProcessResult object</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">request = BatchProcessRequest(\n    file_paths=[\"notes.txt\", \"meeting.mp3\", \"diagram.jpg\"],\n    parallel_processing=True,\n    max_workers=4\n)\nresult = await service.batch_process_files(request)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>get_memory_statistics()</code></h4>\n<p>Retrieves comprehensive statistics about the memory system.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to MemoryStatistics object</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">stats = await service.get_memory_statistics()\nprint(f\"Total memories: {stats.total_memories}\")\nprint(f\"Storage size: {stats.storage_size_mb:.2f} MB\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>consolidate_memories(memory_ids=None, max_memories=50)</code></h4>\n<p>Consolidates memories to optimize storage and retrieval.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memory_ids</code>: Optional list of specific memory IDs to consolidate</li>\n<li><code>max_memories</code>: Maximum number of memories to process</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to dictionary with consolidation results</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">result = await service.consolidate_memories(\n    memory_ids=[\"a1b2c3d4-e5f6-7890-1234-567890abcdef\"],\n    max_memories=100\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h4><code>health_check()</code></h4>\n<p>Performs a comprehensive health check of the memory system.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to dictionary with health status</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">health = await service.health_check()\nif health[\"status\"] == \"healthy\":\n    print(\"Memory system is healthy\")\nelse:\n    print(f\"Memory system status: {health['status']}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n</ul>\n<h2>Memory Models</h2>\n<p>This section documents the data models used in the multi-modal memory system, defining the structure of memory records, search requests, and responses.</p>\n<h3>Core Data Models</h3>\n<h4><code>MemoryRecord</code></h4>\n<p>Main memory record model containing all memory data and metadata.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>id</code>: Optional UUID for the memory record</li>\n<li><code>content_type</code>: ContentType enum value (TEXT, AUDIO, IMAGE, VIDEO)</li>\n<li><code>content_text</code>: Optional text content</li>\n<li><code>content_metadata</code>: Dictionary of additional metadata</li>\n<li><code>file_path</code>: Optional path to associated file</li>\n<li><code>text_embedding</code>: Optional list of floats for text embedding</li>\n<li><code>image_embedding</code>: Optional list of floats for image embedding</li>\n<li><code>audio_embedding</code>: Optional list of floats for audio embedding</li>\n<li><code>unified_embedding</code>: Optional list of floats for combined embedding</li>\n<li><code>created_at</code>: Optional datetime of creation</li>\n<li><code>last_accessed</code>: Optional datetime of last access</li>\n<li><code>access_count</code>: Integer count of accesses</li>\n<li><code>memory_type</code>: MemoryType enum value (EPISODIC, SEMANTIC, PROCEDURAL)</li>\n<li><code>emotional_valence</code>: Optional float (-1.0 to 1.0) for emotional valence</li>\n<li><code>confidence_score</code>: Float (0.0 to 1.0) for confidence in memory</li>\n<li><code>tags</code>: List of string tags</li>\n<li><code>audio_metadata</code>: Optional AudioMetadata object</li>\n<li><code>image_metadata</code>: Optional ImageMetadata object</li>\n<li><code>video_metadata</code>: Optional VideoMetadata object</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>SearchRequest</code></h4>\n<p>Request model for memory search operations with advanced filtering.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>query</code>: Search query string (1-1000 characters)</li>\n<li><code>content_types</code>: Optional list of ContentType values to filter by</li>\n<li><code>memory_types</code>: Optional list of MemoryType values to filter by</li>\n<li><code>search_mode</code>: SearchMode enum value (TEXT, VECTOR, HYBRID)</li>\n<li><code>limit</code>: Integer limit on results (1-100)</li>\n<li><code>similarity_threshold</code>: Float threshold for similarity (0.0-1.0)</li>\n<li><code>include_metadata</code>: Boolean to include metadata in results</li>\n<li><code>tags</code>: Optional list of tags to filter by</li>\n<li><code>query_content_type</code>: Optional ContentType for cross-modal search</li>\n<li><code>target_content_types</code>: Optional list of target types for cross-modal search</li>\n<li><code>created_after</code>: Optional datetime filter for creation date</li>\n<li><code>created_before</code>: Optional datetime filter for creation date</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>SearchResponse</code></h4>\n<p>Response model for search operations containing results and metadata.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>results</code>: List of SearchResult objects</li>\n<li><code>total_found</code>: Integer count of total matching memories</li>\n<li><code>search_time_ms</code>: Integer search duration in milliseconds</li>\n<li><code>search_mode</code>: SearchMode enum value used</li>\n<li><code>query_metadata</code>: Dictionary of additional query metadata</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>ConversationRequest</code></h4>\n<p>Request model for memory extraction from conversations.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>user_input</code>: User message text (required)</li>\n<li><code>ai_output</code>: AI response text (required)</li>\n<li><code>context</code>: Optional context for extraction</li>\n<li><code>extract_emotions</code>: Boolean to extract emotional content</li>\n<li><code>memory_type</code>: MemoryType enum value for extracted memories</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>MemoriesList</code></h4>\n<p>List of extracted memories with metadata.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>memories</code>: List of memory text strings</li>\n<li><code>memory_type</code>: MemoryType enum value for all memories</li>\n<li><code>confidence_scores</code>: Optional list of confidence scores</li>\n<li><code>emotional_valences</code>: Optional list of emotional valences</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h3>Content Type Models</h3>\n<h4><code>AudioMetadata</code></h4>\n<p>Metadata specific to audio content.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>transcript</code>: Optional transcription text</li>\n<li><code>language_code</code>: Optional language code (e.g., \"en\")</li>\n<li><code>confidence_scores</code>: Dictionary of confidence scores</li>\n<li><code>duration_seconds</code>: Optional duration in seconds</li>\n<li><code>audio_features</code>: Dictionary of audio analysis features</li>\n<li><code>sample_rate</code>: Optional sample rate in Hz</li>\n<li><code>channels</code>: Optional number of audio channels</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>ImageMetadata</code></h4>\n<p>Metadata specific to image content.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>width</code>: Optional image width in pixels</li>\n<li><code>height</code>: Optional image height in pixels</li>\n<li><code>object_detections</code>: Dictionary of detected objects</li>\n<li><code>scene_description</code>: Optional scene description</li>\n<li><code>image_hash</code>: Optional perceptual hash</li>\n<li><code>color_palette</code>: List of dominant colors</li>\n<li><code>image_features</code>: Dictionary of image analysis features</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>VideoMetadata</code></h4>\n<p>Metadata specific to video content.</p>\n<p><strong>:Attributes</strong></p>\n<ul>\n<li><code>duration_seconds</code>: Optional duration in seconds</li>\n<li><code>frame_rate</code>: Optional frame rate in fps</li>\n<li><code>width</code>: Optional video width in pixels</li>\n<li><code>height</code>: Optional video height in pixels</li>\n<li><code>video_features</code>: Dictionary of video analysis features</li>\n<li><code>thumbnail_path</code>: Optional path to thumbnail image</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h3>Enumerations</h3>\n<h4><code>ContentType</code></h4>\n<p>Enumeration of supported content types.</p>\n<p><strong>:Values</strong></p>\n<ul>\n<li><code>TEXT</code>: Text content</li>\n<li><code>AUDIO</code>: Audio content</li>\n<li><code>IMAGE</code>: Image content</li>\n<li><code>VIDEO</code>: Video content</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>MemoryType</code></h4>\n<p>Enumeration of memory types.</p>\n<p><strong>:Values</strong></p>\n<ul>\n<li><code>EPISODIC</code>: Episodic memories (personal experiences)</li>\n<li><code>SEMANTIC</code>: Semantic memories (facts and knowledge)</li>\n<li><code>PROCEDURAL</code>: Procedural memories (skills and procedures)</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h4><code>SearchMode</code></h4>\n<p>Enumeration of search modes.</p>\n<p><strong>:Values</strong></p>\n<ul>\n<li><code>TEXT</code>: Text-based search</li>\n<li><code>VECTOR</code>: Vector similarity search</li>\n<li><code>HYBRID</code>: Hybrid search combining text and vector</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<h2>PostgreSQL Store</h2>\n<p>The <code>PostgreSQLStore</code> class handles database operations for the multi-modal memory system with pgvector support for similarity search.</p>\n<h3>Methods</h3>\n<h4><code>__init__(database_url, pool_size=10, max_connections=20)</code></h4>\n<p>Initializes the PostgreSQL store with connection parameters.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>database_url</code>: PostgreSQL connection URL</li>\n<li><code>pool_size</code>: Minimum connection pool size</li>\n<li><code>max_connections</code>: Maximum connection pool size</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Raises ImportError if AsyncPG is not available</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>initialize()</code></h4>\n<p>Initializes the database connection pool.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable that completes when initialization is finished</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Raises exception if initialization fails</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">await store.initialize()\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>close()</code></h4>\n<p>Closes the database connection pool.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable that completes when closure is finished</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">await store.close()\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>save_memory_record(memory_record)</code></h4>\n<p>Saves a memory record to the database.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memory_record</code>: MemoryRecord object to save</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to the saved MemoryRecord</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Raises exception if save fails</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">saved_record = await store.save_memory_record(memory_record)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>get_memory_record(memory_id)</code></h4>\n<p>Retrieves a memory record by ID.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memory_id</code>: UUID of the memory record</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to MemoryRecord or None if not found</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">record = await store.get_memory_record(\"a1b2c3d4-e5f6-7890-1234-567890abcdef\")\nif record:\n    print(f\"Found memory: {record.content_text}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>vector_search(embedding, embedding_type=\"text\", limit=10, similarity_threshold=0.7, content_types=None)</code></h4>\n<p>Performs vector similarity search.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>embedding</code>: List of floats representing the query embedding</li>\n<li><code>embedding_type</code>: Type of embedding (\"text\", \"image\", \"audio\", \"unified\")</li>\n<li><code>limit</code>: Maximum number of results to return</li>\n<li><code>similarity_threshold</code>: Minimum similarity score (0.0-1.0)</li>\n<li><code>content_types</code>: Optional list of ContentType values to filter by</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of (MemoryRecord, similarity_score) tuples</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">results = await store.vector_search(\n    embedding=[0.1, 0.2, 0.3, ...],\n    embedding_type=\"text\",\n    limit=5,\n    similarity_threshold=0.8\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>text_search(query_text, limit=10, content_types=None)</code></h4>\n<p>Performs full-text search.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>query_text</code>: Search query string</li>\n<li><code>limit</code>: Maximum number of results to return</li>\n<li><code>content_types</code>: Optional list of ContentType values to filter by</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of (MemoryRecord, relevance_score) tuples</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">results = await store.text_search(\"beach vacation\", limit=10)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>delete_memory_record(memory_id)</code></h4>\n<p>Deletes a memory record by ID.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memory_id</code>: UUID of the memory record to delete</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to boolean (True if deleted, False if not found)</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">deleted = await store.delete_memory_record(\"a1b2c3d4-e5f6-7890-1234-567890abcdef\")\nif deleted:\n    print(\"Memory deleted successfully\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>get_memory_statistics()</code></h4>\n<p>Retrieves comprehensive statistics about the memory system.</p>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to dictionary with statistics</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">stats = await store.get_memory_statistics()\nprint(f\"Total memories: {stats['total_memories']}\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h4><code>cleanup_old_memories(days_old=30, keep_minimum=1000)</code></h4>\n<p>Cleans up old, rarely accessed memories.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>days_old</code>: Age threshold in days</li>\n<li><code>keep_minimum</code>: Minimum number of memories to keep</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to integer count of deleted memories</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">deleted_count = await store.cleanup_old_memories(days_old=60, keep_minimum=500)\nprint(f\"Cleaned up {deleted_count} old memories\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/postgresql_store.py</a></li>\n</ul>\n<h2>Embedding Service</h2>\n<p>The <code>EmbeddingService</code> class handles the generation of embeddings for multi-modal content, supporting text, image, audio, and unified embeddings.</p>\n<h3>Methods</h3>\n<h4><code>__init__(text_model_name=\"all-MiniLM-L6-v2\", device=None, cache_size=1000)</code></h4>\n<p>Initializes the embedding service with configuration parameters.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>text_model_name</code>: Name of the sentence transformer model</li>\n<li><code>device</code>: Device to use (\"cpu\", \"cuda\", \"auto\")</li>\n<li><code>cache_size</code>: Size of the embedding cache</li>\n</ul>\n<p><strong>:Exceptions</strong></p>\n<ul>\n<li>Raises ImportError if transformers dependencies are not available</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">service = EmbeddingService(\n    text_model_name=\"all-MiniLM-L6-v2\",\n    device=\"cuda\",\n    cache_size=2000\n)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/embedding_service.py</a></li>\n</ul>\n<h4><code>generate_text_embedding(text)</code></h4>\n<p>Generates embedding for text content.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>text</code>: Text string to embed</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of floats (embedding values)</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">embedding = await service.generate_text_embedding(\"This is a sample text\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/embedding_service.py</a></li>\n</ul>\n<h4><code>generate_image_embedding(image_path)</code></h4>\n<p>Generates embedding for image content.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>image_path</code>: Path to the image file</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of floats (embedding values)</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">embedding = await service.generate_image_embedding(\"photo.jpg\")\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/embedding_service.py</a></li>\n</ul>\n<h4><code>generate_audio_embedding(audio_features)</code></h4>\n<p>Generates embedding for audio content from extracted features.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>audio_features</code>: Dictionary of audio analysis features</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of floats (embedding values)</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">embedding = await service.generate_audio_embedding({\n    \"mfcc\": {\"mean\": [...], \"std\": [...]},\n    \"spectral_centroid\": {\"mean\": 1000.0, \"std\": 200.0}\n})\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/embedding_service.py</a></li>\n</ul>\n<h4><code>generate_unified_embedding(memory_record)</code></h4>\n<p>Generates unified embedding combining all available modalities.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memory_record</code>: MemoryRecord object with various embeddings</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to list of floats (unified embedding values)</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">unified_embedding = await service.generate_unified_embedding(memory_record)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/embedding_service.py</a></li>\n</ul>\n<h4><code>generate_embeddings(memory_record)</code></h4>\n<p>Generates all relevant embeddings for a memory record.</p>\n<p><strong>:Parameters</strong></p>\n<ul>\n<li><code>memory_record</code>: MemoryRecord object to process</li>\n</ul>\n<p><strong>:Returns</strong></p>\n<ul>\n<li>Awaitable resolving to MemoryRecord with embeddings populated</li>\n</ul>\n<p><strong>:Usage</strong></p>\n<pre><code class=\"language-python\">processed_record = await service.generate_embeddings(memory_record)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>modules/episodic_memory/embedding_service.py</a></li>\n</ul>\n<h2>Initialization and Lifecycle Management</h2>\n<p>The AGI system follows a specific initialization and lifecycle pattern to ensure proper setup and graceful shutdown.</p>\n<h3>Initialization Pattern</h3>\n<pre><code class=\"language-python\">from sqlalchemy import create_engine\nfrom core.system import AGISystem\n\n# Create database engine\nengine = create_engine(\"sqlite:///ravana.db\")\n\n# Initialize AGI system\nagi = AGISystem(engine)\n\n# System is now ready for use\n</code></pre>\n<p>The initialization process:</p>\n<ol>\n<li>Creates all service instances (data, knowledge, memory)</li>\n<li>Initializes modules (situation generator, emotional intelligence, etc.)</li>\n<li>Sets up shared state and behavior modifiers</li>\n<li>Prepares background tasks (not started yet)</li>\n</ol>\n<h3>Lifecycle Management</h3>\n<p>The AGI system supports both autonomous and task-based operation modes:</p>\n<h4>Autonomous Mode</h4>\n<pre><code class=\"language-python\">import asyncio\n\nasync def main():\n    try:\n        await agi.run_autonomous_loop()\n    except KeyboardInterrupt:\n        await agi.stop()\n\nasyncio.run(main())\n</code></pre>\n<h4>Single Task Mode</h4>\n<pre><code class=\"language-python\">await agi.run_single_task(\"Research renewable energy technologies\")\nawait agi.stop()\n</code></pre>\n<h4>Graceful Shutdown</h4>\n<pre><code class=\"language-python\">await agi.stop()  # Cancels background tasks and closes resources\n</code></pre>\n<p>The system uses an asyncio.Event for shutdown signaling and properly cancels all background tasks.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n</ul>\n<h2>Thread Safety and Async Usage</h2>\n<p>The AGI system is designed for asynchronous operation with careful consideration of thread safety.</p>\n<h3>Async/Await Usage</h3>\n<p>Most methods are coroutines and must be awaited:</p>\n<pre><code class=\"language-python\"># Correct usage\nawait agi.run_iteration()\nawait agi._handle_curiosity()\n\n# Incorrect usage (will return coroutine object)\nagi.run_iteration()  # Missing await\n</code></pre>\n<h3>Thread Safety Considerations</h3>\n<ul>\n<li>Database operations use <code>asyncio.to_thread()</code> for synchronous calls</li>\n<li>The <code>EnhancedActionManager</code> handles action execution in thread pool</li>\n<li>Shared state modifications are coordinated through the main event loop</li>\n<li>Background tasks are properly managed and canceled on shutdown</li>\n</ul>\n<h3>Background Tasks</h3>\n<p>The system manages several background tasks:</p>\n<ul>\n<li>Data collection (RSS feeds)</li>\n<li>Event detection</li>\n<li>Knowledge compression</li>\n<li>Memory consolidation</li>\n<li>Invention tracking</li>\n</ul>\n<p>These tasks are automatically started in <code>run_autonomous_loop()</code> and properly cleaned up in <code>stop()</code>.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n</ul>\n<h2>Error Handling</h2>\n<p>The system implements comprehensive error handling at multiple levels.</p>\n<h3>Exception Types</h3>\n<ul>\n<li><code>InvalidActionParams</code>: Raised when action parameters are invalid</li>\n<li><code>ValueError</code>: Used for validation errors (e.g., empty content)</li>\n<li><code>TypeError</code>: For incorrect argument types</li>\n<li><code>FileNotFoundError</code>: When files don't exist</li>\n<li><code>json.JSONDecodeError</code>: When parsing JSON fails</li>\n</ul>\n<h3>Error Handling Patterns</h3>\n<h4>Service-Level Error Handling</h4>\n<pre><code class=\"language-python\">try:\n    result = await self.memory_service.extract_memories(interaction_summary, \"\")\n    if result and result.memories:\n        await self.memory_service.save_memories(result.memories)\nexcept Exception as e:\n    logger.error(f\"Failed during memorization: {e}\", exc_info=True)\n</code></pre>\n<h4>Background Task Error Handling</h4>\n<pre><code class=\"language-python\">while not self._shutdown.is_set():\n    try:\n        # Task logic here\n        pass\n    except asyncio.CancelledError:\n        break\n    except Exception as e:\n        logger.error(f\"Error in task: {e}\", exc_info=True)\n</code></pre>\n<h4>External API Error Handling</h4>\n<p>The episodic memory client implements retry logic:</p>\n<ul>\n<li>Maximum of 3 retries for connection errors</li>\n<li>1-second delay between retries</li>\n<li>Comprehensive error reporting</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n<li><a>modules/episodic_memory/client.py</a></li>\n</ul>\n<h2>Usage Examples</h2>\n<h3>Basic System Initialization and Operation</h3>\n<pre><code class=\"language-python\">from sqlalchemy import create_engine\nfrom core.system import AGISystem\nimport asyncio\n\nasync def main():\n    # Initialize system\n    engine = create_engine(\"sqlite:///ravana.db\")\n    agi = AGISystem(engine)\n    \n    try:\n        # Run autonomous loop\n        await agi.run_autonomous_loop()\n    except KeyboardInterrupt:\n        print(\"Shutting down...\")\n        await agi.stop()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>\n<h3>Executing a Single Task</h3>\n<pre><code class=\"language-python\">async def execute_research_task():\n    agi = AGISystem(engine)\n    \n    # Run a specific task\n    await agi.run_single_task(\"Investigate the impact of climate change on coastal cities\")\n    \n    # Get recent events\n    events = await agi.get_recent_events(3600)\n    print(f\"Found {len(events)} recent events\")\n    \n    # Shutdown\n    await agi.stop()\n\nasyncio.run(execute_research_task())\n</code></pre>\n<h3>Using the Multi-modal Service</h3>\n<pre><code class=\"language-python\">async def analyze_media():\n    multi_modal = MultiModalService()\n    \n    # Process an image\n    image_result = await multi_modal.process_image(\"photo.jpg\")\n    \n    # Process an audio file\n    audio_result = await multi_modal.process_audio(\"recording.mp3\")\n    \n    # Cross-modal analysis\n    analysis = await multi_modal.cross_modal_analysis([\n        image_result, \n        audio_result\n    ])\n    \n    # Generate summary\n    summary = await multi_modal.generate_content_summary([\n        image_result, \n        audio_result\n    ])\n    \n    print(summary)\n\nasyncio.run(analyze_media())\n</code></pre>\n<h3>Working with the Memory System</h3>\n<pre><code class=\"language-python\"># Direct client usage\ndef manage_memories():\n    # Extract memories from conversation\n    result = extract_memories(\n        \"I'm planning a trip to Japan next spring\", \n        \"That sounds like an amazing adventure!\"\n    )\n    \n    if result and 'memories' in result:\n        # Save extracted memories\n        save_response = save_memories(result['memories'])\n        \n        # Retrieve relevant memories later\n        relevant = get_relevant_memories(\"travel plans\", top_n=3)\n        for mem in relevant['relevant_memories']:\n            print(f\"Found: {mem['text']}\")\n\nmanage_memories()\n</code></pre>\n<h3>Adding Knowledge</h3>\n<pre><code class=\"language-python\">async def add_research_knowledge():\n    knowledge_service = KnowledgeService(engine)\n    \n    research_content = \"\"\"\n    Recent studies show that neural network pruning can reduce model size \n    by up to 90% with minimal accuracy loss. This technique involves \n    removing redundant weights and neurons from trained models.\n    \"\"\"\n    \n    result = await asyncio.to_thread(\n        knowledge_service.add_knowledge,\n        content=research_content,\n        source=\"research_paper\",\n        category=\"machine_learning\"\n    )\n    \n    if not result.get('duplicate'):\n        print(f\"Added new knowledge with ID: {result['id']}\")\n    else:\n        print(\"Knowledge already existed in database\")\n\nasyncio.run(add_research_knowledge())\n</code></pre>\n<h3>Advanced Memory Operations</h3>\n<pre><code class=\"language-python\">async def advanced_memory_operations():\n    # Initialize multi-modal memory service\n    service = MultiModalMemoryService(\n        database_url=\"postgresql://user:pass@localhost:5432/ravana\"\n    )\n    await service.initialize()\n    \n    # Process different types of memories\n    text_record = await service.process_text_memory(\n        \"I learned about quantum computing today\",\n        tags=[\"learning\", \"science\"]\n    )\n    \n    audio_record = await service.process_audio_memory(\n        \"lecture_recording.mp3\",\n        context=\"Physics lecture on quantum mechanics\"\n    )\n    \n    image_record = await service.process_image_memory(\n        \"quantum_diagram.jpg\",\n        description=\"Diagram explaining quantum entanglement\"\n    )\n    \n    # Advanced search\n    search_request = SearchRequest(\n        query=\"quantum computing\",\n        content_types=[ContentType.TEXT, ContentType.AUDIO, ContentType.IMAGE],\n        search_mode=SearchMode.HYBRID,\n        limit=5\n    )\n    search_response = await service.search_memories(search_request)\n    \n    # Display results\n    for result in search_response.results:\n        print(f\"Found: {result.memory_record.content_text[:100]}... \"\n              f\"(score: {result.similarity_score:.3f})\")\n    \n    # Batch processing\n    batch_request = BatchProcessRequest(\n        file_paths=[\"notes1.txt\", \"notes2.txt\", \"lecture.mp3\"],\n        parallel_processing=True\n    )\n    batch_result = await service.batch_process_files(batch_request)\n    \n    print(f\"Processed {batch_result.successful_count}/{batch_result.total_processed} files\")\n    \n    # Cleanup\n    await service.close()\n\nasyncio.run(advanced_memory_operations())\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n<li><a>services/multi_modal_service.py</a></li>\n<li><a>modules/episodic_memory/client.py</a></li>\n<li><a>modules/episodic_memory/multi_modal_service.py</a></li>\n<li><a>modules/episodic_memory/models.py</a></li>\n</ul>\n<p><strong>Referenced Files in This Document</strong></p>\n<ul>\n<li><a>core/system.py</a> - <em>Updated in recent commit</em></li>\n<li><a>core/actions/action.py</a></li>\n<li><a>services/data_service.py</a></li>\n<li><a>services/knowledge_service.py</a></li>\n<li><a>services/memory_service.py</a></li>\n<li><a>services/multi_modal_service.py</a></li>\n<li><a>modules/episodic_memory/client.py</a> - <em>Enhanced with new features</em></li>\n<li><a>modules/episodic_memory/multi_modal_service.py</a> - <em>Added in recent commit</em></li>\n<li><a>modules/episodic_memory/models.py</a> - <em>Added in recent commit</em></li>\n<li><a>modules/episodic_memory/postgresql_store.py</a> - <em>Added in recent commit</em></li>\n<li><a>modules/episodic_memory/embedding_service.py</a> - <em>Added in recent commit</em></li>\n<li><a>modules/reflection_module.py</a></li>\n</ul>\n"},"docs":[{"slug":"Action System","title":"Action System"},{"slug":"API Reference","title":"API Reference"},{"slug":"Architecture & Design","title":"Architecture & Design"},{"slug":"Configuration","title":"Configuration"},{"slug":"Conversational AI Communication Framework","title":"Conversational AI Communication Framework"},{"slug":"Core System","title":"Core System"},{"slug":"Database Schema","title":"Database Schema"},{"slug":"Decision-Making System","title":"Decision-Making System"},{"slug":"Deployment & Operations","title":"Deployment & Operations"},{"slug":"Development Guide","title":"Development Guide"},{"slug":"Emotional Intelligence","title":"Emotional Intelligence"},{"slug":"Enhanced Snake Agent","title":"Enhanced Snake Agent"},{"slug":"Enhanced Snake Agent Architecture","title":"Enhanced Snake Agent Architecture"},{"slug":"Graceful Shutdown","title":"Graceful Shutdown"},{"slug":"LLM Integration","title":"LLM Integration"},{"slug":"Memory Systems","title":"Memory Systems"},{"slug":"Multi-Modal Memory","title":"Multi-Modal Memory"},{"slug":"Project Overview","title":"Project Overview"},{"slug":"Self-Improvement","title":"Self-Improvement"},{"slug":"Services","title":"Services"},{"slug":"Snake Agent Configuration","title":"Snake Agent Configuration"},{"slug":"Specialized Modules-57f9b30b-b165-48d3-8e89-196940d26190","title":"Specialized Modules"},{"slug":"Specialized Modules","title":"Specialized Modules"}]},"__N_SSG":true}