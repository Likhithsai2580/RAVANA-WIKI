{"pageProps":{"doc":{"slug":"Database Schema","title":"Database Schema","content":"<h1>Database Schema</h1>\n<h2>Update Summary</h2>\n<p><strong>Changes Made</strong></p>\n<ul>\n<li>Added new entity definitions for VeryLongTermMemory, MemoryPattern, MemoryConsolidation, StrategicKnowledge, and related junction tables</li>\n<li>Updated relationships and schema diagram to include new VLTM entities and many-to-many relationships</li>\n<li>Added new section on Very Long-Term Memory System architecture</li>\n<li>Updated indexing strategy to include new VLTM indexes</li>\n<li>Enhanced data lifecycle policies to include VLTM retention policies</li>\n<li>Added new section on strategic knowledge management</li>\n</ul>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#entity-definitions\">Entity Definitions</a></li>\n<li><a href=\"#very-long-term-memory-system\">Very Long-Term Memory System</a></li>\n<li><a href=\"#relationships-and-schema-diagram\">Relationships and Schema Diagram</a></li>\n<li><a href=\"#data-access-patterns-and-orm-usage\">Data Access Patterns and ORM Usage</a></li>\n<li><a href=\"#indexing-strategy-for-performance-critical-queries\">Indexing Strategy for Performance-Critical Queries</a></li>\n<li><a href=\"#data-lifecycle-policies-and-retention\">Data Lifecycle Policies and Retention</a></li>\n<li><a href=\"#data-security-encryption-and-backup-procedures\">Data Security, Encryption, and Backup Procedures</a></li>\n<li><a href=\"#migration-strategies-for-schema-evolution\">Migration Strategies for Schema Evolution</a></li>\n<li><a href=\"#conclusion\">Conclusion</a></li>\n</ol>\n<h2>Introduction</h2>\n<p>This document provides comprehensive documentation for the database schema used in the RAVANA AGI system. The schema is designed to support an autonomous artificial general intelligence system that processes information, makes decisions, reflects on its behavior, and evolves over time. The database stores various types of operational, emotional, and cognitive data that enable the system to maintain context, learn from experience, and generate intelligent responses. This documentation details all entities, their relationships, access patterns, performance considerations, and lifecycle management policies.</p>\n<h2>Entity Definitions</h2>\n<p>The database schema consists of several key entities that capture different aspects of the AGI's operation and cognition. Each entity is defined using SQLModel, which provides a Pythonic interface for database interactions.</p>\n<h3>Article</h3>\n<p>Stores information about news articles and other content sources that the system monitors.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the article</li>\n<li><code>title</code>: str - Title of the article</li>\n<li><code>link</code>: str - URL of the article</li>\n<li><code>published</code>: str - Publication timestamp in ISO format</li>\n<li><code>source</code>: str - Source of the article (e.g., CNN, BBC)</li>\n<li><code>fetched_at</code>: str - Timestamp when the article was fetched by the system</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n<li>Uniqueness is enforced at the application level based on the <code>link</code> field to prevent duplicate articles</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h3>Event</h3>\n<p>Represents significant events detected by the system through analysis of articles and other inputs.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the event</li>\n<li><code>timestamp</code>: str - Timestamp of the event in ISO format</li>\n<li><code>description</code>: str - Natural language description of the event</li>\n<li><code>keywords</code>: str - Comma-separated keywords associated with the event</li>\n<li><code>cluster_id</code>: int - Identifier for the cluster to which this event belongs</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h3>Summary</h3>\n<p>Stores compressed knowledge and summaries generated by the system, serving as a mechanism for knowledge retention and deduplication.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the summary</li>\n<li><code>timestamp</code>: str - Creation timestamp in ISO format</li>\n<li><code>summary_text</code>: str - The actual summary content</li>\n<li><code>source</code>: str | None = Field(default=\"unknown\") - Source of the summary (e.g., system, user)</li>\n<li><code>category</code>: str | None = Field(default=\"misc\") - Category of the summary (e.g., compression, reflection)</li>\n<li><code>content_hash</code>: str | None = Field(default=None) - SHA-256 hash of the summary text for deduplication</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n<li>The <code>content_hash</code> field enables deduplication by allowing the system to check if a similar summary already exists</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h3>ActionLog</h3>\n<p>Records all actions performed by the AGI system, providing an audit trail of its operations.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the log entry</li>\n<li><code>timestamp</code>: str - Timestamp of the action in ISO format</li>\n<li><code>action_name</code>: str - Name of the action performed</li>\n<li><code>params</code>: str - JSON string containing the parameters passed to the action</li>\n<li><code>status</code>: str - Status of the action ('success' or 'failure')</li>\n<li><code>result</code>: str - JSON string containing the result of the action</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h3>MoodLog</h3>\n<p>Captures the emotional state of the AGI system at specific points in time.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the mood log entry</li>\n<li><code>timestamp</code>: str - Timestamp of the mood recording in ISO format</li>\n<li><code>mood_vector</code>: str - JSON string representing the mood vector (a multidimensional representation of emotional state)</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h3>SituationLog</h3>\n<p>Records situations generated by the system for decision-making and reflection purposes.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the situation log</li>\n<li><code>timestamp</code>: str - Timestamp of the situation creation in ISO format</li>\n<li><code>situation_type</code>: str - Type of situation (e.g., curiosity, reflection)</li>\n<li><code>prompt</code>: str - The prompt that generated the situation</li>\n<li><code>context</code>: str - JSON string containing additional context for the situation</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h3>DecisionLog</h3>\n<p>Stores decisions made by the AGI system in response to specific situations.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the decision log</li>\n<li><code>timestamp</code>: str - Timestamp of the decision in ISO format</li>\n<li><code>situation_id</code>: int | None = Field(default=None, foreign_key=\"situationlog.id\") - Foreign key referencing the situation that prompted the decision</li>\n<li><code>raw_response</code>: str - The raw response from the decision-making process</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n<li>Foreign key relationship with <code>SituationLog</code> on the <code>situation_id</code> field</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h3>ExperimentLog</h3>\n<p>Records experiments conducted by the AGI system to test hypotheses or explore new ideas.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>id</code>: int | None = Field(default=None, primary_key=True) - Unique identifier for the experiment log</li>\n<li><code>timestamp</code>: str - Timestamp of the experiment in ISO format</li>\n<li><code>hypothesis</code>: str - The hypothesis being tested</li>\n<li><code>results</code>: str - JSON string containing the results of the experiment</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>id</code></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n</ul>\n<h2>Very Long-Term Memory System</h2>\n<p>The Very Long-Term Memory (VLTM) system has been enhanced with new entities and relationships to support advanced knowledge management and strategic reasoning.</p>\n<h3>VeryLongTermMemory</h3>\n<p>Core very long-term memory record that stores compressed cognitive content.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>memory_id</code>: str - Primary key, UUID identifier for the memory</li>\n<li><code>memory_type</code>: MemoryType - Enum indicating the type of memory (strategic_knowledge, architectural_insight, etc.)</li>\n<li><code>created_at</code>: datetime - Timestamp when the memory was created</li>\n<li><code>last_accessed</code>: datetime - Timestamp of last access</li>\n<li><code>promoted_at</code>: datetime - Timestamp when memory was promoted to long-term storage</li>\n<li><code>access_count</code>: int - Number of times the memory has been accessed</li>\n<li><code>importance_score</code>: float - Calculated importance score (0.0-1.0)</li>\n<li><code>strategic_value</code>: float - Strategic value for long-term planning (0.0-1.0)</li>\n<li><code>compressed_content</code>: str - JSON string of compressed memory data</li>\n<li><code>metadata_info</code>: str - JSON string of metadata</li>\n<li><code>source_session</code>: str - Identifier of the session that created the memory</li>\n<li><code>related_memories</code>: str - JSON array of related memory IDs</li>\n<li><code>retention_category</code>: str - Retention policy category</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>memory_id</code></li>\n<li>Importance score and strategic value constrained between 0.0 and 1.0</li>\n<li>JSON fields validated for proper format</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n</ul>\n<h3>MemoryPattern</h3>\n<p>Patterns extracted from memories through analysis of memory content and relationships.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>pattern_id</code>: str - Primary key, UUID identifier for the pattern</li>\n<li><code>pattern_type</code>: PatternType - Enum indicating the type of pattern (temporal, causal, behavioral, etc.)</li>\n<li><code>pattern_description</code>: str - Natural language description of the pattern</li>\n<li><code>confidence_score</code>: float - Confidence in pattern validity (0.0-1.0)</li>\n<li><code>pattern_data</code>: str - JSON string of pattern-specific data</li>\n<li><code>discovered_at</code>: datetime - Timestamp when the pattern was discovered</li>\n<li><code>supporting_memories</code>: str - JSON array of memory IDs that support this pattern</li>\n<li><code>validation_count</code>: int - Number of times the pattern has been validated</li>\n<li><code>last_validated</code>: Optional[datetime] - Timestamp of last validation</li>\n<li><code>source_memory_id</code>: Optional[str] - Foreign key to the source memory</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>pattern_id</code></li>\n<li>Confidence score constrained between 0.0 and 1.0</li>\n<li>JSON fields validated for proper format</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n</ul>\n<h3>MemoryConsolidation</h3>\n<p>Records of memory consolidation processes that optimize storage and extract higher-level knowledge.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>consolidation_id</code>: str - Primary key, UUID identifier for the consolidation</li>\n<li><code>consolidation_date</code>: datetime - Timestamp of the consolidation process</li>\n<li><code>consolidation_type</code>: ConsolidationType - Enum indicating the type (daily, weekly, monthly, etc.)</li>\n<li><code>memories_processed</code>: int - Number of memories processed in this consolidation</li>\n<li><code>patterns_extracted</code>: int - Number of patterns extracted</li>\n<li><code>compression_ratio</code>: float - Ratio of original size to compressed size</li>\n<li><code>consolidation_results</code>: str - JSON string of consolidation results</li>\n<li><code>processing_time_seconds</code>: float - Time taken to process the consolidation</li>\n<li><code>success</code>: bool - Whether the consolidation was successful</li>\n<li><code>error_message</code>: Optional[str] - Error message if consolidation failed</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>consolidation_id</code></li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n</ul>\n<h3>StrategicKnowledge</h3>\n<p>High-level strategic knowledge derived from patterns and used for long-term planning.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>knowledge_id</code>: str - Primary key, UUID identifier for the knowledge</li>\n<li><code>knowledge_domain</code>: str - Domain of the knowledge (e.g., architecture, performance, learning)</li>\n<li><code>knowledge_summary</code>: str - Natural language summary of the knowledge</li>\n<li><code>confidence_level</code>: float - Confidence in the knowledge (0.0-1.0)</li>\n<li><code>last_updated</code>: datetime - Timestamp of last update</li>\n<li><code>source_patterns</code>: str - JSON array of pattern IDs that contributed to this knowledge</li>\n<li><code>knowledge_structure</code>: str - JSON string of structured knowledge representation</li>\n<li><code>validation_score</code>: float - Score based on validation attempts (0.0-1.0)</li>\n<li><code>application_count</code>: int - Number of times this knowledge has been applied</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>knowledge_id</code></li>\n<li>Confidence level and validation score constrained between 0.0 and 1.0</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n</ul>\n<h3>ConsolidationPattern</h3>\n<p>Junction table linking memory consolidations and patterns, enabling many-to-many relationships.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>consolidation_id</code>: str - Foreign key to memory_consolidations table, part of primary key</li>\n<li><code>pattern_id</code>: str - Foreign key to memory_patterns table, part of primary key</li>\n<li><code>extraction_confidence</code>: float - Confidence in the pattern extraction during consolidation</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Composite primary key on <code>consolidation_id</code> and <code>pattern_id</code></li>\n<li>Foreign key relationships to memory_consolidations and memory_patterns tables</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n</ul>\n<h3>PatternStrategicKnowledge</h3>\n<p>Junction table linking memory patterns and strategic knowledge, enabling many-to-many relationships.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>pattern_id</code>: str - Foreign key to memory_patterns table, part of primary key</li>\n<li><code>knowledge_id</code>: str - Foreign key to strategic_knowledge table, part of primary key</li>\n<li><code>contribution_weight</code>: float - Weight of the pattern's contribution to the strategic knowledge</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Composite primary key on <code>pattern_id</code> and <code>knowledge_id</code></li>\n<li>Foreign key relationships to memory_patterns and strategic_knowledge tables</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n</ul>\n<h3>ConsolidationMetrics</h3>\n<p>Performance metrics for consolidation processes.</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><code>metric_id</code>: str - Primary key, UUID identifier for the metric</li>\n<li><code>consolidation_id</code>: str - Foreign key to memory_consolidations table</li>\n<li><code>metric_name</code>: str - Name of the metric</li>\n<li><code>metric_value</code>: float - Value of the metric</li>\n<li><code>metric_unit</code>: str - Unit of measurement</li>\n<li><code>timestamp</code>: datetime - Timestamp when the metric was recorded</li>\n</ul>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>Primary key on <code>metric_id</code></li>\n<li>Foreign key relationship to memory_consolidations table</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n</ul>\n<h2>Relationships and Schema Diagram</h2>\n<p>The database schema entities are related through foreign key relationships and conceptual associations that reflect the AGI system's cognitive processes.</p>\n<p>``mermaid\nerDiagram\nSITUATIONLOG {\nint id PK\nstring timestamp\nstring situation_type\nstring prompt\nstring context\n}\nDECISIONLOG {\nint id PK\nstring timestamp\nint situation_id FK\nstring raw_response\n}\nARTICLE {\nint id PK\nstring title\nstring link\nstring published\nstring source\nstring fetched_at\n}\nEVENT {\nint id PK\nstring timestamp\nstring description\nstring keywords\nint cluster_id\n}\nSUMMARY {\nint id PK\nstring timestamp\nstring summary_text\nstring source\nstring category\nstring content_hash\n}\nACTIONLOG {\nint id PK\nstring timestamp\nstring action_name\nstring params\nstring status\nstring result\n}\nMOODLOG {\nint id PK\nstring timestamp\nstring mood_vector\n}\nEXPERIMENTLOG {\nint id PK\nstring timestamp\nstring hypothesis\nstring results\n}\nVERYLONGTERMMEMORY {\nstring memory_id PK\nstring memory_type\ndatetime created_at\ndatetime last_accessed\nfloat importance_score\nfloat strategic_value\nstring compressed_content\nstring metadata_info\n}\nMEMORYPATTERN {\nstring pattern_id PK\nstring pattern_type\nstring pattern_description\nfloat confidence_score\ndatetime discovered_at\nstring source_memory_id FK\n}\nMEMORYCONSOLIDATION {\nstring consolidation_id PK\ndatetime consolidation_date\nstring consolidation_type\nint memories_processed\nint patterns_extracted\nfloat compression_ratio\n}\nSTRATEGICKNOWLEDGE {\nstring knowledge_id PK\nstring knowledge_domain\nstring knowledge_summary\nfloat confidence_level\ndatetime last_updated\nint application_count\n}\nCONSOLIDATIONPATTERN {\nstring consolidation_id PK, FK\nstring pattern_id PK, FK\nfloat extraction_confidence\n}\nPATTERNSTRATEGICKNOWLEDGE {\nstring pattern_id PK, FK\nstring knowledge_id PK, FK\nfloat contribution_weight\n}\nSITUATIONLOG ||--o{ DECISIONLOG : \"has\"\nARTICLE ||--o{ EVENT : \"triggers\"\nSUMMARY ||--o{ EXPERIMENTLOG : \"informs\"\nACTIONLOG ||--o{ SITUATIONLOG : \"generates\"\nMOODLOG ||--o{ SITUATIONLOG : \"influences\"\nVERYLONGTERMMEMORY ||--o{ MEMORYPATTERN : \"contains\"\nMEMORYPATTERN ||--o{ MEMORYCONSOLIDATION : \"extracted_in\"\nMEMORYPATTERN ||--o{ STRATEGICKNOWLEDGE : \"contributes_to\"\nMEMORYCONSOLIDATION ||--o{ CONSOLIDATIONPATTERN : \"has\"\nCONSOLIDATIONPATTERN ||--o{ MEMORYPATTERN : \"links\"\nMEMORYPATTERN ||--o{ PATTERNSTRATEGICKNOWLEDGE : \"links\"\nPATTERNSTRATEGICKNOWLEDGE ||--o{ STRATEGICKNOWLEDGE : \"links\"</p>\n<pre><code>\n**Diagram sources**\n- [core/vltm_data_models.py](file://c:\\Users\\ASUS\\Documents\\GitHub\\RAVANA\\core\\vltm_data_models.py#L56-L198)\n- [database/vltm_schema.sql](file://c:\\Users\\ASUS\\Documents\\GitHub\\RAVANA\\database\\vltm_schema.sql#L96-L125)\n\n**Section sources**\n- [core/vltm_data_models.py](file://c:\\Users\\ASUS\\Documents\\GitHub\\RAVANA\\core\\vltm_data_models.py#L56-L198)\n- [database/vltm_schema.sql](file://c:\\Users\\ASUS\\Documents\\GitHub\\RAVANA\\database\\vltm_schema.sql#L67-L125)\n\n## Data Access Patterns and ORM Usage\nThe system uses SQLModel as an ORM (Object-Relational Mapper) to interact with the database, providing a clean, Pythonic interface for data operations.\n\n### ORM Configuration\nThe database engine is configured in `engine.py` using SQLAlchemy's create_engine function with the database URL obtained from the configuration system.\n\n```python\nfrom sqlmodel import create_engine, SQLModel\nfrom core.config import Config\n\nengine = create_engine(Config.DATABASE_URL, echo=True)\n\ndef create_db_and_tables():\n    SQLModel.metadata.create_all(engine)\n</code></pre>\n<p>The <code>create_db_and_tables()</code> function initializes the database schema by creating all tables defined in the SQLModel classes.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/engine.py</a></li>\n</ul>\n<h3>Transaction Boundaries</h3>\n<p>Data access follows a consistent pattern using context managers to ensure proper transaction boundaries and resource cleanup. The <code>DataService</code> class in <code>data_service.py</code> implements methods for saving various types of data with proper transaction management.</p>\n<pre><code class=\"language-python\">def save_action_log(self, action_name: str, params: dict, status: str, result: any):\n    \"\"\"Saves a record of an executed action to the database.\"\"\"\n    with Session(self.engine) as session:\n        action_log = ActionLog(\n            timestamp=datetime.utcnow().isoformat(),\n            action_name=action_name,\n            params=json.dumps(params),\n            status=status,\n            result=json.dumps(result)\n        )\n        session.add(action_log)\n        session.commit()\n</code></pre>\n<p>Key characteristics of the data access pattern:</p>\n<ul>\n<li>Each operation uses a context manager (<code>with Session(...) as session</code>) to ensure the session is properly closed</li>\n<li>Transactions are committed explicitly with <code>session.commit()</code></li>\n<li>JSON serialization is used for complex data structures stored in text fields</li>\n<li>Operations are atomic and follow the principle of least privilege</li>\n</ul>\n<h3>Data Service Implementation</h3>\n<p>The <code>DataService</code> class provides a service layer interface for database operations, abstracting the underlying ORM details from the rest of the application.</p>\n<p><strong>Key methods:</strong></p>\n<ul>\n<li><code>fetch_and_save_articles()</code>: Fetches articles from configured RSS feeds and saves new ones to the database</li>\n<li><code>detect_and_save_events()</code>: Analyzes articles to detect significant events and saves them</li>\n<li><code>save_action_log()</code>: Records system actions</li>\n<li><code>save_mood_log()</code>: Records the system's emotional state</li>\n<li><code>save_situation_log()</code>: Records generated situations</li>\n<li><code>save_decision_log()</code>: Records decisions made by the system</li>\n<li><code>save_experiment_log()</code>: Records experiments and their results</li>\n</ul>\n<p>The service layer ensures consistent data handling and provides a single point of control for database interactions.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>services/data_service.py</a></li>\n</ul>\n<h2>Indexing Strategy for Performance-Critical Queries</h2>\n<p>The system employs a multi-layered approach to optimize performance-critical queries, particularly for memory retrieval operations.</p>\n<h3>ChromaDB for Semantic Memory Retrieval</h3>\n<p>For performance-critical memory retrieval operations, the system uses ChromaDB, an embedding database optimized for semantic search. This is implemented in the <code>episodic_memory</code> module.</p>\n<p><strong>Key features:</strong></p>\n<ul>\n<li>Uses sentence-transformers with the 'all-MiniLM-L6-v2' model to generate 384-dimensional embeddings</li>\n<li>Stores embeddings in a persistent ChromaDB collection with automatic embedding generation</li>\n<li>Supports similarity-based queries for retrieving relevant memories</li>\n</ul>\n<pre><code class=\"language-python\">chroma_collection = chroma_client.get_or_create_collection(\n    name=CHROMA_COLLECTION,\n    embedding_function=sentence_transformer_ef\n)\n</code></pre>\n<p><strong>Query process:</strong></p>\n<ol>\n<li>A query text is converted to an embedding vector</li>\n<li>The system finds the nearest neighbors in the embedding space</li>\n<li>Results are returned based on cosine similarity</li>\n<li>A similarity threshold filters out irrelevant results</li>\n</ol>\n<p>The <code>get_relevant_memories_api</code> function implements this retrieval pattern:</p>\n<pre><code class=\"language-python\">def get_relevant_memories_api(request: QueryRequest):\n    results = chroma_collection.query(\n        query_texts=[request.query_text],\n        n_results=request.top_n\n    )\n    \n    # Convert distance to similarity and filter by threshold\n    similarity = 1 - dist\n    if similarity >= request.similarity_threshold:\n        # Include in results\n</code></pre>\n<h3>VLTM Database Indexing</h3>\n<p>The VLTM system implements comprehensive indexing strategies to optimize query performance for very long-term memory operations.</p>\n<p><strong>Index types:</strong></p>\n<ul>\n<li><strong>B-tree indexes</strong>: On frequently queried scalar fields like timestamps, memory types, and confidence scores</li>\n<li><strong>GIN indexes</strong>: On JSONB fields for efficient querying of structured data</li>\n<li><strong>Text search indexes</strong>: Using tsvector for full-text search capabilities</li>\n<li><strong>Composite indexes</strong>: On frequently queried field combinations</li>\n</ul>\n<p><strong>Key indexes:</strong></p>\n<ul>\n<li><code>idx_vltm_memory_type</code>: On memory_type for filtering by memory category</li>\n<li><code>idx_vltm_created_at</code>: On created_at for time-based queries</li>\n<li><code>idx_vltm_importance_score</code>: On importance_score for prioritizing important memories</li>\n<li><code>idx_patterns_type</code>: On pattern_type for filtering by pattern category</li>\n<li><code>idx_strategic_domain</code>: On knowledge_domain for domain-specific queries</li>\n<li><code>idx_vltm_metadata_gin</code>: GIN index on metadata for efficient JSON querying</li>\n<li><code>idx_patterns_description_text</code>: Text search index on pattern descriptions</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>database/vltm_schema.sql</a></li>\n<li><a>modules/episodic_memory/memory.py</a></li>\n<li><a>services/memory_service.py</a></li>\n</ul>\n<h2>Data Lifecycle Policies and Retention</h2>\n<p>The system implements automated data lifecycle management through background tasks that handle retention, consolidation, and archival.</p>\n<h3>Knowledge Compression</h3>\n<p>The system runs a periodic knowledge compression task that summarizes recent interactions and creates higher-level abstractions.</p>\n<p><strong>Configuration:</strong></p>\n<ul>\n<li>Frequency: Every 24 hours (86,400 seconds)</li>\n<li>Triggered by: <code>knowledge_compression_task()</code> in the main system loop</li>\n</ul>\n<p><strong>Process:</strong></p>\n<ol>\n<li>Retrieves recent summaries from the database</li>\n<li>Uses an LLM to compress and synthesize the information</li>\n<li>Creates new <code>Summary</code> records with category \"compression\"</li>\n<li>Uses content hashing to prevent duplication</li>\n</ol>\n<pre><code class=\"language-python\">async def knowledge_compression_task(self):\n    \"\"\"Background task to compress knowledge every 24 hours.\"\"\"\n    while not self._shutdown.is_set():\n        try:\n            summary = await asyncio.to_thread(self.knowledge_service.compress_and_save_knowledge)\n            logger.info(f\"Compressed and saved knowledge summary.\")\n        except Exception as e:\n            logger.error(f\"Error in knowledge compression: {e}\")\n\n        try:\n            await asyncio.sleep(86400)\n        except asyncio.CancelledError:\n            break\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h3>Memory Consolidation</h3>\n<p>The system performs periodic memory consolidation to optimize storage and retrieval efficiency.</p>\n<p><strong>Configuration:</strong></p>\n<ul>\n<li>Frequency: Every 6 hours (21,600 seconds)</li>\n<li>Triggered by: <code>memory_consolidation_task()</code> in the main system loop</li>\n</ul>\n<p><strong>Process:</strong></p>\n<ol>\n<li>Selects a batch of memories for consolidation</li>\n<li>Uses an LLM to analyze, merge, deduplicate, and generalize memories</li>\n<li>Creates consolidated memories with type 'long-term-consolidated'</li>\n<li>Deletes the original, redundant memories</li>\n</ol>\n<p>The consolidation process follows these rules:</p>\n<ul>\n<li>Merge related memories into comprehensive statements</li>\n<li>Remove duplicates, keeping the most detailed version</li>\n<li>Generalize specific facts into broader categories</li>\n<li>Never lose critical information</li>\n<li>Never merge unrelated facts</li>\n</ul>\n<pre><code class=\"language-python\">async def memory_consolidation_task(self):\n    \"\"\"Periodically consolidates memories to optimize retrieval and relevance.\"\"\"\n    while not self._shutdown.is_set():\n        try:\n            logger.info(\"Starting memory consolidation...\")\n            consolidation_result = await self.memory_service.consolidate_memories()\n            logger.info(f\"Memory consolidation finished. Report: {consolidation_result}\")\n        except Exception as e:\n            logger.error(f\"Error during memory consolidation: {e}\", exc_info=True)\n\n        try:\n            await asyncio.sleep(21600)\n        except asyncio.CancelledError:\n            break\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/system.py</a></li>\n<li><a>modules/episodic_memory/memory.py</a></li>\n</ul>\n<h3>VLTM Retention Policies</h3>\n<p>The Very Long-Term Memory system implements configurable retention policies based on memory type and importance.</p>\n<p><strong>Policy configuration:</strong></p>\n<ul>\n<li><strong>Strategic knowledge</strong>: Permanent retention, compression after 90 days</li>\n<li><strong>Critical failures</strong>: Permanent retention, compression after 30 days</li>\n<li><strong>Successful improvements</strong>: 2-year retention, compression after 180 days</li>\n<li><strong>Code patterns</strong>: 1-year retention, compression after 90 days</li>\n</ul>\n<p><strong>Retention rules:</strong></p>\n<ul>\n<li>Memories are automatically compressed based on age and type</li>\n<li>High-importance memories are retained permanently</li>\n<li>Low-importance memories may be archived or deleted based on policy</li>\n<li>Compression reduces storage footprint while preserving essential information</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/vltm_data_models.py</a></li>\n<li><a>database/vltm_schema.sql</a></li>\n</ul>\n<h2>Data Security, Encryption, and Backup Procedures</h2>\n<p>The system's approach to data security, encryption, and backup is primarily defined by its configuration and deployment environment.</p>\n<h3>Database Configuration</h3>\n<p>The database URL is configured through environment variables, allowing for flexible deployment configurations.</p>\n<pre><code class=\"language-python\">class Config:\n    DATABASE_URL = os.environ.get(\"DATABASE_URL\", \"sqlite:///ravana_agi.db\")\n</code></pre>\n<p><strong>Default configuration:</strong></p>\n<ul>\n<li>SQLite database file named <code>ravana_agi.db</code></li>\n<li>Stored in the working directory</li>\n<li>No built-in encryption at rest</li>\n</ul>\n<p><strong>Security implications:</strong></p>\n<ul>\n<li>The default SQLite configuration provides no encryption for data at rest</li>\n<li>Production deployments should use environment variables to specify a database URL with appropriate security features</li>\n<li>Supported databases include PostgreSQL, MySQL, and others that can provide encryption at rest</li>\n</ul>\n<h3>Data Protection Measures</h3>\n<p>The system implements several data protection measures:</p>\n<p><strong>Deduplication with hashing:</strong></p>\n<ul>\n<li>Uses SHA-256 hashing to identify duplicate content</li>\n<li>Hashes are stored in the <code>content_hash</code> field of the <code>Summary</code> table</li>\n<li>Prevents redundant storage of identical information</li>\n</ul>\n<pre><code class=\"language-python\">content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()\n</code></pre>\n<p><strong>No explicit backup procedures:</strong></p>\n<ul>\n<li>The codebase does not contain explicit backup procedures</li>\n<li>Backup strategy would depend on the underlying database system and deployment environment</li>\n<li>For SQLite, backup would involve copying the database file</li>\n<li>For server-based databases, standard database backup procedures would apply</li>\n</ul>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>core/config.py</a></li>\n<li><a>services/knowledge_service.py</a></li>\n</ul>\n<h2>Migration Strategies for Schema Evolution</h2>\n<p>The system's architecture suggests several approaches for handling schema evolution, though explicit migration tools are not implemented in the current codebase.</p>\n<h3>Current State</h3>\n<p>The system uses SQLModel's <code>create_all()</code> method to create tables, which only creates missing tables but does not handle schema changes to existing tables.</p>\n<pre><code class=\"language-python\">def create_db_and_tables():\n    SQLModel.metadata.create_all(engine)\n</code></pre>\n<p>This approach has limitations:</p>\n<ul>\n<li>Does not modify existing columns</li>\n<li>Does not add constraints to existing tables</li>\n<li>Does not handle data migration between schema versions</li>\n<li>Risk of data loss or corruption during schema changes</li>\n</ul>\n<h3>Recommended Migration Strategy</h3>\n<p>For production use, the following migration strategy is recommended:</p>\n<p><strong>1. Use Alembic for database migrations:</strong></p>\n<ul>\n<li>Alembic is the standard migration tool for SQLAlchemy (which SQLModel is built upon)</li>\n<li>Provides versioned migration scripts</li>\n<li>Supports both automated and manual migration generation</li>\n<li>Handles forward and backward migrations</li>\n</ul>\n<p><strong>2. Migration process:</strong></p>\n<ul>\n<li>Create a new migration script for each schema change</li>\n<li>Include data migration logic when necessary</li>\n<li>Test migrations on a copy of production data</li>\n<li>Apply migrations in a controlled manner</li>\n</ul>\n<p><strong>3. Example migration workflow:</strong></p>\n<pre><code class=\"language-bash\"># Generate migration\nalembic revision --autogenerate -m \"Add mood intensity field\"\n\n# Review and edit migration script\n# Apply migration\nalembic upgrade head\n</code></pre>\n<p><strong>4. Zero-downtime considerations:</strong></p>\n<ul>\n<li>Design schema changes to be backward compatible</li>\n<li>Use additive changes when possible (adding columns, not removing)</li>\n<li>Implement feature flags for new functionality</li>\n<li>Deploy schema changes separately from application changes when possible</li>\n</ul>\n<p><strong>5. Data migration best practices:</strong></p>\n<ul>\n<li>Always backup data before migrations</li>\n<li>Test migrations on representative data sets</li>\n<li>Monitor application behavior after migrations</li>\n<li>Have a rollback plan for each migration</li>\n</ul>\n<p>While the current codebase does not implement a formal migration system, adopting Alembic or a similar tool would provide a robust solution for schema evolution.</p>\n<h2>Conclusion</h2>\n<p>The RAVANA AGI system employs a comprehensive database schema designed to support an autonomous artificial intelligence that can process information, make decisions, and evolve over time. The schema captures various aspects of the system's operation, including external inputs (articles), internal states (mood logs), cognitive processes (situations, decisions), and learning mechanisms (summaries, experiments).</p>\n<p>Key strengths of the current implementation include:</p>\n<ul>\n<li>Clean separation of concerns through well-defined entities</li>\n<li>Effective use of JSON fields for flexible data storage</li>\n<li>Integration of semantic search through ChromaDB for performance-critical memory retrieval</li>\n<li>Automated data lifecycle management through periodic compression and consolidation</li>\n<li>Enhanced Very Long-Term Memory system with many-to-many relationships between consolidations, patterns, and strategic knowledge</li>\n</ul>\n<p>Areas for improvement include:</p>\n<ul>\n<li>Implementing a formal database migration system like Alembic</li>\n<li>Enhancing data security with encryption at rest</li>\n<li>Establishing explicit backup procedures</li>\n<li>Potentially adding database indexes on frequently queried fields</li>\n</ul>\n<p>The system's architecture demonstrates a sophisticated approach to AGI data management, balancing structured storage with flexible, semantic retrieval mechanisms to support intelligent behavior.</p>\n<p><strong>Referenced Files in This Document</strong></p>\n<ul>\n<li><a>database/models.py</a></li>\n<li><a>database/engine.py</a></li>\n<li><a>services/data_service.py</a></li>\n<li><a>services/knowledge_service.py</a></li>\n<li><a>core/config.py</a></li>\n<li><a>modules/episodic_memory/memory.py</a></li>\n<li><a>services/memory_service.py</a></li>\n<li><a>modules/knowledge_compression/compressed_memory.py</a></li>\n<li><a>core/vltm_data_models.py</a> - <em>Updated in recent commit</em></li>\n<li><a>database/vltm_schema.sql</a> - <em>Updated in recent commit</em></li>\n</ul>\n"},"docs":[{"slug":"Action System","title":"Action System"},{"slug":"API Reference","title":"API Reference"},{"slug":"Architecture & Design","title":"Architecture & Design"},{"slug":"Configuration","title":"Configuration"},{"slug":"Conversational AI Communication Framework","title":"Conversational AI Communication Framework"},{"slug":"Core System","title":"Core System"},{"slug":"Database Schema","title":"Database Schema"},{"slug":"Decision-Making System","title":"Decision-Making System"},{"slug":"Deployment & Operations","title":"Deployment & Operations"},{"slug":"Development Guide","title":"Development Guide"},{"slug":"Emotional Intelligence","title":"Emotional Intelligence"},{"slug":"Enhanced Snake Agent","title":"Enhanced Snake Agent"},{"slug":"Enhanced Snake Agent Architecture","title":"Enhanced Snake Agent Architecture"},{"slug":"Graceful Shutdown","title":"Graceful Shutdown"},{"slug":"LLM Integration","title":"LLM Integration"},{"slug":"Memory Systems","title":"Memory Systems"},{"slug":"Multi-Modal Memory","title":"Multi-Modal Memory"},{"slug":"Project Overview","title":"Project Overview"},{"slug":"Self-Improvement","title":"Self-Improvement"},{"slug":"Services","title":"Services"},{"slug":"Snake Agent Configuration","title":"Snake Agent Configuration"},{"slug":"Specialized Modules-57f9b30b-b165-48d3-8e89-196940d26190","title":"Specialized Modules"},{"slug":"Specialized Modules","title":"Specialized Modules"}]},"__N_SSG":true}