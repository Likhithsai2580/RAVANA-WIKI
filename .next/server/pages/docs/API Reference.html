<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta charSet="utf-8"/><title>API Reference<!-- --> - RAVANA AGI Documentation</title><meta name="description" content="Documentation for API Reference"/><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/aa7d986e9c238cc1.css" as="style"/><link rel="stylesheet" href="/_next/static/css/aa7d986e9c238cc1.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js" defer="" data-nscript="beforeInteractive"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js" defer="" data-nscript="beforeInteractive"></script><script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.0/dist/mermaid.min.js" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-eb143115b8bf2786.js" defer=""></script><script src="/_next/static/chunks/pages/_app-a41459f5c0b49356.js" defer=""></script><script src="/_next/static/chunks/664-d254d21a6fe56bff.js" defer=""></script><script src="/_next/static/chunks/pages/docs/%5Bslug%5D-37d587d3c8e56222.js" defer=""></script><script src="/_next/static/QHWQNiRZOuW15nbk5-ngt/_buildManifest.js" defer=""></script><script src="/_next/static/QHWQNiRZOuW15nbk5-ngt/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="min-h-screen flex flex-col"><div class="min-h-screen flex flex-col"><header class="bg-wiki-blue text-white p-4 shadow-md"><div class="container mx-auto flex justify-between items-center"><h1 class="text-2xl font-bold">RAVANA AGI Documentation</h1><nav><ul class="flex space-x-4"><li><a class="hover:underline" href="/">Home</a></li></ul></nav></div></header><div class="flex-grow container mx-auto p-4 flex flex-col md:flex-row gap-6"><div class="w-full md:w-64 flex-shrink-0"><nav class="w-full md:w-64 flex-shrink-0"><div class="bg-white rounded-lg shadow p-4 sticky top-4"><h3 class="font-bold text-lg mb-3">Documentation</h3><ul class="space-y-1"><li class="mb-3"><div class="font-semibold text-gray-700">A</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Action%20System">Action System</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 bg-wiki-blue text-white" href="/docs/API%20Reference">API Reference</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Architecture%20&amp;%20Design">Architecture &amp; Design</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">C</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Configuration">Configuration</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Conversational%20AI%20Communication%20Framework">Conversational AI Communication Framework</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Core%20System">Core System</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">D</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Database%20Schema">Database Schema</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Decision-Making%20System">Decision-Making System</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Deployment%20&amp;%20Operations">Deployment &amp; Operations</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Development%20Guide">Development Guide</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">E</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Emotional%20Intelligence">Emotional Intelligence</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Enhanced%20Snake%20Agent">Enhanced Snake Agent</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Enhanced%20Snake%20Agent%20Architecture">Enhanced Snake Agent Architecture</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">G</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Graceful%20Shutdown">Graceful Shutdown</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">L</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/LLM%20Integration">LLM Integration</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">M</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Memory%20Systems">Memory Systems</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Multi-Modal%20Memory">Multi-Modal Memory</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">P</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Project%20Overview">Project Overview</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">S</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Self-Improvement">Self-Improvement</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Services">Services</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Snake%20Agent%20Configuration">Snake Agent Configuration</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Specialized%20Modules-57f9b30b-b165-48d3-8e89-196940d26190">Specialized Modules</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Specialized%20Modules">Specialized Modules</a></li></ul></li></ul></div></nav></div><main class="flex-grow"><nav class="mb-4 text-sm"><ol class="list-none p-0 inline-flex"><li class="flex items-center"><a class="text-wiki-blue hover:underline" href="/">Home</a><svg class="fill-current w-3 h-3 mx-3" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"></path></svg></li><li class="flex items-center"><span class="text-gray-500">API Reference</span></li></ol></nav><div class="flex flex-col md:flex-row gap-6"><article class="prose max-w-none bg-white p-6 rounded-lg shadow flex-grow"><h1>API Reference</h1><div><h1>API Reference</h1>
<h2>Update Summary</h2>
<p><strong>Changes Made</strong></p>
<ul>
<li>Updated Episodic Memory Client section with new methods for audio/image upload, advanced search, and batch processing</li>
<li>Added new section for Multi-modal Memory Service with comprehensive API documentation</li>
<li>Added new section for Memory Models with detailed data structure documentation</li>
<li>Added new sections for PostgreSQL Store and Embedding Service implementations</li>
<li>Updated Table of Contents to reflect new sections and organization</li>
<li>Enhanced source tracking with specific file references and annotations</li>
</ul>
<h2>Table of Contents</h2>
<ol>
<li><a href="#agisystem-class">AGISystem Class</a></li>
<li><a href="#action-abstract-base-class">Action Abstract Base Class</a></li>
<li><a href="#service-apis">Service APIs</a>
<ul>
<li><a href="#data-service">Data Service</a></li>
<li><a href="#knowledge-service">Knowledge Service</a></li>
<li><a href="#memory-service">Memory Service</a></li>
<li><a href="#multi-modal-service">Multi-modal Service</a></li>
</ul>
</li>
<li><a href="#module-specific-apis">Module-specific APIs</a>
<ul>
<li><a href="#episodic-memory-client">Episodic Memory Client</a></li>
<li><a href="#reflection-system">Reflection System</a></li>
</ul>
</li>
<li><a href="#multi-modal-memory-service">Multi-modal Memory Service</a></li>
<li><a href="#memory-models">Memory Models</a></li>
<li><a href="#postgresql-store">PostgreSQL Store</a></li>
<li><a href="#embedding-service">Embedding Service</a></li>
<li><a href="#initialization-and-lifecycle-management">Initialization and Lifecycle Management</a></li>
<li><a href="#thread-safety-and-async-usage">Thread Safety and Async Usage</a></li>
<li><a href="#error-handling">Error Handling</a></li>
<li><a href="#usage-examples">Usage Examples</a></li>
</ol>
<h2>AGISystem Class</h2>
<p>The <code>AGISystem</code> class is the central orchestrator of the Ravana AGI system, managing the integration of various modules, services, and decision-making processes. It implements an autonomous loop that continuously processes situations, makes decisions, executes actions, and reflects on outcomes.</p>
<h3>Methods</h3>
<h4><code>__init__(engine)</code></h4>
<p>Initializes the AGI system with core components and services.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>engine</code>: Database engine instance for persistence operations</li>
</ul>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>data_service</code>: DataService instance for data operations</li>
<li><code>knowledge_service</code>: KnowledgeService instance for knowledge management</li>
<li><code>memory_service</code>: MemoryService instance for memory operations</li>
<li><code>action_manager</code>: EnhancedActionManager for action execution</li>
<li><code>shared_state</code>: SharedState object for cross-component state</li>
<li><code>personality</code>: Personality instance influencing behavior</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>None explicitly raised, but depends on underlying service initialization</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">from sqlalchemy import create_engine
from core.system import AGISystem

engine = create_engine("sqlite:///ravana.db")
agi = AGISystem(engine)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
</ul>
<h4><code>run_autonomous_loop()</code></h4>
<p>Starts the main autonomous loop of the AGI system, which continuously processes iterations.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>None (runs indefinitely until stopped)</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Logs critical errors but continues execution with extended sleep intervals</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">import asyncio

async def main():
    await agi.run_autonomous_loop()

asyncio.run(main())
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
</ul>
<h4><code>run_single_task(prompt: str)</code></h4>
<p>Executes a single task specified by a prompt, running multiple iterations if needed.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>prompt</code>: String describing the task to be performed</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>None (modifies internal state and executes actions)</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">await agi.run_single_task("Research quantum computing advancements")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
</ul>
<h4><code>stop()</code></h4>
<p>Gracefully stops the AGI system and all background tasks.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>None</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">await agi.stop()
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
</ul>
<h4><code>get_recent_events(time_limit_seconds: int = 3600)</code></h4>
<p>Retrieves recent events from the database within a specified time window.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>time_limit_seconds</code>: Number of seconds in the past to include (default: 3600)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>List of Event objects from the database</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">events = await agi.get_recent_events(7200)  # Get events from last 2 hours
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
</ul>
<h2>Action Abstract Base Class</h2>
<p>The <code>Action</code> class is an abstract base class that defines the interface for all actions that the AGI system can perform. All concrete actions must inherit from this class and implement its abstract methods.</p>
<h3>Methods</h3>
<h4><code>name</code> (property)</h4>
<p>Returns the name of the action.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>String representing the action name</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/actions/action.py</a></li>
</ul>
<h4><code>description</code> (property)</h4>
<p>Returns a description of what the action does.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>String describing the action's purpose</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/actions/action.py</a></li>
</ul>
<h4><code>parameters</code> (property)</h4>
<p>Returns a list of parameters that the action accepts.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>List of dictionaries, each containing parameter metadata (name, type, required, etc.)</li>
</ul>
<p><strong>:Example Return</strong></p>
<pre><code class="language-python">[
    {
        "name": "query",
        "type": "string",
        "required": True,
        "description": "Search query string"
    }
]
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/actions/action.py</a></li>
</ul>
<h4><code>execute(**kwargs: Any)</code></h4>
<p>Abstract method that executes the action with the given parameters.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>**kwargs</code>: Arbitrary keyword arguments matching the action's parameters</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Any: Result of the action execution</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Must be implemented by subclasses</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/actions/action.py</a></li>
</ul>
<h4><code>validate_params(params: Dict[str, Any])</code></h4>
<p>Validates the given parameters against the action's defined parameters.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>params</code>: Dictionary of parameter names and values</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li><code>InvalidActionParams</code>: Raised when required parameters are missing or unexpected parameters are provided</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">try:
    action.validate_params({"query": "AI research"})
    # Parameters are valid
except InvalidActionParams as e:
    print(f"Invalid parameters: {e}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/actions/action.py</a></li>
</ul>
<h4><code>to_dict()</code></h4>
<p>Returns a dictionary representation of the action.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary containing name, description, and parameters</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/actions/action.py</a></li>
</ul>
<h4><code>to_json()</code></h4>
<p>Returns a JSON string representing the action's schema.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>String containing JSON-formatted action schema</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/actions/action.py</a></li>
</ul>
<h2>Service APIs</h2>
<h3>Data Service</h3>
<p>The <code>DataService</code> class handles data persistence operations, including articles, events, and logging.</p>
<h4><code>__init__(engine, feed_urls, embedding_model=None, sentiment_classifier=None)</code></h4>
<p>Initializes the data service with database connection and processing models.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>engine</code>: Database engine instance</li>
<li><code>feed_urls</code>: List of RSS feed URLs to monitor</li>
<li><code>embedding_model</code>: Optional sentence transformer model for embeddings</li>
<li><code>sentiment_classifier</code>: Optional pipeline for sentiment analysis</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h4><code>fetch_and_save_articles()</code></h4>
<p>Fetches articles from configured RSS feeds and saves new ones to the database.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Integer: Number of new articles saved</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">num_saved = await asyncio.to_thread(data_service.fetch_and_save_articles)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h4><code>detect_and_save_events()</code></h4>
<p>Analyzes recent articles to detect and save significant events.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Integer: Number of events detected and saved</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">num_events = await asyncio.to_thread(data_service.detect_and_save_events)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h4><code>save_action_log(action_name, params, status, result)</code></h4>
<p>Persists a record of an executed action to the database.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>action_name</code>: String name of the action</li>
<li><code>params</code>: Dictionary of action parameters</li>
<li><code>status</code>: String status ("success" or "error")</li>
<li><code>result</code>: Any result data from action execution</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h4><code>save_mood_log(mood_vector)</code></h4>
<p>Saves the current mood vector to the database.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>mood_vector</code>: Dictionary representing the current emotional state</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h4><code>save_situation_log(situation)</code></h4>
<p>Saves a generated situation and returns its database ID.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>situation</code>: Dictionary containing situation details</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Integer: Database ID of the saved situation</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h4><code>save_decision_log(situation_id, raw_response)</code></h4>
<p>Saves a decision made by the AGI to the database.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>situation_id</code>: Integer ID of the associated situation</li>
<li><code>raw_response</code>: String containing the raw LLM response</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h4><code>save_experiment_log(hypothesis, *args)</code></h4>
<p>Saves experiment results to the database with flexible calling conventions.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>hypothesis</code>: String describing the experiment hypothesis</li>
<li><code>*args</code>: Either a single dict of results, or three arguments (test_plan, final_verdict, execution_result)</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li><code>TypeError</code>: Raised when arguments don't match expected patterns</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python"># Style 1: Dictionary of results
data_service.save_experiment_log("AI creativity improves with reflection", {"findings": "Positive correlation observed"})

# Style 2: Individual components
data_service.save_experiment_log(
    "Memory consolidation improves recall",
    "Tested with 100 memory queries",
    "Supported",
    {"accuracy": 0.92}
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
</ul>
<h3>Knowledge Service</h3>
<p>The <code>KnowledgeService</code> manages the storage, retrieval, and compression of knowledge.</p>
<h4><code>__init__(engine, embedding_model=None)</code></h4>
<p>Initializes the knowledge service with database connection and embedding model.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>engine</code>: Database engine instance</li>
<li><code>embedding_model</code>: Optional SentenceTransformer instance (defaults to 'all-MiniLM-L6-v2')</li>
</ul>
<p><strong>:Notes</strong></p>
<ul>
<li>Automatically initializes FAISS index for semantic search if available</li>
<li>Loads existing index from disk or creates new one</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/knowledge_service.py</a></li>
</ul>
<h4><code>add_knowledge(content, source="unknown", category="misc")</code></h4>
<p>Adds new knowledge by summarizing content and saving it with metadata.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>content</code>: String content to be added</li>
<li><code>source</code>: String source identifier (default: "unknown")</li>
<li><code>category</code>: String category (default: "misc")</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary containing:
<ul>
<li><code>timestamp</code>: ISO format timestamp</li>
<li><code>summary</code>: Generated summary text</li>
<li><code>source</code>: Source identifier</li>
<li><code>category</code>: Category</li>
<li><code>duplicate</code>: Boolean indicating if content already existed</li>
<li><code>id</code>: Database ID (if new)</li>
</ul>
</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li><code>ValueError</code>: When no content is provided</li>
<li>Logs and re-raises any other exceptions</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = await asyncio.to_thread(
    knowledge_service.add_knowledge,
    "Recent advances in quantum computing have enabled...",
    source="research_paper",
    category="science"
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/knowledge_service.py</a></li>
</ul>
<h4><code>get_knowledge_by_category(category, limit=10)</code></h4>
<p>Retrieves knowledge entries by category.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>category</code>: String category to filter by</li>
<li><code>limit</code>: Maximum number of results to return (default: 10)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>List of dictionaries containing knowledge entry details</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/knowledge_service.py</a></li>
</ul>
<h4><code>get_recent_knowledge(hours=24, limit=20)</code></h4>
<p>Retrieves recently added knowledge entries.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>hours</code>: Number of hours in the past to include (default: 24)</li>
<li><code>limit</code>: Maximum number of results (default: 20)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>List of knowledge entry dictionaries</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/knowledge_service.py</a></li>
</ul>
<h4><code>search_knowledge(query, limit=10)</code></h4>
<p>Performs text search in knowledge summaries.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>query</code>: Search query string</li>
<li><code>limit</code>: Maximum results to return (default: 10)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>List of dictionaries with knowledge entries and relevance scores</li>
</ul>
<p><strong>:Notes</strong></p>
<ul>
<li>Uses simple LIKE search; could be enhanced with full-text search</li>
<li>Includes relevance_score based on keyword matching</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/knowledge_service.py</a></li>
</ul>
<h4><code>compress_and_save_knowledge()</code></h4>
<p>Compresses recent knowledge into a summary and saves it.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary containing the generated summary</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Logs and re-raises any exceptions</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">summary = await asyncio.to_thread(knowledge_service.compress_and_save_knowledge)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/knowledge_service.py</a></li>
</ul>
<h3>Memory Service</h3>
<p>The <code>MemoryService</code> provides an interface to the episodic memory system.</p>
<h4><code>get_relevant_memories(query_text)</code></h4>
<p>Retrieves memories relevant to a query.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>query_text</code>: String query to find relevant memories</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable that resolves to a response object with relevant memories</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">response = await memory_service.get_relevant_memories("vacation plans")
for memory in response.relevant_memories:
    print(f"{memory.text} (similarity: {memory.similarity})")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/memory_service.py</a></li>
</ul>
<h4><code>save_memories(memories)</code></h4>
<p>Saves a list of memories to persistent storage.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memories</code>: List of memory strings or objects</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable (completes when save operation finishes)</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">await memory_service.save_memories(["I planned a trip to Hawaii", "I enjoy hiking"])
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/memory_service.py</a></li>
</ul>
<h4><code>extract_memories(user_input, ai_output)</code></h4>
<p>Extracts memories from user-AI interaction.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>user_input</code>: String containing user message</li>
<li><code>ai_output</code>: String containing AI response</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to an object with extracted memories</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = await memory_service.extract_memories(
    "I'm planning a vacation to Hawaii", 
    "That sounds wonderful!"
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/memory_service.py</a></li>
</ul>
<h4><code>consolidate_memories()</code></h4>
<p>Performs memory consolidation to optimize retrieval.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to consolidation results</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = await memory_service.consolidate_memories()
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/memory_service.py</a></li>
</ul>
<h3>Multi-modal Service</h3>
<p>The <code>MultiModalService</code> handles processing of images, audio, and cross-modal analysis.</p>
<h4><code>__init__()</code></h4>
<p>Initializes the multi-modal service with supported formats and temporary directory.</p>
<p><strong>:Notes</strong></p>
<ul>
<li>Creates temporary directory for processing files</li>
<li>Defines supported image and audio formats</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/multi_modal_service.py</a></li>
</ul>
<h4><code>process_image(image_path, prompt="Analyze this image in detail")</code></h4>
<p>Processes an image file and returns detailed analysis.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>image_path</code>: String path to the image file</li>
<li><code>prompt</code>: Optional custom prompt for analysis (default: "Analyze this image in detail")</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary containing:
<ul>
<li><code>type</code>: "image"</li>
<li><code>path</code>: Original path</li>
<li><code>format</code>: File extension</li>
<li><code>size_bytes</code>: File size</li>
<li><code>description</code>: AI-generated description</li>
<li><code>analysis_prompt</code>: Prompt used</li>
<li><code>success</code>: Boolean indicating success</li>
<li><code>error</code>: Error message if unsuccessful</li>
</ul>
</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li><code>FileNotFoundError</code>: When image file doesn't exist</li>
<li><code>ValueError</code>: When file format is unsupported</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = await multi_modal_service.process_image("/path/to/photo.jpg")
if result["success"]:
    print(result["description"])
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/multi_modal_service.py</a></li>
</ul>
<h4><code>process_audio(audio_path, prompt="Describe and analyze this audio")</code></h4>
<p>Processes an audio file and returns analysis.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>audio_path</code>: String path to the audio file</li>
<li><code>prompt</code>: Optional custom prompt for analysis (default: "Describe and analyze this audio")</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with similar structure to process_image result</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li><code>FileNotFoundError</code>: When audio file doesn't exist</li>
<li><code>ValueError</code>: When file format is unsupported</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/multi_modal_service.py</a></li>
</ul>
<h4><code>cross_modal_analysis(content_list, analysis_prompt=None)</code></h4>
<p>Performs analysis across multiple content types.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>content_list</code>: List of processed content objects (from process_image/process_audio)</li>
<li><code>analysis_prompt</code>: Optional custom analysis prompt</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary containing cross-modal analysis</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">analysis = await multi_modal_service.cross_modal_analysis([
    image_result, 
    audio_result
])
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/multi_modal_service.py</a></li>
</ul>
<h4><code>generate_content_summary(processed_content)</code></h4>
<p>Generates a comprehensive summary of multi-modal content.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>processed_content</code>: List of processed content results</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>String summary of all content</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/multi_modal_service.py</a></li>
</ul>
<h4><code>process_directory(directory_path, recursive=False)</code></h4>
<p>Processes all supported files in a directory.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>directory_path</code>: Path to directory to process</li>
<li><code>recursive</code>: Whether to include subdirectories (default: False)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>List of processing results for each file</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/multi_modal_service.py</a></li>
</ul>
<h4><code>cleanup_temp_files(max_age_hours=24)</code></h4>
<p>Cleans up temporary files older than specified age.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>max_age_hours</code>: Maximum age in hours (default: 24)</li>
</ul>
<p><strong>:Notes</strong></p>
<ul>
<li>Runs synchronously (not async)</li>
<li>Used for maintenance</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/multi_modal_service.py</a></li>
</ul>
<h2>Module-specific APIs</h2>
<h3>Episodic Memory Client</h3>
<p>The episodic memory client provides direct access to the memory database API.</p>
<h4><code>extract_memories(user_input, ai_output)</code></h4>
<p>Calls the /extract_memories/ endpoint to extract memories from conversation.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>user_input</code>: String user message</li>
<li><code>ai_output</code>: String AI response</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with extracted memories or None on failure</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = extract_memories("I love hiking in the mountains", "That sounds invigorating!")
if result and 'memories' in result:
    print(f"Extracted: {result['memories']}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h4><code>save_memories(memories_list, memory_type='long-term')</code></h4>
<p>Saves a list of memories to the server.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memories_list</code>: List of memory strings</li>
<li><code>memory_type</code>: String type of memory (default: 'long-term')</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with save response or None on failure</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h4><code>get_relevant_memories(query_text, top_n=5, similarity_threshold=0.7)</code></h4>
<p>Retrieves memories relevant to a query.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>query_text</code>: Search query</li>
<li><code>top_n</code>: Maximum number of results (default: 5)</li>
<li><code>similarity_threshold</code>: Minimum similarity score (default: 0.7)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with relevant memories or None on failure</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h4><code>health_check()</code></h4>
<p>Checks the health of the memory database API.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with health status or None on failure</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">health = health_check()
if health and health.get("status") == "ok":
    print("Memory API is healthy")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h4><code>upload_audio_file(file_path, context=None, extract_text=True)</code></h4>
<p>Uploads an audio file and processes it into memory.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>file_path</code>: Path to the audio file</li>
<li><code>context</code>: Optional context for transcription</li>
<li><code>extract_text</code>: Whether to extract text from audio</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with processing result or None on failure</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = upload_audio_file("meeting_recording.mp3", context="Team meeting about project timeline")
if result and result["success"]:
    print(f"Audio processed with transcript: {result['transcript']}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h4><code>upload_image_file(file_path, description=None)</code></h4>
<p>Uploads an image file and processes it into memory.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>file_path</code>: Path to the image file</li>
<li><code>description</code>: Optional description of the image</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with processing result or None on failure</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = upload_image_file("vacation_photo.jpg", description="Sunset at the beach")
if result and result["success"]:
    print(f"Image processed with description: {result['description']}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h4><code>advanced_search(query, content_types=None, memory_types=None, search_mode="hybrid")</code></h4>
<p>Performs advanced search with multiple filtering options.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>query</code>: Search query string</li>
<li><code>content_types</code>: List of content types to include</li>
<li><code>memory_types</code>: List of memory types to include</li>
<li><code>search_mode</code>: Search mode ("text", "vector", "hybrid")</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with search results or None on failure</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">results = advanced_search(
    "beach vacation", 
    content_types=["image", "text"], 
    memory_types=["episodic"],
    search_mode="hybrid"
)
if results:
    for result in results["results"]:
        print(f"Found: {result['content_text']} (score: {result['similarity_score']})")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h4><code>batch_process_files(file_paths, content_types=None)</code></h4>
<p>Processes multiple files in batch.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>file_paths</code>: List of file paths to process</li>
<li><code>content_types</code>: Optional list of content types corresponding to files</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Dictionary with batch processing results or None on failure</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">results = batch_process_files([
    "notes.txt", 
    "meeting_recording.mp3", 
    "project_diagram.jpg"
])
if results:
    print(f"Processed {results['successful_count']} of {results['total_processed']} files")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h3>Reflection System</h3>
<p>The <code>ReflectionModule</code> enables self-reflection capabilities.</p>
<h4><code>__init__(agi_system)</code></h4>
<p>Initializes the reflection module with a reference to the AGI system.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>agi_system</code>: Reference to the main AGISystem instance</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/reflection_module.py</a></li>
</ul>
<h4><code>reflect_on_experiment(experiment_results)</code></h4>
<p>Analyzes experiment results and generates insights.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>experiment_results</code>: Dictionary containing experiment data including 'hypothesis' and 'findings'</li>
</ul>
<p><strong>:Notes</strong></p>
<ul>
<li>Automatically adds generated insights to the knowledge base</li>
<li>Uses "reflection" as source and "insight" as category</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/reflection_module.py</a></li>
</ul>
<h4><code>reflect(shared_state)</code></h4>
<p>Performs general reflection based on the system's state.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>shared_state</code>: SharedState object containing mood history and other state</li>
</ul>
<p><strong>:Notes</strong></p>
<ul>
<li>Currently focuses on mood history analysis</li>
<li>Placeholder for more sophisticated reflection logic</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/reflection_module.py</a></li>
</ul>
<h2>Multi-modal Memory Service</h2>
<p>The <code>MultiModalMemoryService</code> is the main orchestration class for the multi-modal memory system, integrating PostgreSQL storage, embeddings, Whisper audio processing, and advanced search capabilities.</p>
<h3>Methods</h3>
<h4><code>__init__(database_url, text_model_name="all-MiniLM-L6-v2", whisper_model_size="base", device=None)</code></h4>
<p>Initializes the multi-modal memory service with all required components.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>database_url</code>: PostgreSQL connection URL</li>
<li><code>text_model_name</code>: SentenceTransformer model name for text embeddings</li>
<li><code>whisper_model_size</code>: Whisper model size for audio processing</li>
<li><code>device</code>: Device to use ("cpu", "cuda", "auto")</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">service = MultiModalMemoryService(
    database_url="postgresql://user:pass@localhost:5432/ravana",
    text_model_name="all-MiniLM-L6-v2",
    whisper_model_size="base"
)
await service.initialize()
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>initialize()</code></h4>
<p>Initializes all service components and establishes database connections.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable that completes when initialization is finished</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Raises exception if initialization fails</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">try:
    await service.initialize()
    print("Service initialized successfully")
except Exception as e:
    print(f"Initialization failed: {e}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>close()</code></h4>
<p>Closes all service components gracefully and releases resources.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable that completes when shutdown is finished</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">await service.close()
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>process_text_memory(text, memory_type="episodic", tags=None, emotional_valence=None)</code></h4>
<p>Processes and stores text memory with embeddings.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>text</code>: Text content to store</li>
<li><code>memory_type</code>: Type of memory ("episodic", "semantic", "procedural")</li>
<li><code>tags</code>: Optional list of tags</li>
<li><code>emotional_valence</code>: Emotional valence (-1.0 to 1.0)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to the stored MemoryRecord</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">record = await service.process_text_memory(
    "I enjoyed the concert last night",
    memory_type="episodic",
    tags=["entertainment", "music"],
    emotional_valence=0.8
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>process_audio_memory(audio_path, context=None, memory_type="episodic", tags=None)</code></h4>
<p>Processes and stores audio memory with Whisper transcription and embeddings.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>audio_path</code>: Path to the audio file</li>
<li><code>context</code>: Optional context for transcription</li>
<li><code>memory_type</code>: Type of memory</li>
<li><code>tags</code>: Optional list of tags</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to the stored MemoryRecord</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">record = await service.process_audio_memory(
    "meeting_recording.mp3",
    context="Team meeting about project timeline",
    tags=["work", "meetings"]
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>process_image_memory(image_path, description=None, memory_type="episodic", tags=None)</code></h4>
<p>Processes and stores image memory with metadata and embeddings.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>image_path</code>: Path to the image file</li>
<li><code>description</code>: Optional image description</li>
<li><code>memory_type</code>: Type of memory</li>
<li><code>tags</code>: Optional list of tags</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to the stored MemoryRecord</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">record = await service.process_image_memory(
    "vacation_photo.jpg",
    description="Sunset at the beach",
    tags=["vacation", "nature"]
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>extract_memories_from_conversation(request)</code></h4>
<p>Extracts memories from a conversation using LLM analysis.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>request</code>: ConversationRequest object with user_input, ai_output, and context</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to MemoriesList object</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">request = ConversationRequest(
    user_input="I'm planning a trip to Japan next spring",
    ai_output="That sounds like an amazing adventure!",
    context="Travel planning conversation"
)
memories = await service.extract_memories_from_conversation(request)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>save_extracted_memories(memories_list)</code></h4>
<p>Saves a list of extracted memories to the database.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memories_list</code>: MemoriesList object containing memories to save</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of saved MemoryRecord objects</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">saved_records = await service.save_extracted_memories(memories_list)
print(f"Saved {len(saved_records)} memories")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>search_memories(request)</code></h4>
<p>Searches memories using advanced search capabilities.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>request</code>: SearchRequest object with query and search parameters</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to SearchResponse object</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">request = SearchRequest(
    query="beach vacation",
    content_types=[ContentType.IMAGE, ContentType.TEXT],
    memory_types=[MemoryType.EPISODIC],
    search_mode=SearchMode.HYBRID,
    limit=10,
    similarity_threshold=0.7
)
response = await service.search_memories(request)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>find_similar_memories(memory_id, limit=10, similarity_threshold=0.7)</code></h4>
<p>Finds memories similar to a given memory.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memory_id</code>: UUID of the reference memory</li>
<li><code>limit</code>: Maximum number of similar memories to return</li>
<li><code>similarity_threshold</code>: Minimum similarity score (0.0 to 1.0)</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of similar MemoryRecord objects</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">similar_memories = await service.find_similar_memories(
    memory_id="a1b2c3d4-e5f6-7890-1234-567890abcdef",
    limit=5,
    similarity_threshold=0.8
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>batch_process_files(request)</code></h4>
<p>Processes multiple files in batch with parallel processing.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>request</code>: BatchProcessRequest object with file paths and processing options</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to BatchProcessResult object</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">request = BatchProcessRequest(
    file_paths=["notes.txt", "meeting.mp3", "diagram.jpg"],
    parallel_processing=True,
    max_workers=4
)
result = await service.batch_process_files(request)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>get_memory_statistics()</code></h4>
<p>Retrieves comprehensive statistics about the memory system.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to MemoryStatistics object</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">stats = await service.get_memory_statistics()
print(f"Total memories: {stats.total_memories}")
print(f"Storage size: {stats.storage_size_mb:.2f} MB")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>consolidate_memories(memory_ids=None, max_memories=50)</code></h4>
<p>Consolidates memories to optimize storage and retrieval.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memory_ids</code>: Optional list of specific memory IDs to consolidate</li>
<li><code>max_memories</code>: Maximum number of memories to process</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to dictionary with consolidation results</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">result = await service.consolidate_memories(
    memory_ids=["a1b2c3d4-e5f6-7890-1234-567890abcdef"],
    max_memories=100
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h4><code>health_check()</code></h4>
<p>Performs a comprehensive health check of the memory system.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to dictionary with health status</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">health = await service.health_check()
if health["status"] == "healthy":
    print("Memory system is healthy")
else:
    print(f"Memory system status: {health['status']}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
</ul>
<h2>Memory Models</h2>
<p>This section documents the data models used in the multi-modal memory system, defining the structure of memory records, search requests, and responses.</p>
<h3>Core Data Models</h3>
<h4><code>MemoryRecord</code></h4>
<p>Main memory record model containing all memory data and metadata.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>id</code>: Optional UUID for the memory record</li>
<li><code>content_type</code>: ContentType enum value (TEXT, AUDIO, IMAGE, VIDEO)</li>
<li><code>content_text</code>: Optional text content</li>
<li><code>content_metadata</code>: Dictionary of additional metadata</li>
<li><code>file_path</code>: Optional path to associated file</li>
<li><code>text_embedding</code>: Optional list of floats for text embedding</li>
<li><code>image_embedding</code>: Optional list of floats for image embedding</li>
<li><code>audio_embedding</code>: Optional list of floats for audio embedding</li>
<li><code>unified_embedding</code>: Optional list of floats for combined embedding</li>
<li><code>created_at</code>: Optional datetime of creation</li>
<li><code>last_accessed</code>: Optional datetime of last access</li>
<li><code>access_count</code>: Integer count of accesses</li>
<li><code>memory_type</code>: MemoryType enum value (EPISODIC, SEMANTIC, PROCEDURAL)</li>
<li><code>emotional_valence</code>: Optional float (-1.0 to 1.0) for emotional valence</li>
<li><code>confidence_score</code>: Float (0.0 to 1.0) for confidence in memory</li>
<li><code>tags</code>: List of string tags</li>
<li><code>audio_metadata</code>: Optional AudioMetadata object</li>
<li><code>image_metadata</code>: Optional ImageMetadata object</li>
<li><code>video_metadata</code>: Optional VideoMetadata object</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>SearchRequest</code></h4>
<p>Request model for memory search operations with advanced filtering.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>query</code>: Search query string (1-1000 characters)</li>
<li><code>content_types</code>: Optional list of ContentType values to filter by</li>
<li><code>memory_types</code>: Optional list of MemoryType values to filter by</li>
<li><code>search_mode</code>: SearchMode enum value (TEXT, VECTOR, HYBRID)</li>
<li><code>limit</code>: Integer limit on results (1-100)</li>
<li><code>similarity_threshold</code>: Float threshold for similarity (0.0-1.0)</li>
<li><code>include_metadata</code>: Boolean to include metadata in results</li>
<li><code>tags</code>: Optional list of tags to filter by</li>
<li><code>query_content_type</code>: Optional ContentType for cross-modal search</li>
<li><code>target_content_types</code>: Optional list of target types for cross-modal search</li>
<li><code>created_after</code>: Optional datetime filter for creation date</li>
<li><code>created_before</code>: Optional datetime filter for creation date</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>SearchResponse</code></h4>
<p>Response model for search operations containing results and metadata.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>results</code>: List of SearchResult objects</li>
<li><code>total_found</code>: Integer count of total matching memories</li>
<li><code>search_time_ms</code>: Integer search duration in milliseconds</li>
<li><code>search_mode</code>: SearchMode enum value used</li>
<li><code>query_metadata</code>: Dictionary of additional query metadata</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>ConversationRequest</code></h4>
<p>Request model for memory extraction from conversations.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>user_input</code>: User message text (required)</li>
<li><code>ai_output</code>: AI response text (required)</li>
<li><code>context</code>: Optional context for extraction</li>
<li><code>extract_emotions</code>: Boolean to extract emotional content</li>
<li><code>memory_type</code>: MemoryType enum value for extracted memories</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>MemoriesList</code></h4>
<p>List of extracted memories with metadata.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>memories</code>: List of memory text strings</li>
<li><code>memory_type</code>: MemoryType enum value for all memories</li>
<li><code>confidence_scores</code>: Optional list of confidence scores</li>
<li><code>emotional_valences</code>: Optional list of emotional valences</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h3>Content Type Models</h3>
<h4><code>AudioMetadata</code></h4>
<p>Metadata specific to audio content.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>transcript</code>: Optional transcription text</li>
<li><code>language_code</code>: Optional language code (e.g., "en")</li>
<li><code>confidence_scores</code>: Dictionary of confidence scores</li>
<li><code>duration_seconds</code>: Optional duration in seconds</li>
<li><code>audio_features</code>: Dictionary of audio analysis features</li>
<li><code>sample_rate</code>: Optional sample rate in Hz</li>
<li><code>channels</code>: Optional number of audio channels</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>ImageMetadata</code></h4>
<p>Metadata specific to image content.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>width</code>: Optional image width in pixels</li>
<li><code>height</code>: Optional image height in pixels</li>
<li><code>object_detections</code>: Dictionary of detected objects</li>
<li><code>scene_description</code>: Optional scene description</li>
<li><code>image_hash</code>: Optional perceptual hash</li>
<li><code>color_palette</code>: List of dominant colors</li>
<li><code>image_features</code>: Dictionary of image analysis features</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>VideoMetadata</code></h4>
<p>Metadata specific to video content.</p>
<p><strong>:Attributes</strong></p>
<ul>
<li><code>duration_seconds</code>: Optional duration in seconds</li>
<li><code>frame_rate</code>: Optional frame rate in fps</li>
<li><code>width</code>: Optional video width in pixels</li>
<li><code>height</code>: Optional video height in pixels</li>
<li><code>video_features</code>: Dictionary of video analysis features</li>
<li><code>thumbnail_path</code>: Optional path to thumbnail image</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h3>Enumerations</h3>
<h4><code>ContentType</code></h4>
<p>Enumeration of supported content types.</p>
<p><strong>:Values</strong></p>
<ul>
<li><code>TEXT</code>: Text content</li>
<li><code>AUDIO</code>: Audio content</li>
<li><code>IMAGE</code>: Image content</li>
<li><code>VIDEO</code>: Video content</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>MemoryType</code></h4>
<p>Enumeration of memory types.</p>
<p><strong>:Values</strong></p>
<ul>
<li><code>EPISODIC</code>: Episodic memories (personal experiences)</li>
<li><code>SEMANTIC</code>: Semantic memories (facts and knowledge)</li>
<li><code>PROCEDURAL</code>: Procedural memories (skills and procedures)</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h4><code>SearchMode</code></h4>
<p>Enumeration of search modes.</p>
<p><strong>:Values</strong></p>
<ul>
<li><code>TEXT</code>: Text-based search</li>
<li><code>VECTOR</code>: Vector similarity search</li>
<li><code>HYBRID</code>: Hybrid search combining text and vector</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<h2>PostgreSQL Store</h2>
<p>The <code>PostgreSQLStore</code> class handles database operations for the multi-modal memory system with pgvector support for similarity search.</p>
<h3>Methods</h3>
<h4><code>__init__(database_url, pool_size=10, max_connections=20)</code></h4>
<p>Initializes the PostgreSQL store with connection parameters.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>database_url</code>: PostgreSQL connection URL</li>
<li><code>pool_size</code>: Minimum connection pool size</li>
<li><code>max_connections</code>: Maximum connection pool size</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Raises ImportError if AsyncPG is not available</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>initialize()</code></h4>
<p>Initializes the database connection pool.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable that completes when initialization is finished</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Raises exception if initialization fails</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">await store.initialize()
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>close()</code></h4>
<p>Closes the database connection pool.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable that completes when closure is finished</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">await store.close()
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>save_memory_record(memory_record)</code></h4>
<p>Saves a memory record to the database.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memory_record</code>: MemoryRecord object to save</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to the saved MemoryRecord</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Raises exception if save fails</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">saved_record = await store.save_memory_record(memory_record)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>get_memory_record(memory_id)</code></h4>
<p>Retrieves a memory record by ID.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memory_id</code>: UUID of the memory record</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to MemoryRecord or None if not found</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">record = await store.get_memory_record("a1b2c3d4-e5f6-7890-1234-567890abcdef")
if record:
    print(f"Found memory: {record.content_text}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>vector_search(embedding, embedding_type="text", limit=10, similarity_threshold=0.7, content_types=None)</code></h4>
<p>Performs vector similarity search.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>embedding</code>: List of floats representing the query embedding</li>
<li><code>embedding_type</code>: Type of embedding ("text", "image", "audio", "unified")</li>
<li><code>limit</code>: Maximum number of results to return</li>
<li><code>similarity_threshold</code>: Minimum similarity score (0.0-1.0)</li>
<li><code>content_types</code>: Optional list of ContentType values to filter by</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of (MemoryRecord, similarity_score) tuples</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">results = await store.vector_search(
    embedding=[0.1, 0.2, 0.3, ...],
    embedding_type="text",
    limit=5,
    similarity_threshold=0.8
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>text_search(query_text, limit=10, content_types=None)</code></h4>
<p>Performs full-text search.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>query_text</code>: Search query string</li>
<li><code>limit</code>: Maximum number of results to return</li>
<li><code>content_types</code>: Optional list of ContentType values to filter by</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of (MemoryRecord, relevance_score) tuples</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">results = await store.text_search("beach vacation", limit=10)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>delete_memory_record(memory_id)</code></h4>
<p>Deletes a memory record by ID.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memory_id</code>: UUID of the memory record to delete</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to boolean (True if deleted, False if not found)</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">deleted = await store.delete_memory_record("a1b2c3d4-e5f6-7890-1234-567890abcdef")
if deleted:
    print("Memory deleted successfully")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>get_memory_statistics()</code></h4>
<p>Retrieves comprehensive statistics about the memory system.</p>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to dictionary with statistics</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">stats = await store.get_memory_statistics()
print(f"Total memories: {stats['total_memories']}")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h4><code>cleanup_old_memories(days_old=30, keep_minimum=1000)</code></h4>
<p>Cleans up old, rarely accessed memories.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>days_old</code>: Age threshold in days</li>
<li><code>keep_minimum</code>: Minimum number of memories to keep</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to integer count of deleted memories</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">deleted_count = await store.cleanup_old_memories(days_old=60, keep_minimum=500)
print(f"Cleaned up {deleted_count} old memories")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/postgresql_store.py</a></li>
</ul>
<h2>Embedding Service</h2>
<p>The <code>EmbeddingService</code> class handles the generation of embeddings for multi-modal content, supporting text, image, audio, and unified embeddings.</p>
<h3>Methods</h3>
<h4><code>__init__(text_model_name="all-MiniLM-L6-v2", device=None, cache_size=1000)</code></h4>
<p>Initializes the embedding service with configuration parameters.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>text_model_name</code>: Name of the sentence transformer model</li>
<li><code>device</code>: Device to use ("cpu", "cuda", "auto")</li>
<li><code>cache_size</code>: Size of the embedding cache</li>
</ul>
<p><strong>:Exceptions</strong></p>
<ul>
<li>Raises ImportError if transformers dependencies are not available</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">service = EmbeddingService(
    text_model_name="all-MiniLM-L6-v2",
    device="cuda",
    cache_size=2000
)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/embedding_service.py</a></li>
</ul>
<h4><code>generate_text_embedding(text)</code></h4>
<p>Generates embedding for text content.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>text</code>: Text string to embed</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of floats (embedding values)</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">embedding = await service.generate_text_embedding("This is a sample text")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/embedding_service.py</a></li>
</ul>
<h4><code>generate_image_embedding(image_path)</code></h4>
<p>Generates embedding for image content.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>image_path</code>: Path to the image file</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of floats (embedding values)</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">embedding = await service.generate_image_embedding("photo.jpg")
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/embedding_service.py</a></li>
</ul>
<h4><code>generate_audio_embedding(audio_features)</code></h4>
<p>Generates embedding for audio content from extracted features.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>audio_features</code>: Dictionary of audio analysis features</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of floats (embedding values)</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">embedding = await service.generate_audio_embedding({
    "mfcc": {"mean": [...], "std": [...]},
    "spectral_centroid": {"mean": 1000.0, "std": 200.0}
})
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/embedding_service.py</a></li>
</ul>
<h4><code>generate_unified_embedding(memory_record)</code></h4>
<p>Generates unified embedding combining all available modalities.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memory_record</code>: MemoryRecord object with various embeddings</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to list of floats (unified embedding values)</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">unified_embedding = await service.generate_unified_embedding(memory_record)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/embedding_service.py</a></li>
</ul>
<h4><code>generate_embeddings(memory_record)</code></h4>
<p>Generates all relevant embeddings for a memory record.</p>
<p><strong>:Parameters</strong></p>
<ul>
<li><code>memory_record</code>: MemoryRecord object to process</li>
</ul>
<p><strong>:Returns</strong></p>
<ul>
<li>Awaitable resolving to MemoryRecord with embeddings populated</li>
</ul>
<p><strong>:Usage</strong></p>
<pre><code class="language-python">processed_record = await service.generate_embeddings(memory_record)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/episodic_memory/embedding_service.py</a></li>
</ul>
<h2>Initialization and Lifecycle Management</h2>
<p>The AGI system follows a specific initialization and lifecycle pattern to ensure proper setup and graceful shutdown.</p>
<h3>Initialization Pattern</h3>
<pre><code class="language-python">from sqlalchemy import create_engine
from core.system import AGISystem

# Create database engine
engine = create_engine("sqlite:///ravana.db")

# Initialize AGI system
agi = AGISystem(engine)

# System is now ready for use
</code></pre>
<p>The initialization process:</p>
<ol>
<li>Creates all service instances (data, knowledge, memory)</li>
<li>Initializes modules (situation generator, emotional intelligence, etc.)</li>
<li>Sets up shared state and behavior modifiers</li>
<li>Prepares background tasks (not started yet)</li>
</ol>
<h3>Lifecycle Management</h3>
<p>The AGI system supports both autonomous and task-based operation modes:</p>
<h4>Autonomous Mode</h4>
<pre><code class="language-python">import asyncio

async def main():
    try:
        await agi.run_autonomous_loop()
    except KeyboardInterrupt:
        await agi.stop()

asyncio.run(main())
</code></pre>
<h4>Single Task Mode</h4>
<pre><code class="language-python">await agi.run_single_task("Research renewable energy technologies")
await agi.stop()
</code></pre>
<h4>Graceful Shutdown</h4>
<pre><code class="language-python">await agi.stop()  # Cancels background tasks and closes resources
</code></pre>
<p>The system uses an asyncio.Event for shutdown signaling and properly cancels all background tasks.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
</ul>
<h2>Thread Safety and Async Usage</h2>
<p>The AGI system is designed for asynchronous operation with careful consideration of thread safety.</p>
<h3>Async/Await Usage</h3>
<p>Most methods are coroutines and must be awaited:</p>
<pre><code class="language-python"># Correct usage
await agi.run_iteration()
await agi._handle_curiosity()

# Incorrect usage (will return coroutine object)
agi.run_iteration()  # Missing await
</code></pre>
<h3>Thread Safety Considerations</h3>
<ul>
<li>Database operations use <code>asyncio.to_thread()</code> for synchronous calls</li>
<li>The <code>EnhancedActionManager</code> handles action execution in thread pool</li>
<li>Shared state modifications are coordinated through the main event loop</li>
<li>Background tasks are properly managed and canceled on shutdown</li>
</ul>
<h3>Background Tasks</h3>
<p>The system manages several background tasks:</p>
<ul>
<li>Data collection (RSS feeds)</li>
<li>Event detection</li>
<li>Knowledge compression</li>
<li>Memory consolidation</li>
<li>Invention tracking</li>
</ul>
<p>These tasks are automatically started in <code>run_autonomous_loop()</code> and properly cleaned up in <code>stop()</code>.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
</ul>
<h2>Error Handling</h2>
<p>The system implements comprehensive error handling at multiple levels.</p>
<h3>Exception Types</h3>
<ul>
<li><code>InvalidActionParams</code>: Raised when action parameters are invalid</li>
<li><code>ValueError</code>: Used for validation errors (e.g., empty content)</li>
<li><code>TypeError</code>: For incorrect argument types</li>
<li><code>FileNotFoundError</code>: When files don't exist</li>
<li><code>json.JSONDecodeError</code>: When parsing JSON fails</li>
</ul>
<h3>Error Handling Patterns</h3>
<h4>Service-Level Error Handling</h4>
<pre><code class="language-python">try:
    result = await self.memory_service.extract_memories(interaction_summary, "")
    if result and result.memories:
        await self.memory_service.save_memories(result.memories)
except Exception as e:
    logger.error(f"Failed during memorization: {e}", exc_info=True)
</code></pre>
<h4>Background Task Error Handling</h4>
<pre><code class="language-python">while not self._shutdown.is_set():
    try:
        # Task logic here
        pass
    except asyncio.CancelledError:
        break
    except Exception as e:
        logger.error(f"Error in task: {e}", exc_info=True)
</code></pre>
<h4>External API Error Handling</h4>
<p>The episodic memory client implements retry logic:</p>
<ul>
<li>Maximum of 3 retries for connection errors</li>
<li>1-second delay between retries</li>
<li>Comprehensive error reporting</li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
<li><a>modules/episodic_memory/client.py</a></li>
</ul>
<h2>Usage Examples</h2>
<h3>Basic System Initialization and Operation</h3>
<pre><code class="language-python">from sqlalchemy import create_engine
from core.system import AGISystem
import asyncio

async def main():
    # Initialize system
    engine = create_engine("sqlite:///ravana.db")
    agi = AGISystem(engine)
    
    try:
        # Run autonomous loop
        await agi.run_autonomous_loop()
    except KeyboardInterrupt:
        print("Shutting down...")
        await agi.stop()

if __name__ == "__main__":
    asyncio.run(main())
</code></pre>
<h3>Executing a Single Task</h3>
<pre><code class="language-python">async def execute_research_task():
    agi = AGISystem(engine)
    
    # Run a specific task
    await agi.run_single_task("Investigate the impact of climate change on coastal cities")
    
    # Get recent events
    events = await agi.get_recent_events(3600)
    print(f"Found {len(events)} recent events")
    
    # Shutdown
    await agi.stop()

asyncio.run(execute_research_task())
</code></pre>
<h3>Using the Multi-modal Service</h3>
<pre><code class="language-python">async def analyze_media():
    multi_modal = MultiModalService()
    
    # Process an image
    image_result = await multi_modal.process_image("photo.jpg")
    
    # Process an audio file
    audio_result = await multi_modal.process_audio("recording.mp3")
    
    # Cross-modal analysis
    analysis = await multi_modal.cross_modal_analysis([
        image_result, 
        audio_result
    ])
    
    # Generate summary
    summary = await multi_modal.generate_content_summary([
        image_result, 
        audio_result
    ])
    
    print(summary)

asyncio.run(analyze_media())
</code></pre>
<h3>Working with the Memory System</h3>
<pre><code class="language-python"># Direct client usage
def manage_memories():
    # Extract memories from conversation
    result = extract_memories(
        "I'm planning a trip to Japan next spring", 
        "That sounds like an amazing adventure!"
    )
    
    if result and 'memories' in result:
        # Save extracted memories
        save_response = save_memories(result['memories'])
        
        # Retrieve relevant memories later
        relevant = get_relevant_memories("travel plans", top_n=3)
        for mem in relevant['relevant_memories']:
            print(f"Found: {mem['text']}")

manage_memories()
</code></pre>
<h3>Adding Knowledge</h3>
<pre><code class="language-python">async def add_research_knowledge():
    knowledge_service = KnowledgeService(engine)
    
    research_content = """
    Recent studies show that neural network pruning can reduce model size 
    by up to 90% with minimal accuracy loss. This technique involves 
    removing redundant weights and neurons from trained models.
    """
    
    result = await asyncio.to_thread(
        knowledge_service.add_knowledge,
        content=research_content,
        source="research_paper",
        category="machine_learning"
    )
    
    if not result.get('duplicate'):
        print(f"Added new knowledge with ID: {result['id']}")
    else:
        print("Knowledge already existed in database")

asyncio.run(add_research_knowledge())
</code></pre>
<h3>Advanced Memory Operations</h3>
<pre><code class="language-python">async def advanced_memory_operations():
    # Initialize multi-modal memory service
    service = MultiModalMemoryService(
        database_url="postgresql://user:pass@localhost:5432/ravana"
    )
    await service.initialize()
    
    # Process different types of memories
    text_record = await service.process_text_memory(
        "I learned about quantum computing today",
        tags=["learning", "science"]
    )
    
    audio_record = await service.process_audio_memory(
        "lecture_recording.mp3",
        context="Physics lecture on quantum mechanics"
    )
    
    image_record = await service.process_image_memory(
        "quantum_diagram.jpg",
        description="Diagram explaining quantum entanglement"
    )
    
    # Advanced search
    search_request = SearchRequest(
        query="quantum computing",
        content_types=[ContentType.TEXT, ContentType.AUDIO, ContentType.IMAGE],
        search_mode=SearchMode.HYBRID,
        limit=5
    )
    search_response = await service.search_memories(search_request)
    
    # Display results
    for result in search_response.results:
        print(f"Found: {result.memory_record.content_text[:100]}... "
              f"(score: {result.similarity_score:.3f})")
    
    # Batch processing
    batch_request = BatchProcessRequest(
        file_paths=["notes1.txt", "notes2.txt", "lecture.mp3"],
        parallel_processing=True
    )
    batch_result = await service.batch_process_files(batch_request)
    
    print(f"Processed {batch_result.successful_count}/{batch_result.total_processed} files")
    
    # Cleanup
    await service.close()

asyncio.run(advanced_memory_operations())
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
<li><a>services/multi_modal_service.py</a></li>
<li><a>modules/episodic_memory/client.py</a></li>
<li><a>modules/episodic_memory/multi_modal_service.py</a></li>
<li><a>modules/episodic_memory/models.py</a></li>
</ul>
<p><strong>Referenced Files in This Document</strong></p>
<ul>
<li><a>core/system.py</a> - <em>Updated in recent commit</em></li>
<li><a>core/actions/action.py</a></li>
<li><a>services/data_service.py</a></li>
<li><a>services/knowledge_service.py</a></li>
<li><a>services/memory_service.py</a></li>
<li><a>services/multi_modal_service.py</a></li>
<li><a>modules/episodic_memory/client.py</a> - <em>Enhanced with new features</em></li>
<li><a>modules/episodic_memory/multi_modal_service.py</a> - <em>Added in recent commit</em></li>
<li><a>modules/episodic_memory/models.py</a> - <em>Added in recent commit</em></li>
<li><a>modules/episodic_memory/postgresql_store.py</a> - <em>Added in recent commit</em></li>
<li><a>modules/episodic_memory/embedding_service.py</a> - <em>Added in recent commit</em></li>
<li><a>modules/reflection_module.py</a></li>
</ul>
</div></article><div class="w-full md:w-64 flex-shrink-0"></div></div></main></div><footer class="bg-wiki-dark text-white p-4"><div class="container mx-auto text-center"><p> <!-- -->2025<!-- --> RAVANA AGI System Documentation</p></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"doc":{"slug":"API Reference","title":"API Reference","content":"\u003ch1\u003eAPI Reference\u003c/h1\u003e\n\u003ch2\u003eUpdate Summary\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eChanges Made\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUpdated Episodic Memory Client section with new methods for audio/image upload, advanced search, and batch processing\u003c/li\u003e\n\u003cli\u003eAdded new section for Multi-modal Memory Service with comprehensive API documentation\u003c/li\u003e\n\u003cli\u003eAdded new section for Memory Models with detailed data structure documentation\u003c/li\u003e\n\u003cli\u003eAdded new sections for PostgreSQL Store and Embedding Service implementations\u003c/li\u003e\n\u003cli\u003eUpdated Table of Contents to reflect new sections and organization\u003c/li\u003e\n\u003cli\u003eEnhanced source tracking with specific file references and annotations\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eTable of Contents\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"#agisystem-class\"\u003eAGISystem Class\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#action-abstract-base-class\"\u003eAction Abstract Base Class\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#service-apis\"\u003eService APIs\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#data-service\"\u003eData Service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#knowledge-service\"\u003eKnowledge Service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#memory-service\"\u003eMemory Service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#multi-modal-service\"\u003eMulti-modal Service\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#module-specific-apis\"\u003eModule-specific APIs\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#episodic-memory-client\"\u003eEpisodic Memory Client\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#reflection-system\"\u003eReflection System\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#multi-modal-memory-service\"\u003eMulti-modal Memory Service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#memory-models\"\u003eMemory Models\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#postgresql-store\"\u003ePostgreSQL Store\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#embedding-service\"\u003eEmbedding Service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#initialization-and-lifecycle-management\"\u003eInitialization and Lifecycle Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#thread-safety-and-async-usage\"\u003eThread Safety and Async Usage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#error-handling\"\u003eError Handling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#usage-examples\"\u003eUsage Examples\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eAGISystem Class\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eAGISystem\u003c/code\u003e class is the central orchestrator of the Ravana AGI system, managing the integration of various modules, services, and decision-making processes. It implements an autonomous loop that continuously processes situations, makes decisions, executes actions, and reflects on outcomes.\u003c/p\u003e\n\u003ch3\u003eMethods\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003e__init__(engine)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the AGI system with core components and services.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eengine\u003c/code\u003e: Database engine instance for persistence operations\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edata_service\u003c/code\u003e: DataService instance for data operations\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eknowledge_service\u003c/code\u003e: KnowledgeService instance for knowledge management\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_service\u003c/code\u003e: MemoryService instance for memory operations\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eaction_manager\u003c/code\u003e: EnhancedActionManager for action execution\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eshared_state\u003c/code\u003e: SharedState object for cross-component state\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epersonality\u003c/code\u003e: Personality instance influencing behavior\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNone explicitly raised, but depends on underlying service initialization\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom sqlalchemy import create_engine\nfrom core.system import AGISystem\n\nengine = create_engine(\"sqlite:///ravana.db\")\nagi = AGISystem(engine)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003erun_autonomous_loop()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eStarts the main autonomous loop of the AGI system, which continuously processes iterations.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNone (runs indefinitely until stopped)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLogs critical errors but continues execution with extended sleep intervals\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport asyncio\n\nasync def main():\n    await agi.run_autonomous_loop()\n\nasyncio.run(main())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003erun_single_task(prompt: str)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eExecutes a single task specified by a prompt, running multiple iterations if needed.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eprompt\u003c/code\u003e: String describing the task to be performed\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNone (modifies internal state and executes actions)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait agi.run_single_task(\"Research quantum computing advancements\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003estop()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eGracefully stops the AGI system and all background tasks.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNone\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait agi.stop()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eget_recent_events(time_limit_seconds: int = 3600)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves recent events from the database within a specified time window.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etime_limit_seconds\u003c/code\u003e: Number of seconds in the past to include (default: 3600)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eList of Event objects from the database\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eevents = await agi.get_recent_events(7200)  # Get events from last 2 hours\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eAction Abstract Base Class\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eAction\u003c/code\u003e class is an abstract base class that defines the interface for all actions that the AGI system can perform. All concrete actions must inherit from this class and implement its abstract methods.\u003c/p\u003e\n\u003ch3\u003eMethods\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003ename\u003c/code\u003e (property)\u003c/h4\u003e\n\u003cp\u003eReturns the name of the action.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eString representing the action name\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003edescription\u003c/code\u003e (property)\u003c/h4\u003e\n\u003cp\u003eReturns a description of what the action does.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eString describing the action's purpose\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eparameters\u003c/code\u003e (property)\u003c/h4\u003e\n\u003cp\u003eReturns a list of parameters that the action accepts.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eList of dictionaries, each containing parameter metadata (name, type, required, etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Example Return\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e[\n    {\n        \"name\": \"query\",\n        \"type\": \"string\",\n        \"required\": True,\n        \"description\": \"Search query string\"\n    }\n]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eexecute(**kwargs: Any)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eAbstract method that executes the action with the given parameters.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e**kwargs\u003c/code\u003e: Arbitrary keyword arguments matching the action's parameters\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAny: Result of the action execution\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMust be implemented by subclasses\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003evalidate_params(params: Dict[str, Any])\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eValidates the given parameters against the action's defined parameters.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eparams\u003c/code\u003e: Dictionary of parameter names and values\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eInvalidActionParams\u003c/code\u003e: Raised when required parameters are missing or unexpected parameters are provided\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003etry:\n    action.validate_params({\"query\": \"AI research\"})\n    # Parameters are valid\nexcept InvalidActionParams as e:\n    print(f\"Invalid parameters: {e}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eto_dict()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eReturns a dictionary representation of the action.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary containing name, description, and parameters\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eto_json()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eReturns a JSON string representing the action's schema.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eString containing JSON-formatted action schema\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eService APIs\u003c/h2\u003e\n\u003ch3\u003eData Service\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eDataService\u003c/code\u003e class handles data persistence operations, including articles, events, and logging.\u003c/p\u003e\n\u003ch4\u003e\u003ccode\u003e__init__(engine, feed_urls, embedding_model=None, sentiment_classifier=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the data service with database connection and processing models.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eengine\u003c/code\u003e: Database engine instance\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efeed_urls\u003c/code\u003e: List of RSS feed URLs to monitor\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eembedding_model\u003c/code\u003e: Optional sentence transformer model for embeddings\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esentiment_classifier\u003c/code\u003e: Optional pipeline for sentiment analysis\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003efetch_and_save_articles()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eFetches articles from configured RSS feeds and saves new ones to the database.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInteger: Number of new articles saved\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003enum_saved = await asyncio.to_thread(data_service.fetch_and_save_articles)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003edetect_and_save_events()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eAnalyzes recent articles to detect and save significant events.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInteger: Number of events detected and saved\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003enum_events = await asyncio.to_thread(data_service.detect_and_save_events)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_action_log(action_name, params, status, result)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePersists a record of an executed action to the database.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eaction_name\u003c/code\u003e: String name of the action\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eparams\u003c/code\u003e: Dictionary of action parameters\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003estatus\u003c/code\u003e: String status (\"success\" or \"error\")\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eresult\u003c/code\u003e: Any result data from action execution\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_mood_log(mood_vector)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves the current mood vector to the database.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emood_vector\u003c/code\u003e: Dictionary representing the current emotional state\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_situation_log(situation)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves a generated situation and returns its database ID.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esituation\u003c/code\u003e: Dictionary containing situation details\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInteger: Database ID of the saved situation\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_decision_log(situation_id, raw_response)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves a decision made by the AGI to the database.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esituation_id\u003c/code\u003e: Integer ID of the associated situation\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eraw_response\u003c/code\u003e: String containing the raw LLM response\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_experiment_log(hypothesis, *args)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves experiment results to the database with flexible calling conventions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ehypothesis\u003c/code\u003e: String describing the experiment hypothesis\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e*args\u003c/code\u003e: Either a single dict of results, or three arguments (test_plan, final_verdict, execution_result)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eTypeError\u003c/code\u003e: Raised when arguments don't match expected patterns\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Style 1: Dictionary of results\ndata_service.save_experiment_log(\"AI creativity improves with reflection\", {\"findings\": \"Positive correlation observed\"})\n\n# Style 2: Individual components\ndata_service.save_experiment_log(\n    \"Memory consolidation improves recall\",\n    \"Tested with 100 memory queries\",\n    \"Supported\",\n    {\"accuracy\": 0.92}\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eKnowledge Service\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eKnowledgeService\u003c/code\u003e manages the storage, retrieval, and compression of knowledge.\u003c/p\u003e\n\u003ch4\u003e\u003ccode\u003e__init__(engine, embedding_model=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the knowledge service with database connection and embedding model.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eengine\u003c/code\u003e: Database engine instance\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eembedding_model\u003c/code\u003e: Optional SentenceTransformer instance (defaults to 'all-MiniLM-L6-v2')\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Notes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAutomatically initializes FAISS index for semantic search if available\u003c/li\u003e\n\u003cli\u003eLoads existing index from disk or creates new one\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/knowledge_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eadd_knowledge(content, source=\"unknown\", category=\"misc\")\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eAdds new knowledge by summarizing content and saving it with metadata.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econtent\u003c/code\u003e: String content to be added\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esource\u003c/code\u003e: String source identifier (default: \"unknown\")\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecategory\u003c/code\u003e: String category (default: \"misc\")\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary containing:\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etimestamp\u003c/code\u003e: ISO format timestamp\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esummary\u003c/code\u003e: Generated summary text\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esource\u003c/code\u003e: Source identifier\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecategory\u003c/code\u003e: Category\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eduplicate\u003c/code\u003e: Boolean indicating if content already existed\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eid\u003c/code\u003e: Database ID (if new)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eValueError\u003c/code\u003e: When no content is provided\u003c/li\u003e\n\u003cli\u003eLogs and re-raises any other exceptions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = await asyncio.to_thread(\n    knowledge_service.add_knowledge,\n    \"Recent advances in quantum computing have enabled...\",\n    source=\"research_paper\",\n    category=\"science\"\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/knowledge_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eget_knowledge_by_category(category, limit=10)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves knowledge entries by category.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ecategory\u003c/code\u003e: String category to filter by\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elimit\u003c/code\u003e: Maximum number of results to return (default: 10)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eList of dictionaries containing knowledge entry details\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/knowledge_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eget_recent_knowledge(hours=24, limit=20)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves recently added knowledge entries.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ehours\u003c/code\u003e: Number of hours in the past to include (default: 24)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elimit\u003c/code\u003e: Maximum number of results (default: 20)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eList of knowledge entry dictionaries\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/knowledge_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esearch_knowledge(query, limit=10)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms text search in knowledge summaries.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003equery\u003c/code\u003e: Search query string\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elimit\u003c/code\u003e: Maximum results to return (default: 10)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eList of dictionaries with knowledge entries and relevance scores\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Notes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUses simple LIKE search; could be enhanced with full-text search\u003c/li\u003e\n\u003cli\u003eIncludes relevance_score based on keyword matching\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/knowledge_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ecompress_and_save_knowledge()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eCompresses recent knowledge into a summary and saves it.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary containing the generated summary\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLogs and re-raises any exceptions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003esummary = await asyncio.to_thread(knowledge_service.compress_and_save_knowledge)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/knowledge_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMemory Service\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eMemoryService\u003c/code\u003e provides an interface to the episodic memory system.\u003c/p\u003e\n\u003ch4\u003e\u003ccode\u003eget_relevant_memories(query_text)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves memories relevant to a query.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003equery_text\u003c/code\u003e: String query to find relevant memories\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable that resolves to a response object with relevant memories\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresponse = await memory_service.get_relevant_memories(\"vacation plans\")\nfor memory in response.relevant_memories:\n    print(f\"{memory.text} (similarity: {memory.similarity})\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/memory_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_memories(memories)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves a list of memories to persistent storage.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememories\u003c/code\u003e: List of memory strings or objects\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable (completes when save operation finishes)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait memory_service.save_memories([\"I planned a trip to Hawaii\", \"I enjoy hiking\"])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/memory_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eextract_memories(user_input, ai_output)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eExtracts memories from user-AI interaction.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003euser_input\u003c/code\u003e: String containing user message\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eai_output\u003c/code\u003e: String containing AI response\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to an object with extracted memories\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = await memory_service.extract_memories(\n    \"I'm planning a vacation to Hawaii\", \n    \"That sounds wonderful!\"\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/memory_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003econsolidate_memories()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms memory consolidation to optimize retrieval.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to consolidation results\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = await memory_service.consolidate_memories()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/memory_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMulti-modal Service\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eMultiModalService\u003c/code\u003e handles processing of images, audio, and cross-modal analysis.\u003c/p\u003e\n\u003ch4\u003e\u003ccode\u003e__init__()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the multi-modal service with supported formats and temporary directory.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Notes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreates temporary directory for processing files\u003c/li\u003e\n\u003cli\u003eDefines supported image and audio formats\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eprocess_image(image_path, prompt=\"Analyze this image in detail\")\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses an image file and returns detailed analysis.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eimage_path\u003c/code\u003e: String path to the image file\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprompt\u003c/code\u003e: Optional custom prompt for analysis (default: \"Analyze this image in detail\")\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary containing:\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etype\u003c/code\u003e: \"image\"\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epath\u003c/code\u003e: Original path\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eformat\u003c/code\u003e: File extension\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esize_bytes\u003c/code\u003e: File size\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edescription\u003c/code\u003e: AI-generated description\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eanalysis_prompt\u003c/code\u003e: Prompt used\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esuccess\u003c/code\u003e: Boolean indicating success\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eerror\u003c/code\u003e: Error message if unsuccessful\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eFileNotFoundError\u003c/code\u003e: When image file doesn't exist\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eValueError\u003c/code\u003e: When file format is unsupported\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = await multi_modal_service.process_image(\"/path/to/photo.jpg\")\nif result[\"success\"]:\n    print(result[\"description\"])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eprocess_audio(audio_path, prompt=\"Describe and analyze this audio\")\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses an audio file and returns analysis.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eaudio_path\u003c/code\u003e: String path to the audio file\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprompt\u003c/code\u003e: Optional custom prompt for analysis (default: \"Describe and analyze this audio\")\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with similar structure to process_image result\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eFileNotFoundError\u003c/code\u003e: When audio file doesn't exist\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eValueError\u003c/code\u003e: When file format is unsupported\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ecross_modal_analysis(content_list, analysis_prompt=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms analysis across multiple content types.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econtent_list\u003c/code\u003e: List of processed content objects (from process_image/process_audio)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eanalysis_prompt\u003c/code\u003e: Optional custom analysis prompt\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary containing cross-modal analysis\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eanalysis = await multi_modal_service.cross_modal_analysis([\n    image_result, \n    audio_result\n])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003egenerate_content_summary(processed_content)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eGenerates a comprehensive summary of multi-modal content.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eprocessed_content\u003c/code\u003e: List of processed content results\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eString summary of all content\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eprocess_directory(directory_path, recursive=False)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses all supported files in a directory.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edirectory_path\u003c/code\u003e: Path to directory to process\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erecursive\u003c/code\u003e: Whether to include subdirectories (default: False)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eList of processing results for each file\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ecleanup_temp_files(max_age_hours=24)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eCleans up temporary files older than specified age.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emax_age_hours\u003c/code\u003e: Maximum age in hours (default: 24)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Notes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRuns synchronously (not async)\u003c/li\u003e\n\u003cli\u003eUsed for maintenance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eModule-specific APIs\u003c/h2\u003e\n\u003ch3\u003eEpisodic Memory Client\u003c/h3\u003e\n\u003cp\u003eThe episodic memory client provides direct access to the memory database API.\u003c/p\u003e\n\u003ch4\u003e\u003ccode\u003eextract_memories(user_input, ai_output)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eCalls the /extract_memories/ endpoint to extract memories from conversation.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003euser_input\u003c/code\u003e: String user message\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eai_output\u003c/code\u003e: String AI response\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with extracted memories or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = extract_memories(\"I love hiking in the mountains\", \"That sounds invigorating!\")\nif result and 'memories' in result:\n    print(f\"Extracted: {result['memories']}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_memories(memories_list, memory_type='long-term')\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves a list of memories to the server.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememories_list\u003c/code\u003e: List of memory strings\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_type\u003c/code\u003e: String type of memory (default: 'long-term')\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with save response or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eget_relevant_memories(query_text, top_n=5, similarity_threshold=0.7)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves memories relevant to a query.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003equery_text\u003c/code\u003e: Search query\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etop_n\u003c/code\u003e: Maximum number of results (default: 5)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esimilarity_threshold\u003c/code\u003e: Minimum similarity score (default: 0.7)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with relevant memories or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ehealth_check()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eChecks the health of the memory database API.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with health status or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003ehealth = health_check()\nif health and health.get(\"status\") == \"ok\":\n    print(\"Memory API is healthy\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eupload_audio_file(file_path, context=None, extract_text=True)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eUploads an audio file and processes it into memory.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003efile_path\u003c/code\u003e: Path to the audio file\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtext\u003c/code\u003e: Optional context for transcription\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eextract_text\u003c/code\u003e: Whether to extract text from audio\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with processing result or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = upload_audio_file(\"meeting_recording.mp3\", context=\"Team meeting about project timeline\")\nif result and result[\"success\"]:\n    print(f\"Audio processed with transcript: {result['transcript']}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eupload_image_file(file_path, description=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eUploads an image file and processes it into memory.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003efile_path\u003c/code\u003e: Path to the image file\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edescription\u003c/code\u003e: Optional description of the image\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with processing result or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = upload_image_file(\"vacation_photo.jpg\", description=\"Sunset at the beach\")\nif result and result[\"success\"]:\n    print(f\"Image processed with description: {result['description']}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eadvanced_search(query, content_types=None, memory_types=None, search_mode=\"hybrid\")\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms advanced search with multiple filtering options.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003equery\u003c/code\u003e: Search query string\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_types\u003c/code\u003e: List of content types to include\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_types\u003c/code\u003e: List of memory types to include\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esearch_mode\u003c/code\u003e: Search mode (\"text\", \"vector\", \"hybrid\")\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with search results or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresults = advanced_search(\n    \"beach vacation\", \n    content_types=[\"image\", \"text\"], \n    memory_types=[\"episodic\"],\n    search_mode=\"hybrid\"\n)\nif results:\n    for result in results[\"results\"]:\n        print(f\"Found: {result['content_text']} (score: {result['similarity_score']})\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ebatch_process_files(file_paths, content_types=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses multiple files in batch.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003efile_paths\u003c/code\u003e: List of file paths to process\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_types\u003c/code\u003e: Optional list of content types corresponding to files\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDictionary with batch processing results or None on failure\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresults = batch_process_files([\n    \"notes.txt\", \n    \"meeting_recording.mp3\", \n    \"project_diagram.jpg\"\n])\nif results:\n    print(f\"Processed {results['successful_count']} of {results['total_processed']} files\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eReflection System\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eReflectionModule\u003c/code\u003e enables self-reflection capabilities.\u003c/p\u003e\n\u003ch4\u003e\u003ccode\u003e__init__(agi_system)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the reflection module with a reference to the AGI system.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eagi_system\u003c/code\u003e: Reference to the main AGISystem instance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/reflection_module.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ereflect_on_experiment(experiment_results)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eAnalyzes experiment results and generates insights.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eexperiment_results\u003c/code\u003e: Dictionary containing experiment data including 'hypothesis' and 'findings'\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Notes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAutomatically adds generated insights to the knowledge base\u003c/li\u003e\n\u003cli\u003eUses \"reflection\" as source and \"insight\" as category\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/reflection_module.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ereflect(shared_state)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms general reflection based on the system's state.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eshared_state\u003c/code\u003e: SharedState object containing mood history and other state\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Notes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCurrently focuses on mood history analysis\u003c/li\u003e\n\u003cli\u003ePlaceholder for more sophisticated reflection logic\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/reflection_module.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eMulti-modal Memory Service\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eMultiModalMemoryService\u003c/code\u003e is the main orchestration class for the multi-modal memory system, integrating PostgreSQL storage, embeddings, Whisper audio processing, and advanced search capabilities.\u003c/p\u003e\n\u003ch3\u003eMethods\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003e__init__(database_url, text_model_name=\"all-MiniLM-L6-v2\", whisper_model_size=\"base\", device=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the multi-modal memory service with all required components.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edatabase_url\u003c/code\u003e: PostgreSQL connection URL\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etext_model_name\u003c/code\u003e: SentenceTransformer model name for text embeddings\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ewhisper_model_size\u003c/code\u003e: Whisper model size for audio processing\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edevice\u003c/code\u003e: Device to use (\"cpu\", \"cuda\", \"auto\")\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eservice = MultiModalMemoryService(\n    database_url=\"postgresql://user:pass@localhost:5432/ravana\",\n    text_model_name=\"all-MiniLM-L6-v2\",\n    whisper_model_size=\"base\"\n)\nawait service.initialize()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003einitialize()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes all service components and establishes database connections.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable that completes when initialization is finished\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRaises exception if initialization fails\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003etry:\n    await service.initialize()\n    print(\"Service initialized successfully\")\nexcept Exception as e:\n    print(f\"Initialization failed: {e}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eclose()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eCloses all service components gracefully and releases resources.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable that completes when shutdown is finished\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait service.close()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eprocess_text_memory(text, memory_type=\"episodic\", tags=None, emotional_valence=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses and stores text memory with embeddings.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etext\u003c/code\u003e: Text content to store\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_type\u003c/code\u003e: Type of memory (\"episodic\", \"semantic\", \"procedural\")\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etags\u003c/code\u003e: Optional list of tags\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eemotional_valence\u003c/code\u003e: Emotional valence (-1.0 to 1.0)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to the stored MemoryRecord\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003erecord = await service.process_text_memory(\n    \"I enjoyed the concert last night\",\n    memory_type=\"episodic\",\n    tags=[\"entertainment\", \"music\"],\n    emotional_valence=0.8\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eprocess_audio_memory(audio_path, context=None, memory_type=\"episodic\", tags=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses and stores audio memory with Whisper transcription and embeddings.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eaudio_path\u003c/code\u003e: Path to the audio file\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtext\u003c/code\u003e: Optional context for transcription\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_type\u003c/code\u003e: Type of memory\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etags\u003c/code\u003e: Optional list of tags\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to the stored MemoryRecord\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003erecord = await service.process_audio_memory(\n    \"meeting_recording.mp3\",\n    context=\"Team meeting about project timeline\",\n    tags=[\"work\", \"meetings\"]\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eprocess_image_memory(image_path, description=None, memory_type=\"episodic\", tags=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses and stores image memory with metadata and embeddings.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eimage_path\u003c/code\u003e: Path to the image file\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edescription\u003c/code\u003e: Optional image description\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_type\u003c/code\u003e: Type of memory\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etags\u003c/code\u003e: Optional list of tags\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to the stored MemoryRecord\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003erecord = await service.process_image_memory(\n    \"vacation_photo.jpg\",\n    description=\"Sunset at the beach\",\n    tags=[\"vacation\", \"nature\"]\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eextract_memories_from_conversation(request)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eExtracts memories from a conversation using LLM analysis.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003erequest\u003c/code\u003e: ConversationRequest object with user_input, ai_output, and context\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to MemoriesList object\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003erequest = ConversationRequest(\n    user_input=\"I'm planning a trip to Japan next spring\",\n    ai_output=\"That sounds like an amazing adventure!\",\n    context=\"Travel planning conversation\"\n)\nmemories = await service.extract_memories_from_conversation(request)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_extracted_memories(memories_list)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves a list of extracted memories to the database.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememories_list\u003c/code\u003e: MemoriesList object containing memories to save\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of saved MemoryRecord objects\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003esaved_records = await service.save_extracted_memories(memories_list)\nprint(f\"Saved {len(saved_records)} memories\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esearch_memories(request)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSearches memories using advanced search capabilities.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003erequest\u003c/code\u003e: SearchRequest object with query and search parameters\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to SearchResponse object\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003erequest = SearchRequest(\n    query=\"beach vacation\",\n    content_types=[ContentType.IMAGE, ContentType.TEXT],\n    memory_types=[MemoryType.EPISODIC],\n    search_mode=SearchMode.HYBRID,\n    limit=10,\n    similarity_threshold=0.7\n)\nresponse = await service.search_memories(request)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003efind_similar_memories(memory_id, limit=10, similarity_threshold=0.7)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eFinds memories similar to a given memory.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememory_id\u003c/code\u003e: UUID of the reference memory\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elimit\u003c/code\u003e: Maximum number of similar memories to return\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esimilarity_threshold\u003c/code\u003e: Minimum similarity score (0.0 to 1.0)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of similar MemoryRecord objects\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003esimilar_memories = await service.find_similar_memories(\n    memory_id=\"a1b2c3d4-e5f6-7890-1234-567890abcdef\",\n    limit=5,\n    similarity_threshold=0.8\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ebatch_process_files(request)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eProcesses multiple files in batch with parallel processing.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003erequest\u003c/code\u003e: BatchProcessRequest object with file paths and processing options\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to BatchProcessResult object\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003erequest = BatchProcessRequest(\n    file_paths=[\"notes.txt\", \"meeting.mp3\", \"diagram.jpg\"],\n    parallel_processing=True,\n    max_workers=4\n)\nresult = await service.batch_process_files(request)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eget_memory_statistics()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves comprehensive statistics about the memory system.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to MemoryStatistics object\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003estats = await service.get_memory_statistics()\nprint(f\"Total memories: {stats.total_memories}\")\nprint(f\"Storage size: {stats.storage_size_mb:.2f} MB\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003econsolidate_memories(memory_ids=None, max_memories=50)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eConsolidates memories to optimize storage and retrieval.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememory_ids\u003c/code\u003e: Optional list of specific memory IDs to consolidate\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emax_memories\u003c/code\u003e: Maximum number of memories to process\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to dictionary with consolidation results\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresult = await service.consolidate_memories(\n    memory_ids=[\"a1b2c3d4-e5f6-7890-1234-567890abcdef\"],\n    max_memories=100\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ehealth_check()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms a comprehensive health check of the memory system.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to dictionary with health status\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003ehealth = await service.health_check()\nif health[\"status\"] == \"healthy\":\n    print(\"Memory system is healthy\")\nelse:\n    print(f\"Memory system status: {health['status']}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eMemory Models\u003c/h2\u003e\n\u003cp\u003eThis section documents the data models used in the multi-modal memory system, defining the structure of memory records, search requests, and responses.\u003c/p\u003e\n\u003ch3\u003eCore Data Models\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003eMemoryRecord\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eMain memory record model containing all memory data and metadata.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eid\u003c/code\u003e: Optional UUID for the memory record\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_type\u003c/code\u003e: ContentType enum value (TEXT, AUDIO, IMAGE, VIDEO)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_text\u003c/code\u003e: Optional text content\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_metadata\u003c/code\u003e: Dictionary of additional metadata\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efile_path\u003c/code\u003e: Optional path to associated file\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etext_embedding\u003c/code\u003e: Optional list of floats for text embedding\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eimage_embedding\u003c/code\u003e: Optional list of floats for image embedding\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eaudio_embedding\u003c/code\u003e: Optional list of floats for audio embedding\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eunified_embedding\u003c/code\u003e: Optional list of floats for combined embedding\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecreated_at\u003c/code\u003e: Optional datetime of creation\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elast_accessed\u003c/code\u003e: Optional datetime of last access\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eaccess_count\u003c/code\u003e: Integer count of accesses\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_type\u003c/code\u003e: MemoryType enum value (EPISODIC, SEMANTIC, PROCEDURAL)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eemotional_valence\u003c/code\u003e: Optional float (-1.0 to 1.0) for emotional valence\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econfidence_score\u003c/code\u003e: Float (0.0 to 1.0) for confidence in memory\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etags\u003c/code\u003e: List of string tags\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eaudio_metadata\u003c/code\u003e: Optional AudioMetadata object\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eimage_metadata\u003c/code\u003e: Optional ImageMetadata object\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003evideo_metadata\u003c/code\u003e: Optional VideoMetadata object\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eSearchRequest\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRequest model for memory search operations with advanced filtering.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003equery\u003c/code\u003e: Search query string (1-1000 characters)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_types\u003c/code\u003e: Optional list of ContentType values to filter by\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_types\u003c/code\u003e: Optional list of MemoryType values to filter by\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esearch_mode\u003c/code\u003e: SearchMode enum value (TEXT, VECTOR, HYBRID)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elimit\u003c/code\u003e: Integer limit on results (1-100)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esimilarity_threshold\u003c/code\u003e: Float threshold for similarity (0.0-1.0)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003einclude_metadata\u003c/code\u003e: Boolean to include metadata in results\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etags\u003c/code\u003e: Optional list of tags to filter by\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003equery_content_type\u003c/code\u003e: Optional ContentType for cross-modal search\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etarget_content_types\u003c/code\u003e: Optional list of target types for cross-modal search\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecreated_after\u003c/code\u003e: Optional datetime filter for creation date\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecreated_before\u003c/code\u003e: Optional datetime filter for creation date\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eSearchResponse\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eResponse model for search operations containing results and metadata.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eresults\u003c/code\u003e: List of SearchResult objects\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etotal_found\u003c/code\u003e: Integer count of total matching memories\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esearch_time_ms\u003c/code\u003e: Integer search duration in milliseconds\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esearch_mode\u003c/code\u003e: SearchMode enum value used\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003equery_metadata\u003c/code\u003e: Dictionary of additional query metadata\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eConversationRequest\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRequest model for memory extraction from conversations.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003euser_input\u003c/code\u003e: User message text (required)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eai_output\u003c/code\u003e: AI response text (required)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtext\u003c/code\u003e: Optional context for extraction\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eextract_emotions\u003c/code\u003e: Boolean to extract emotional content\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_type\u003c/code\u003e: MemoryType enum value for extracted memories\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eMemoriesList\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eList of extracted memories with metadata.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememories\u003c/code\u003e: List of memory text strings\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ememory_type\u003c/code\u003e: MemoryType enum value for all memories\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econfidence_scores\u003c/code\u003e: Optional list of confidence scores\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eemotional_valences\u003c/code\u003e: Optional list of emotional valences\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eContent Type Models\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003eAudioMetadata\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eMetadata specific to audio content.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etranscript\u003c/code\u003e: Optional transcription text\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elanguage_code\u003c/code\u003e: Optional language code (e.g., \"en\")\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econfidence_scores\u003c/code\u003e: Dictionary of confidence scores\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eduration_seconds\u003c/code\u003e: Optional duration in seconds\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eaudio_features\u003c/code\u003e: Dictionary of audio analysis features\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esample_rate\u003c/code\u003e: Optional sample rate in Hz\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003echannels\u003c/code\u003e: Optional number of audio channels\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eImageMetadata\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eMetadata specific to image content.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ewidth\u003c/code\u003e: Optional image width in pixels\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eheight\u003c/code\u003e: Optional image height in pixels\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eobject_detections\u003c/code\u003e: Dictionary of detected objects\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003escene_description\u003c/code\u003e: Optional scene description\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eimage_hash\u003c/code\u003e: Optional perceptual hash\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecolor_palette\u003c/code\u003e: List of dominant colors\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eimage_features\u003c/code\u003e: Dictionary of image analysis features\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eVideoMetadata\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eMetadata specific to video content.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Attributes\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eduration_seconds\u003c/code\u003e: Optional duration in seconds\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eframe_rate\u003c/code\u003e: Optional frame rate in fps\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ewidth\u003c/code\u003e: Optional video width in pixels\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eheight\u003c/code\u003e: Optional video height in pixels\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003evideo_features\u003c/code\u003e: Dictionary of video analysis features\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ethumbnail_path\u003c/code\u003e: Optional path to thumbnail image\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eEnumerations\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003eContentType\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eEnumeration of supported content types.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Values\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eTEXT\u003c/code\u003e: Text content\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAUDIO\u003c/code\u003e: Audio content\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eIMAGE\u003c/code\u003e: Image content\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eVIDEO\u003c/code\u003e: Video content\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eMemoryType\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eEnumeration of memory types.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Values\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eEPISODIC\u003c/code\u003e: Episodic memories (personal experiences)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSEMANTIC\u003c/code\u003e: Semantic memories (facts and knowledge)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ePROCEDURAL\u003c/code\u003e: Procedural memories (skills and procedures)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eSearchMode\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eEnumeration of search modes.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Values\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eTEXT\u003c/code\u003e: Text-based search\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eVECTOR\u003c/code\u003e: Vector similarity search\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eHYBRID\u003c/code\u003e: Hybrid search combining text and vector\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003ePostgreSQL Store\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003ePostgreSQLStore\u003c/code\u003e class handles database operations for the multi-modal memory system with pgvector support for similarity search.\u003c/p\u003e\n\u003ch3\u003eMethods\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003e__init__(database_url, pool_size=10, max_connections=20)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the PostgreSQL store with connection parameters.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edatabase_url\u003c/code\u003e: PostgreSQL connection URL\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epool_size\u003c/code\u003e: Minimum connection pool size\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emax_connections\u003c/code\u003e: Maximum connection pool size\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRaises ImportError if AsyncPG is not available\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003einitialize()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the database connection pool.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable that completes when initialization is finished\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRaises exception if initialization fails\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait store.initialize()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eclose()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eCloses the database connection pool.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable that completes when closure is finished\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait store.close()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003esave_memory_record(memory_record)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eSaves a memory record to the database.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememory_record\u003c/code\u003e: MemoryRecord object to save\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to the saved MemoryRecord\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRaises exception if save fails\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003esaved_record = await store.save_memory_record(memory_record)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eget_memory_record(memory_id)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves a memory record by ID.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememory_id\u003c/code\u003e: UUID of the memory record\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to MemoryRecord or None if not found\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003erecord = await store.get_memory_record(\"a1b2c3d4-e5f6-7890-1234-567890abcdef\")\nif record:\n    print(f\"Found memory: {record.content_text}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003evector_search(embedding, embedding_type=\"text\", limit=10, similarity_threshold=0.7, content_types=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms vector similarity search.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eembedding\u003c/code\u003e: List of floats representing the query embedding\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eembedding_type\u003c/code\u003e: Type of embedding (\"text\", \"image\", \"audio\", \"unified\")\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elimit\u003c/code\u003e: Maximum number of results to return\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esimilarity_threshold\u003c/code\u003e: Minimum similarity score (0.0-1.0)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_types\u003c/code\u003e: Optional list of ContentType values to filter by\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of (MemoryRecord, similarity_score) tuples\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresults = await store.vector_search(\n    embedding=[0.1, 0.2, 0.3, ...],\n    embedding_type=\"text\",\n    limit=5,\n    similarity_threshold=0.8\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003etext_search(query_text, limit=10, content_types=None)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003ePerforms full-text search.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003equery_text\u003c/code\u003e: Search query string\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elimit\u003c/code\u003e: Maximum number of results to return\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econtent_types\u003c/code\u003e: Optional list of ContentType values to filter by\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of (MemoryRecord, relevance_score) tuples\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresults = await store.text_search(\"beach vacation\", limit=10)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003edelete_memory_record(memory_id)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eDeletes a memory record by ID.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememory_id\u003c/code\u003e: UUID of the memory record to delete\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to boolean (True if deleted, False if not found)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edeleted = await store.delete_memory_record(\"a1b2c3d4-e5f6-7890-1234-567890abcdef\")\nif deleted:\n    print(\"Memory deleted successfully\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003eget_memory_statistics()\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eRetrieves comprehensive statistics about the memory system.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to dictionary with statistics\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003estats = await store.get_memory_statistics()\nprint(f\"Total memories: {stats['total_memories']}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003ecleanup_old_memories(days_old=30, keep_minimum=1000)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eCleans up old, rarely accessed memories.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edays_old\u003c/code\u003e: Age threshold in days\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekeep_minimum\u003c/code\u003e: Minimum number of memories to keep\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to integer count of deleted memories\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edeleted_count = await store.cleanup_old_memories(days_old=60, keep_minimum=500)\nprint(f\"Cleaned up {deleted_count} old memories\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eEmbedding Service\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eEmbeddingService\u003c/code\u003e class handles the generation of embeddings for multi-modal content, supporting text, image, audio, and unified embeddings.\u003c/p\u003e\n\u003ch3\u003eMethods\u003c/h3\u003e\n\u003ch4\u003e\u003ccode\u003e__init__(text_model_name=\"all-MiniLM-L6-v2\", device=None, cache_size=1000)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eInitializes the embedding service with configuration parameters.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etext_model_name\u003c/code\u003e: Name of the sentence transformer model\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edevice\u003c/code\u003e: Device to use (\"cpu\", \"cuda\", \"auto\")\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecache_size\u003c/code\u003e: Size of the embedding cache\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Exceptions\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRaises ImportError if transformers dependencies are not available\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eservice = EmbeddingService(\n    text_model_name=\"all-MiniLM-L6-v2\",\n    device=\"cuda\",\n    cache_size=2000\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/embedding_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003egenerate_text_embedding(text)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eGenerates embedding for text content.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etext\u003c/code\u003e: Text string to embed\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of floats (embedding values)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eembedding = await service.generate_text_embedding(\"This is a sample text\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/embedding_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003egenerate_image_embedding(image_path)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eGenerates embedding for image content.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eimage_path\u003c/code\u003e: Path to the image file\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of floats (embedding values)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eembedding = await service.generate_image_embedding(\"photo.jpg\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/embedding_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003egenerate_audio_embedding(audio_features)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eGenerates embedding for audio content from extracted features.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eaudio_features\u003c/code\u003e: Dictionary of audio analysis features\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of floats (embedding values)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eembedding = await service.generate_audio_embedding({\n    \"mfcc\": {\"mean\": [...], \"std\": [...]},\n    \"spectral_centroid\": {\"mean\": 1000.0, \"std\": 200.0}\n})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/embedding_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003egenerate_unified_embedding(memory_record)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eGenerates unified embedding combining all available modalities.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememory_record\u003c/code\u003e: MemoryRecord object with various embeddings\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to list of floats (unified embedding values)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eunified_embedding = await service.generate_unified_embedding(memory_record)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/embedding_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003e\u003ccode\u003egenerate_embeddings(memory_record)\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003eGenerates all relevant embeddings for a memory record.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:Parameters\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ememory_record\u003c/code\u003e: MemoryRecord object to process\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Returns\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAwaitable resolving to MemoryRecord with embeddings populated\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e:Usage\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eprocessed_record = await service.generate_embeddings(memory_record)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/embedding_service.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eInitialization and Lifecycle Management\u003c/h2\u003e\n\u003cp\u003eThe AGI system follows a specific initialization and lifecycle pattern to ensure proper setup and graceful shutdown.\u003c/p\u003e\n\u003ch3\u003eInitialization Pattern\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom sqlalchemy import create_engine\nfrom core.system import AGISystem\n\n# Create database engine\nengine = create_engine(\"sqlite:///ravana.db\")\n\n# Initialize AGI system\nagi = AGISystem(engine)\n\n# System is now ready for use\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe initialization process:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCreates all service instances (data, knowledge, memory)\u003c/li\u003e\n\u003cli\u003eInitializes modules (situation generator, emotional intelligence, etc.)\u003c/li\u003e\n\u003cli\u003eSets up shared state and behavior modifiers\u003c/li\u003e\n\u003cli\u003ePrepares background tasks (not started yet)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eLifecycle Management\u003c/h3\u003e\n\u003cp\u003eThe AGI system supports both autonomous and task-based operation modes:\u003c/p\u003e\n\u003ch4\u003eAutonomous Mode\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport asyncio\n\nasync def main():\n    try:\n        await agi.run_autonomous_loop()\n    except KeyboardInterrupt:\n        await agi.stop()\n\nasyncio.run(main())\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eSingle Task Mode\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait agi.run_single_task(\"Research renewable energy technologies\")\nawait agi.stop()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eGraceful Shutdown\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eawait agi.stop()  # Cancels background tasks and closes resources\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe system uses an asyncio.Event for shutdown signaling and properly cancels all background tasks.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eThread Safety and Async Usage\u003c/h2\u003e\n\u003cp\u003eThe AGI system is designed for asynchronous operation with careful consideration of thread safety.\u003c/p\u003e\n\u003ch3\u003eAsync/Await Usage\u003c/h3\u003e\n\u003cp\u003eMost methods are coroutines and must be awaited:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Correct usage\nawait agi.run_iteration()\nawait agi._handle_curiosity()\n\n# Incorrect usage (will return coroutine object)\nagi.run_iteration()  # Missing await\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eThread Safety Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDatabase operations use \u003ccode\u003easyncio.to_thread()\u003c/code\u003e for synchronous calls\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003eEnhancedActionManager\u003c/code\u003e handles action execution in thread pool\u003c/li\u003e\n\u003cli\u003eShared state modifications are coordinated through the main event loop\u003c/li\u003e\n\u003cli\u003eBackground tasks are properly managed and canceled on shutdown\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eBackground Tasks\u003c/h3\u003e\n\u003cp\u003eThe system manages several background tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eData collection (RSS feeds)\u003c/li\u003e\n\u003cli\u003eEvent detection\u003c/li\u003e\n\u003cli\u003eKnowledge compression\u003c/li\u003e\n\u003cli\u003eMemory consolidation\u003c/li\u003e\n\u003cli\u003eInvention tracking\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese tasks are automatically started in \u003ccode\u003erun_autonomous_loop()\u003c/code\u003e and properly cleaned up in \u003ccode\u003estop()\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eError Handling\u003c/h2\u003e\n\u003cp\u003eThe system implements comprehensive error handling at multiple levels.\u003c/p\u003e\n\u003ch3\u003eException Types\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eInvalidActionParams\u003c/code\u003e: Raised when action parameters are invalid\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eValueError\u003c/code\u003e: Used for validation errors (e.g., empty content)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eTypeError\u003c/code\u003e: For incorrect argument types\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eFileNotFoundError\u003c/code\u003e: When files don't exist\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ejson.JSONDecodeError\u003c/code\u003e: When parsing JSON fails\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eError Handling Patterns\u003c/h3\u003e\n\u003ch4\u003eService-Level Error Handling\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003etry:\n    result = await self.memory_service.extract_memories(interaction_summary, \"\")\n    if result and result.memories:\n        await self.memory_service.save_memories(result.memories)\nexcept Exception as e:\n    logger.error(f\"Failed during memorization: {e}\", exc_info=True)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eBackground Task Error Handling\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003ewhile not self._shutdown.is_set():\n    try:\n        # Task logic here\n        pass\n    except asyncio.CancelledError:\n        break\n    except Exception as e:\n        logger.error(f\"Error in task: {e}\", exc_info=True)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eExternal API Error Handling\u003c/h4\u003e\n\u003cp\u003eThe episodic memory client implements retry logic:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMaximum of 3 retries for connection errors\u003c/li\u003e\n\u003cli\u003e1-second delay between retries\u003c/li\u003e\n\u003cli\u003eComprehensive error reporting\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eUsage Examples\u003c/h2\u003e\n\u003ch3\u003eBasic System Initialization and Operation\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom sqlalchemy import create_engine\nfrom core.system import AGISystem\nimport asyncio\n\nasync def main():\n    # Initialize system\n    engine = create_engine(\"sqlite:///ravana.db\")\n    agi = AGISystem(engine)\n    \n    try:\n        # Run autonomous loop\n        await agi.run_autonomous_loop()\n    except KeyboardInterrupt:\n        print(\"Shutting down...\")\n        await agi.stop()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eExecuting a Single Task\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def execute_research_task():\n    agi = AGISystem(engine)\n    \n    # Run a specific task\n    await agi.run_single_task(\"Investigate the impact of climate change on coastal cities\")\n    \n    # Get recent events\n    events = await agi.get_recent_events(3600)\n    print(f\"Found {len(events)} recent events\")\n    \n    # Shutdown\n    await agi.stop()\n\nasyncio.run(execute_research_task())\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eUsing the Multi-modal Service\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def analyze_media():\n    multi_modal = MultiModalService()\n    \n    # Process an image\n    image_result = await multi_modal.process_image(\"photo.jpg\")\n    \n    # Process an audio file\n    audio_result = await multi_modal.process_audio(\"recording.mp3\")\n    \n    # Cross-modal analysis\n    analysis = await multi_modal.cross_modal_analysis([\n        image_result, \n        audio_result\n    ])\n    \n    # Generate summary\n    summary = await multi_modal.generate_content_summary([\n        image_result, \n        audio_result\n    ])\n    \n    print(summary)\n\nasyncio.run(analyze_media())\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eWorking with the Memory System\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Direct client usage\ndef manage_memories():\n    # Extract memories from conversation\n    result = extract_memories(\n        \"I'm planning a trip to Japan next spring\", \n        \"That sounds like an amazing adventure!\"\n    )\n    \n    if result and 'memories' in result:\n        # Save extracted memories\n        save_response = save_memories(result['memories'])\n        \n        # Retrieve relevant memories later\n        relevant = get_relevant_memories(\"travel plans\", top_n=3)\n        for mem in relevant['relevant_memories']:\n            print(f\"Found: {mem['text']}\")\n\nmanage_memories()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAdding Knowledge\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def add_research_knowledge():\n    knowledge_service = KnowledgeService(engine)\n    \n    research_content = \"\"\"\n    Recent studies show that neural network pruning can reduce model size \n    by up to 90% with minimal accuracy loss. This technique involves \n    removing redundant weights and neurons from trained models.\n    \"\"\"\n    \n    result = await asyncio.to_thread(\n        knowledge_service.add_knowledge,\n        content=research_content,\n        source=\"research_paper\",\n        category=\"machine_learning\"\n    )\n    \n    if not result.get('duplicate'):\n        print(f\"Added new knowledge with ID: {result['id']}\")\n    else:\n        print(\"Knowledge already existed in database\")\n\nasyncio.run(add_research_knowledge())\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAdvanced Memory Operations\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def advanced_memory_operations():\n    # Initialize multi-modal memory service\n    service = MultiModalMemoryService(\n        database_url=\"postgresql://user:pass@localhost:5432/ravana\"\n    )\n    await service.initialize()\n    \n    # Process different types of memories\n    text_record = await service.process_text_memory(\n        \"I learned about quantum computing today\",\n        tags=[\"learning\", \"science\"]\n    )\n    \n    audio_record = await service.process_audio_memory(\n        \"lecture_recording.mp3\",\n        context=\"Physics lecture on quantum mechanics\"\n    )\n    \n    image_record = await service.process_image_memory(\n        \"quantum_diagram.jpg\",\n        description=\"Diagram explaining quantum entanglement\"\n    )\n    \n    # Advanced search\n    search_request = SearchRequest(\n        query=\"quantum computing\",\n        content_types=[ContentType.TEXT, ContentType.AUDIO, ContentType.IMAGE],\n        search_mode=SearchMode.HYBRID,\n        limit=5\n    )\n    search_response = await service.search_memories(search_request)\n    \n    # Display results\n    for result in search_response.results:\n        print(f\"Found: {result.memory_record.content_text[:100]}... \"\n              f\"(score: {result.similarity_score:.3f})\")\n    \n    # Batch processing\n    batch_request = BatchProcessRequest(\n        file_paths=[\"notes1.txt\", \"notes2.txt\", \"lecture.mp3\"],\n        parallel_processing=True\n    )\n    batch_result = await service.batch_process_files(batch_request)\n    \n    print(f\"Processed {batch_result.successful_count}/{batch_result.total_processed} files\")\n    \n    # Cleanup\n    await service.close()\n\nasyncio.run(advanced_memory_operations())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eReferenced Files in This Document\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e - \u003cem\u003eUpdated in recent commit\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/actions/action.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/knowledge_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/memory_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/multi_modal_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/client.py\u003c/a\u003e - \u003cem\u003eEnhanced with new features\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/multi_modal_service.py\u003c/a\u003e - \u003cem\u003eAdded in recent commit\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/models.py\u003c/a\u003e - \u003cem\u003eAdded in recent commit\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/postgresql_store.py\u003c/a\u003e - \u003cem\u003eAdded in recent commit\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/episodic_memory/embedding_service.py\u003c/a\u003e - \u003cem\u003eAdded in recent commit\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/reflection_module.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n"},"docs":[{"slug":"Action System","title":"Action System"},{"slug":"API Reference","title":"API Reference"},{"slug":"Architecture \u0026 Design","title":"Architecture \u0026 Design"},{"slug":"Configuration","title":"Configuration"},{"slug":"Conversational AI Communication Framework","title":"Conversational AI Communication Framework"},{"slug":"Core System","title":"Core System"},{"slug":"Database Schema","title":"Database Schema"},{"slug":"Decision-Making System","title":"Decision-Making System"},{"slug":"Deployment \u0026 Operations","title":"Deployment \u0026 Operations"},{"slug":"Development Guide","title":"Development Guide"},{"slug":"Emotional Intelligence","title":"Emotional Intelligence"},{"slug":"Enhanced Snake Agent","title":"Enhanced Snake Agent"},{"slug":"Enhanced Snake Agent Architecture","title":"Enhanced Snake Agent Architecture"},{"slug":"Graceful Shutdown","title":"Graceful Shutdown"},{"slug":"LLM Integration","title":"LLM Integration"},{"slug":"Memory Systems","title":"Memory Systems"},{"slug":"Multi-Modal Memory","title":"Multi-Modal Memory"},{"slug":"Project Overview","title":"Project Overview"},{"slug":"Self-Improvement","title":"Self-Improvement"},{"slug":"Services","title":"Services"},{"slug":"Snake Agent Configuration","title":"Snake Agent Configuration"},{"slug":"Specialized Modules-57f9b30b-b165-48d3-8e89-196940d26190","title":"Specialized Modules"},{"slug":"Specialized Modules","title":"Specialized Modules"}]},"__N_SSG":true},"page":"/docs/[slug]","query":{"slug":"API Reference"},"buildId":"QHWQNiRZOuW15nbk5-ngt","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>