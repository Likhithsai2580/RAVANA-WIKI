<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta charSet="utf-8"/><title>Emotional Intelligence<!-- --> - RAVANA AGI Documentation</title><meta name="description" content="Documentation for Emotional Intelligence"/><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/aa7d986e9c238cc1.css" as="style"/><link rel="stylesheet" href="/_next/static/css/aa7d986e9c238cc1.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js" defer="" data-nscript="beforeInteractive"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js" defer="" data-nscript="beforeInteractive"></script><script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.0/dist/mermaid.min.js" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-eb143115b8bf2786.js" defer=""></script><script src="/_next/static/chunks/pages/_app-a41459f5c0b49356.js" defer=""></script><script src="/_next/static/chunks/664-d254d21a6fe56bff.js" defer=""></script><script src="/_next/static/chunks/pages/docs/%5Bslug%5D-37d587d3c8e56222.js" defer=""></script><script src="/_next/static/QHWQNiRZOuW15nbk5-ngt/_buildManifest.js" defer=""></script><script src="/_next/static/QHWQNiRZOuW15nbk5-ngt/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="min-h-screen flex flex-col"><div class="min-h-screen flex flex-col"><header class="bg-wiki-blue text-white p-4 shadow-md"><div class="container mx-auto flex justify-between items-center"><h1 class="text-2xl font-bold">RAVANA AGI Documentation</h1><nav><ul class="flex space-x-4"><li><a class="hover:underline" href="/">Home</a></li></ul></nav></div></header><div class="flex-grow container mx-auto p-4 flex flex-col md:flex-row gap-6"><div class="w-full md:w-64 flex-shrink-0"><nav class="w-full md:w-64 flex-shrink-0"><div class="bg-white rounded-lg shadow p-4 sticky top-4"><h3 class="font-bold text-lg mb-3">Documentation</h3><ul class="space-y-1"><li class="mb-3"><div class="font-semibold text-gray-700">A</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Action%20System">Action System</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/API%20Reference">API Reference</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Architecture%20&amp;%20Design">Architecture &amp; Design</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">C</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Configuration">Configuration</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Conversational%20AI%20Communication%20Framework">Conversational AI Communication Framework</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Core%20System">Core System</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">D</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Database%20Schema">Database Schema</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Decision-Making%20System">Decision-Making System</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Deployment%20&amp;%20Operations">Deployment &amp; Operations</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Development%20Guide">Development Guide</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">E</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 bg-wiki-blue text-white" href="/docs/Emotional%20Intelligence">Emotional Intelligence</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Enhanced%20Snake%20Agent">Enhanced Snake Agent</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Enhanced%20Snake%20Agent%20Architecture">Enhanced Snake Agent Architecture</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">G</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Graceful%20Shutdown">Graceful Shutdown</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">L</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/LLM%20Integration">LLM Integration</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">M</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Memory%20Systems">Memory Systems</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Multi-Modal%20Memory">Multi-Modal Memory</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">P</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Project%20Overview">Project Overview</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">S</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Self-Improvement">Self-Improvement</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Services">Services</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Snake%20Agent%20Configuration">Snake Agent Configuration</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Specialized%20Modules-57f9b30b-b165-48d3-8e89-196940d26190">Specialized Modules</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Specialized%20Modules">Specialized Modules</a></li></ul></li></ul></div></nav></div><main class="flex-grow"><nav class="mb-4 text-sm"><ol class="list-none p-0 inline-flex"><li class="flex items-center"><a class="text-wiki-blue hover:underline" href="/">Home</a><svg class="fill-current w-3 h-3 mx-3" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"></path></svg></li><li class="flex items-center"><span class="text-gray-500">Emotional Intelligence</span></li></ol></nav><div class="flex flex-col md:flex-row gap-6"><article class="prose max-w-none bg-white p-6 rounded-lg shadow flex-grow"><h1>Emotional Intelligence</h1><div><h1>Emotional Intelligence</h1>
<h2>Update Summary</h2>
<p><strong>Changes Made</strong></p>
<ul>
<li>Updated <strong>Conversational AI Integration</strong> section to reflect enhanced JSON parsing error logging in thought extraction</li>
<li>Added detailed error logging information for JSONDecodeError in the ConversationalEmotionalIntelligence class</li>
<li>Enhanced documentation of debug-level logging for full LLM responses during thought extraction</li>
<li>Updated code examples to reflect improved error handling and logging practices</li>
<li>Added information about debug logging of full LLM responses for diagnostic purposes</li>
<li>Updated section sources to reflect the specific files analyzed in this update</li>
</ul>
<h2>Table of Contents</h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#mood-modeling-and-tracking">Mood Modeling and Tracking</a></li>
<li><a href="#moodprocessor-calculating-emotional-shifts">MoodProcessor: Calculating Emotional Shifts</a></li>
<li><a href="#emotionalintelligence-response-generation-and-behavior-influence">EmotionalIntelligence: Response Generation and Behavior Influence</a></li>
<li><a href="#persona-management-and-personality-traits">Persona Management and Personality Traits</a></li>
<li><a href="#integration-with-decision-making-and-memory">Integration with Decision-Making and Memory</a></li>
<li><a href="#emotional-event-logging">Emotional Event Logging</a></li>
<li><a href="#conversational-ai-integration">Conversational AI Integration</a></li>
<li><a href="#emotional-context-synchronization">Emotional Context Synchronization</a></li>
<li><a href="#mood-transition-logic-and-examples">Mood Transition Logic and Examples</a></li>
<li><a href="#common-issues-and-best-practices">Common Issues and Best Practices</a></li>
</ol>
<h2>Introduction</h2>
<p>The Emotional Intelligence system in the RAVANA framework models, tracks, and updates an AI agent's emotional state based on its actions and outcomes. This system enables the agent to exhibit nuanced, context-sensitive behavior by integrating mood states with decision-making, memory, and personality. The core components include the <code>EmotionalIntelligence</code> class for managing the overall emotional state, the <code>MoodProcessor</code> for calculating emotional shifts, and the <code>persona.json</code> configuration for defining personality traits. This document provides a comprehensive analysis of how these components work together to create a dynamic emotional model that influences the agent's behavior in a realistic and adaptive manner.</p>
<h2>Mood Modeling and Tracking</h2>
<p>The emotional state of the agent is represented as a <strong>mood vector</strong>, a dictionary that maps each mood state to a floating-point intensity value. The system distinguishes between primary and secondary moods, which are defined in the configuration.</p>
<h3>Emotion Categories</h3>
<p>The mood states are organized into primary emotion categories and secondary emotions, as defined in <code>config.json</code>:</p>
<p><strong>Primary Emotions:</strong></p>
<ul>
<li><strong>Joy-based</strong>: <code>["Confident", "Excited", "Inspired", "Satisfied"]</code></li>
<li><strong>Interest-based</strong>: <code>["Curious", "Reflective", "Intrigued", "Engaged"]</code></li>
<li><strong>Sadness-based</strong>: <code>["Disappointed", "Bored", "Low Energy", "Melancholic"]</code></li>
<li><strong>Anger-based</strong>: <code>["Frustrated", "Irritated", "Stuck", "Resentful"]</code></li>
<li><strong>Fear-based</strong>: <code>["Anxious", "Apprehensive", "Cautious", "Suspicious"]</code></li>
<li><strong>Surprise-based</strong>: <code>["Astonished", "Bewildered", "Amazed", "Shocked"]</code></li>
</ul>
<p><strong>Secondary Emotions:</strong>
<code>["Hopeful", "Grateful", "Proud", "Guilty", "Lonely", "Nostalgic", "Embarrassed", "Jealous", "Relieved", "Surprised", "Envious", "Peaceful", "Compassionate", "Confused", "Optimistic", "Pessimistic"]</code></p>
<h3>Mood Vector Initialization</h3>
<pre><code class="language-python">self.ALL_MOODS = list(set(primary_emotions + extended_primary + secondary_emotions))
self.mood_vector: Dict[str, float] = {mood: 0.0 for mood in self.ALL_MOODS}
</code></pre>
<p>The mood vector is updated in response to actions and outcomes, with values constrained to remain non-negative through the use of <code>max(0.0, value)</code> during updates.</p>
<h3>Mood Decay</h3>
<p>To simulate the natural fading of emotions over time, the system applies a decay factor to all mood values after each action result is processed. The default decay rate is <code>0.05</code> per update cycle, with enhanced decay for high-intensity moods above the stability threshold.</p>
<pre><code class="language-python">def decay_moods(self, decay: float = 0.05):
    stability_threshold = self.config.get("mood_dynamics", {}).get("stability_threshold", 0.3)
    for mood in self.mood_vector:
        current_value = self.mood_vector[mood]
        effective_decay = decay * 1.5 if current_value > stability_threshold else decay
        self.mood_vector[mood] = max(0.0, current_value - effective_decay)
</code></pre>
<h3>Mood Blending</h3>
<p>The system supports mood blending, where combinations of related moods can create more nuanced emotional states:</p>
<pre><code class="language-python">def blend_moods(self):
    blend_rules = {
        ("Confident", "Curious"): "Inspired",
        ("Frustrated", "Stuck"): "Resentful",
        ("Anxious", "Cautious"): "Apprehensive",
        ("Excited", "Satisfied"): "Proud"
    }
    for (mood1, mood2), blended_mood in blend_rules.items():
        if (mood1 in self.mood_vector and mood2 in self.mood_vector and 
            blended_mood in self.mood_vector):
            if (self.mood_vector[mood1] > threshold and 
                self.mood_vector[mood2] > threshold):
                blend_strength = (self.mood_vector[mood1] + self.mood_vector[mood2]) / 2
                self.update_mood(blended_mood, blend_strength * 0.1)
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>config.json</a></li>
<li><a>emotional_intellegence.py</a></li>
</ul>
<h2>MoodProcessor: Calculating Emotional Shifts</h2>
<p>The <code>MoodProcessor</code> class is responsible for calculating how an agent's emotional state should change in response to specific actions or outcomes. It acts as an intermediary between raw action data and the emotional state update logic.</p>
<h3>Processing Structured Action Results</h3>
<p>When a structured action result (a dictionary of boolean flags) is received, the <code>MoodProcessor</code> performs the following steps:</p>
<ol>
<li>Apply mood decay to simulate emotional fading</li>
<li>Look up predefined mood updates in the configuration</li>
<li>Apply direct or LLM-generated mood deltas based on triggers</li>
</ol>
<pre><code class="language-python">def process_action_result(self, action_result: dict):
    logger.debug(f"Processing action result: {action_result}")
    self.ei.decay_moods()
    mood_updates = self.ei.config.get("mood_updates", {})
    for trigger, is_present in action_result.items():
        if is_present and trigger in mood_updates:
            update = mood_updates[trigger]
            if "prompt" in update:
                llm_based_update = self._get_llm_mood_update(update["prompt"], self.ei.get_mood_vector(), action_result)
                for mood, delta in llm_based_update.items():
                    self.ei.update_mood(mood, delta)
            else:
                for mood, delta in update.items():
                    self.ei.update_mood(mood, delta)
</code></pre>
<h3>Natural Language Processing with LLM</h3>
<p>For nuanced emotional updates, the system can use a Large Language Model (LLM) to generate mood deltas based on a prompt. This allows for context-sensitive emotional responses that consider both the current mood and the nature of the action.</p>
<pre><code class="language-python">def _get_llm_mood_update(self, prompt_template: str, current_mood: Dict[str, float], action_result: dict) -> Dict[str, float]:
    prompt = f"""
You are an AI's emotional core. Your task is to update the AI's mood based on its recent action.
Analyze the action result and the AI's current emotional state to determine a nuanced mood update.

**Current Mood:**
{json.dumps(current_mood, indent=2)}

**Recent Emotional Events:**
{json.dumps([{
    "timestamp": event.timestamp.isoformat(),
    "triggers": event.triggers,
    "intensity": event.intensity
} for event in self.ei.emotional_events[-3:]], indent=2)}

**Action Result:**
{json.dumps(action_result, indent=2)}

**All Possible Moods:**
{json.dumps(self.ei.ALL_MOODS, indent=2)}

**Instructions:**
{prompt_template}

**Your JSON Response (only a JSON object with mood deltas, e.g., {{"Confident": 0.1, "Frustrated": -0.05}}):**
"""
    llm_response = safe_call_llm(prompt, timeout=30, retries=3)
    return self._extract_json_from_response(llm_response)
</code></pre>
<h3>Enhanced JSON Extraction</h3>
<p>The system implements multiple fallback strategies for extracting JSON from LLM responses, ensuring robustness against malformed outputs:</p>
<pre><code class="language-python">def _extract_json_from_response(self, response: str) -> Dict:
    if not response or not response.strip():
        return {}
        
    # Strategy 1: Parse entire response as JSON
    try:
        return json.loads(response)
    except json.JSONDecodeError:
        pass
        
    # Strategy 2: Extract JSON from markdown code blocks
    json_match = re.search(r'```(?:json)?\s*({.*?})\s*```', response, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass
            
    # Strategy 3: Extract any JSON-like structure
    json_match = re.search(r'({.*})', response, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass
            
    # Strategy 4: Clean and parse response
    cleaned_response = re.sub(r'^[^{]*', '', response)
    cleaned_response = re.sub(r'[^}]*$', '', cleaned_response)
    if cleaned_response:
        try:
            return json.loads(cleaned_response)
        except json.JSONDecodeError:
            pass
            
    return {}
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>mood_processor.py</a></li>
<li><a>llm.py</a></li>
</ul>
<h2>EmotionalIntelligence: Response Generation and Behavior Influence</h2>
<p>The <code>EmotionalIntelligence</code> class serves as the central controller for the emotional system, managing the mood vector, persona settings, and behavioral influences.</p>
<h3>Core Methods</h3>
<ul>
<li><strong><code>update_mood(mood: str, delta: float)</code></strong>: Updates a specific mood with a delta value, applying the current persona's multiplier and momentum effects.</li>
<li><strong><code>get_dominant_mood()</code></strong>: Returns the mood with the highest intensity value.</li>
<li><strong><code>get_mood_vector()</code></strong>: Returns a copy of the current mood vector.</li>
<li><strong><code>influence_behavior()</code></strong>: Returns behavior modifiers based on the dominant mood.</li>
<li><strong><code>get_emotional_context()</code></strong>: Returns comprehensive emotional context including recent events.</li>
</ul>
<h3>Behavior Influence Mechanism</h3>
<p>The dominant mood directly influences the agent's decision-making through behavior modifiers. These modifiers are retrieved from the configuration based on the current dominant mood.</p>
<pre><code class="language-python">def influence_behavior(self) -> dict:
    mood = self.get_dominant_mood()
    return self.config.get("behavior_influences", {}).get(mood, {})
</code></pre>
<p>These behavior modifiers are then used by other system components to adjust decision-making strategies, risk assessment, and action selection.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>emotional_intellegence.py</a></li>
</ul>
<h2>Persona Management and Personality Traits</h2>
<p>Personality traits are defined in the <code>persona.json</code> file and influence how the agent responds emotionally to events.</p>
<h3>Persona Configuration Structure</h3>
<pre><code class="language-json">{
    "personas": {
        "Optimistic": {
            "mood_multipliers": {
                "Confident": 1.5,
                "Curious": 1.2,
                "Frustrated": 0.5,
                "Stuck": 0.7,
                "Low Energy": 0.8,
                "Inspired": 1.4,
                "Satisfied": 1.3,
                "Anxious": 0.6
            },
            "description": "Sees the glass as half full. Bounces back from setbacks quickly.",
            "adaptation_rate": 0.1
        },
        "Pessimistic": {
            "mood_multipliers": {
                "Confident": 0.8,
                "Curious": 0.9,
                "Frustrated": 1.5,
                "Stuck": 1.3,
                "Low Energy": 1.2,
                "Disappointed": 1.4,
                "Anxious": 1.3,
                "Suspicious": 1.2
            },
            "description": "Tends to expect negative outcomes and is more affected by failures.",
            "adaptation_rate": 0.05
        },
        "Analytical": {
            "mood_multipliers": {
                "Confident": 1.1,
                "Curious": 1.8,
                "Frustrated": 0.8,
                "Stuck": 0.9,
                "Low Energy": 1.0,
                "Intrigued": 1.5,
                "Bewildered": 1.2
            },
            "description": "Driven by data and logic. Less prone to strong emotional swings.",
            "adaptation_rate": 0.15
        },
        "Creative": {
            "mood_multipliers": {
                "Confident": 1.2,
                "Curious": 1.6,
                "Frustrated": 1.1,
                "Stuck": 1.2,
                "Low Energy": 1.1,
                "Inspired": 1.7,
                "Bored": 1.3
            },
            "description": "Values novelty and exploration. Can get frustrated by rigid tasks.",
            "adaptation_rate": 0.2
        },
        "Balanced": {
            "mood_multipliers": {
                "Confident": 1.0,
                "Curious": 1.0,
                "Frustrated": 1.0,
                "Stuck": 1.0,
                "Low Energy": 1.0,
                "Inspired": 1.0,
                "Disappointed": 1.0,
                "Anxious": 1.0
            },
            "description": "Maintains equilibrium across emotional states with moderate responses.",
            "adaptation_rate": 0.1
        },
        "Empathetic": {
            "mood_multipliers": {
                "Confident": 1.1,
                "Curious": 1.3,
                "Frustrated": 1.2,
                "Stuck": 1.1,
                "Low Energy": 1.0,
                "Grateful": 1.5,
                "Compassionate": 1.4,
                "Anxious": 1.1
            },
            "description": "Highly attuned to emotional context and responsive to others' feelings.",
            "adaptation_rate": 0.18
        }
    },
    "default_persona": "Balanced"
}
</code></pre>
<h3>Personality Influence on Mood</h3>
<p>When a mood is updated, the current persona's multiplier for that mood is applied:</p>
<pre><code class="language-python">def update_mood(self, mood: str, delta: float):
    if mood in self.mood_vector:
        multiplier = self.persona.get("mood_multipliers", {}).get(mood, 1.0)
        adjusted_delta = (delta * multiplier) + momentum_effect
        new_value = max(0.0, self.mood_vector[mood] + adjusted_delta)
        self.mood_vector[mood] = new_value * self.damping_factor
</code></pre>
<p>The system also includes an adaptation rate parameter that controls how quickly the persona responds to emotional changes.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>persona.json</a></li>
<li><a>emotional_intellegence.py</a></li>
</ul>
<h2>Integration with Decision-Making and Memory</h2>
<p>The emotional intelligence system is tightly integrated with other core components of the agent architecture.</p>
<h3>Decision-Making Integration</h3>
<p>The emotional state influences decision-making through behavior modifiers. In the core system loop, after processing an action outcome, the system updates the mood and retrieves behavior modifiers:</p>
<pre><code class="language-python">async def _update_mood_and_reflect(self, action_output: Any):
    self.emotional_intelligence.process_action_natural(str(action_output))
    self.shared_state.mood = self.emotional_intelligence.get_mood_vector()
    self.shared_state.mood_history.append(self.shared_state.mood)
    
    self.behavior_modifiers = self.emotional_intelligence.influence_behavior()
    if self.behavior_modifiers:
        logger.info(f"Generated behavior modifiers for next loop: {self.behavior_modifiers}")
</code></pre>
<p>These behavior modifiers can then influence various aspects of decision-making, such as risk aversion, exploration tendency, or confidence levels.</p>
<h3>State Restoration</h3>
<p>The system supports state restoration, preserving emotional state across restarts:</p>
<pre><code class="language-python">if "mood" in agi_state and hasattr(self, 'emotional_intelligence'):
    try:
        self.emotional_intelligence.set_mood_vector(agi_state["mood"])
        logger.info("Restored previous mood state")
    except Exception as e:
        logger.warning(f"Could not restore mood state: {e}")
</code></pre>
<h3>Memory Integration</h3>
<p>Emotional states are stored in the agent's memory system through emotional tagging. The current mood vector is saved alongside interactions in the shared state:</p>
<pre><code class="language-python">self.shared_state.mood = self.emotional_intelligence.get_mood_vector()
self.shared_state.mood_history.append(self.shared_state.mood)
</code></pre>
<p>This allows the agent to recall not just what happened, but also how it felt at the time, enabling more nuanced reflection and learning from past experiences.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>system.py</a></li>
</ul>
<h2>Emotional Event Logging</h2>
<p>The system maintains a log of emotional events to track the evolution of the agent's emotional state over time.</p>
<h3>Emotional Event Structure</h3>
<pre><code class="language-python">class EmotionalEvent:
    def __init__(self, timestamp, mood_changes, triggers, context, intensity):
        self.timestamp = timestamp
        self.mood_changes = mood_changes
        self.triggers = triggers
        self.context = context
        self.intensity = intensity
</code></pre>
<h3>Event Logging Process</h3>
<pre><code class="language-python">def log_emotional_event(self, mood_changes: Dict[str, float], 
                       triggers: List[str], context: str):
    intensity = sum(abs(change) for change in mood_changes.values())
    event = EmotionalEvent(
        timestamp=datetime.now(),
        mood_changes=mood_changes,
        triggers=triggers,
        context=context,
        intensity=intensity
    )
    self.emotional_events.append(event)
    
    # Keep only recent events (last 24 hours)
    cutoff_time = datetime.now() - timedelta(hours=24)
    self.emotional_events = [
        event for event in self.emotional_events 
        if event.timestamp > cutoff_time
    ]
</code></pre>
<h3>Emotional Context Retrieval</h3>
<pre><code class="language-python">def get_emotional_context(self) -> Dict[str, any]:
    return {
        "dominant_mood": self.get_dominant_mood(),
        "mood_vector": self.get_mood_vector(),
        "recent_events": [
            {
                "timestamp": event.timestamp.isoformat(),
                "triggers": event.triggers,
                "intensity": event.intensity
            }
            for event in self.emotional_events[-5:]  # Last 5 events
        ]
    }
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>emotional_intellegence.py</a></li>
</ul>
<h2>Conversational AI Integration</h2>
<p>The emotional intelligence system is integrated with the conversational AI module to provide emotionally-aware responses.</p>
<h3>Conversational Emotional Intelligence</h3>
<pre><code class="language-python">class ConversationalEmotionalIntelligence:
    def __init__(self, config_path: str = "modules/emotional_intellegence/config.json", 
                 persona_path: str = "modules/emotional_intellegence/persona.json"):
        self.base_ei = EmotionalIntelligence(config_path, persona_path)
        self.current_conversation_context = {}
        self.user_interests = {}
</code></pre>
<h3>User Interest Detection</h3>
<pre><code class="language-python">def _detect_user_interests(self, message: str) -> List[str]:
    interest_keywords = {
        "technology": ["technology", "tech", "computer", "software", "programming", "code", "AI", "artificial intelligence"],
        "science": ["science", "physics", "chemistry", "biology", "research", "experiment", "study", "scientific"],
        "philosophy": ["philosophy", "thought", "think", "mind", "consciousness", "meaning", "ethics", "morality"],
        "creativity": ["creative", "art", "music", "design", "innovation", "invent", "imagine", "create"],
        "problem_solving": ["problem", "solve", "solution", "challenge", "puzzle", "fix", "troubleshoot"],
        "learning": ["learn", "study", "education", "knowledge", "understand", "explain", "teach", "skill"],
        "entertainment": ["movie", "film", "tv", "show", "game", "entertainment", "fun", "enjoy"],
        "business": ["business", "startup", "entrepreneur", "market", "finance", "investment", "career"],
        "health": ["health", "fitness", "exercise", "wellness", "medical", "mental health", "nutrition"],
        "travel": ["travel", "vacation", "trip", "destination", "culture", "explore", "adventure"]
    }
    
    message_lower = message.lower()
    interests = []
    for interest, keywords in interest_keywords.items():
        for keyword in keywords:
            if re.search(r'\b' + re.escape(keyword) + r'\b', message_lower):
                interests.append(interest)
                break
                    
    return list(set(interests))
</code></pre>
<h3>Thought Extraction</h3>
<pre><code class="language-python">def extract_thoughts_from_conversation(self, user_message: str, ai_response: str, 
                                     emotional_context: Dict[str, Any]) -> List[Dict[str, Any]]:
    extraction_prompt = f"""
You are an advanced AI assistant with the ability to extract meaningful thoughts and insights from conversations.
Analyze the following conversation and extract any valuable thoughts, insights, or ideas that could be useful
for the main RAVANA system to consider.

**Conversation:**
User: {user_message}
AI: {ai_response}

**Emotional Context:**
{json.dumps(emotional_context, indent=2)}

**Instructions:**
1. Identify any implicit goals or intentions expressed by the user
2. Extract knowledge gaps or learning opportunities from the user's expertise
3. Identify emotional context and user needs for personalized responses
4. Find collaborative task opportunities based on user interests
5. Extract hypotheses about RAVANA's performance that could be tested
6. Identify key topics and themes for chat history summarization

**Response Format:**
Return a JSON array of thought objects with the following structure:
[
  {{
    "thought_type": "insight|goal_suggestion|clarification_request|collaboration_proposal|reflection_trigger|knowledge_gap",
    "content": "The actual thought content",
    "priority": "low|medium|high|critical",
    "emotional_context": {{
      "dominant_mood": "string",
      "mood_vector": {{}},
      "intensity": 0.0
    }},
    "metadata": {{
      "topic": "string",
      "relevance_to_goals": 0.0-1.0,
      "learning_potential": 0.0-1.0
    }}
  }}
]

Return only the JSON array, nothing else.
"""
    response = safe_call_llm(extraction_prompt, timeout=30, retries=3)
    try:
        thoughts = json.loads(response)
        if isinstance(thoughts, list):
            return thoughts
    except json.JSONDecodeError as e:
        logger.warning(f"Failed to parse thoughts from LLM response. JSON decode error: {str(e)[:100]}...")
        logger.debug(f"Full LLM response: {response}")
    return []
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>conversational_ei.py</a></li>
</ul>
<h2>Emotional Context Synchronization</h2>
<p>The system has been enhanced with improved connectivity management and error handling to ensure reliable synchronization of emotional context between the Conversational AI module and the RAVANA core system.</p>
<h3>Implementation Details</h3>
<p>The synchronization process is implemented in the <code>main.py</code> file of the conversational_ai module, specifically in the <code>_synchronize_emotional_context</code> method:</p>
<pre><code class="language-python">def _synchronize_emotional_context(self, user_id: str, emotional_context: Dict[str, Any]):
    """
    Synchronize emotional context with the RAVANA core system.
    
    Args:
        user_id: The user identifier
        emotional_context: The emotional context to synchronize
    """
    # Add user identifier to the emotional context
    emotional_context["user_id"] = user_id
    
    # Send emotional context to RAVANA through the communication bridge
    self.ravana_communicator.send_emotional_context_to_ravana(emotional_context)
</code></pre>
<h3>Communication Protocol</h3>
<p>The emotional context is transmitted using a dedicated message type "emotional_context_update" through the RAVANA communication bridge:</p>
<pre><code class="language-python">def send_emotional_context_to_ravana(self, emotional_data: Dict[str, Any]):
    """
    Send emotional context to RAVANA.
    
    Args:
        emotional_data: Emotional context data to send to RAVANA
    """
    if self._shutdown.is_set():
        return
    try:
        # Add metadata
        emotional_message = {
            "type": "emotional_context_update",
            "timestamp": datetime.now().isoformat(),
            "source": "conversational_ai",
            "destination": "main_system",
            "content": emotional_data
        }
        
        # In a real implementation, this would be sent to RAVANA through IPC
        # For now, we'll add it to the message queue
        if not self._shutdown.is_set():
            asyncio.create_task(self.message_queue.put(emotional_message))
        
        logger.info(f"Emotional context sent to RAVANA for user {emotional_data.get('user_id', 'unknown')}")
        
    except Exception as e:
        if not self._shutdown.is_set():
            logger.error(f"Error sending emotional context to RAVANA: {e}")
</code></pre>
<h3>Integration Flow</h3>
<p>The emotional context synchronization is integrated into the main message processing flow:</p>
<ol>
<li>When a user message is received, it is processed to extract emotional context</li>
<li>The emotional context is used to generate an appropriate response</li>
<li>The emotional context is then synchronized with the RAVANA core system</li>
<li>The response is sent back to the user</li>
</ol>
<pre><code class="language-python">async def handle_user_message(self, message: str, user_id: str, platform: str = None):
    """Handle a user message from any platform."""
    try:
        # Create context for the message
        context = {
            "user_id": user_id,
            "platform": platform,
            "timestamp": datetime.now().isoformat()
        }
        
        # Process the message to get emotional context
        emotional_context = self.emotional_intelligence.process_user_message(message, context)
        
        # Generate response using emotional context
        response = self.emotional_intelligence.generate_response(message, emotional_context)
        
        # Store conversation in memory
        await self.memory_interface.store_conversation(message, response, emotional_context)
        
        # Extract thoughts from the conversation
        thoughts = self.emotional_intelligence.extract_thoughts_from_conversation(
            message, response, emotional_context
        )
        
        # Send thoughts to RAVANA
        for thought in thoughts:
            self.ravana_communicator.send_thought_to_ravana(thought)
        
        # Synchronize emotional context with RAVANA core system
        self._synchronize_emotional_context(user_id, emotional_context)
        
        # Return the response
        return response
        
    except Exception as e:
        logger.error(f"Error handling user message: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        return "I'm having trouble processing your message right now."
</code></pre>
<p>This enhancement ensures that the emotional state of the AI agent is consistently maintained across both the conversational interface and the core reasoning system, enabling more coherent and contextually appropriate interactions.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>main.py</a></li>
<li><a>ravana_bridge.py</a></li>
</ul>
<h2>Mood Transition Logic and Examples</h2>
<h3>Example Mood Transitions</h3>
<p>Using the example from the configuration:</p>
<ol>
<li>
<p><strong>"The agent discovered a new topic about quantum computing."</strong></p>
<ul>
<li>Triggers: <code>{"new_discovery": true}</code></li>
<li>Mood update: <code>{"Curious": 0.2, "Excited": 0.15, "Inspired": 0.1}</code></li>
<li>Result: Increased curiosity, excitement, and inspiration</li>
</ul>
</li>
<li>
<p><strong>"Task completed successfully."</strong></p>
<ul>
<li>Triggers: <code>{"task_completed": true}</code></li>
<li>Mood update: <code>{"Confident": 0.25, "Satisfied": 0.2, "Content": 0.1}</code></li>
<li>Result: Increased confidence and satisfaction</li>
</ul>
</li>
<li>
<p><strong>"An error occurred while processing the data."</strong></p>
<ul>
<li>Triggers: <code>{"error_occurred": true}</code></li>
<li>Mood update: <code>{"Frustrated": 0.3, "Stuck": 0.2, "Anxious": 0.1}</code></li>
<li>Result: Increased frustration, feeling stuck, and anxiety</li>
</ul>
</li>
</ol>
<h3>Persona Effects Example</h3>
<p>When switching from "Optimistic" to "Pessimistic" persona:</p>
<ul>
<li>The same "task_completed" event would produce a smaller increase in "Confident" (multiplied by 0.8 instead of 1.5)</li>
<li>The same "error_occurred" event would produce a larger increase in "Frustrated" (multiplied by 1.5 instead of 0.5)</li>
<li>This creates a systematically more negative emotional response pattern</li>
</ul>
<h2>Common Issues and Best Practices</h2>
<h3>Common Issues</h3>
<ol>
<li><strong>Mood Instability</strong>: Rapid mood swings can occur if decay rates are too low or update deltas are too high.</li>
<li><strong>Inconsistent Emotional Responses</strong>: May result from ambiguous trigger definitions or poorly calibrated LLM prompts.</li>
<li><strong>Persona Drift</strong>: The agent's behavior may become inconsistent if personas are changed too frequently without proper transition logic.</li>
<li><strong>JSON Parsing Failures</strong>: LLM responses may not be valid JSON, requiring robust fallback strategies.</li>
</ol>
<h3>Best Practices for Tuning</h3>
<ol>
<li><strong>Balance Decay and Update Rates</strong>: Ensure decay is sufficient to prevent mood saturation but not so high that emotions disappear too quickly.</li>
<li><strong>Calibrate Multipliers</strong>: Test persona multipliers to ensure they produce meaningful but not extreme behavioral differences.</li>
<li><strong>Define Clear Triggers</strong>: Ensure trigger definitions are specific and non-overlapping to avoid ambiguous classification.</li>
<li><strong>Monitor Mood History</strong>: Track mood vectors over time to identify patterns of instability or stagnation.</li>
<li><strong>Validate LLM Outputs</strong>: Implement robust error handling for LLM-based mood updates, including multiple fallback parsing strategies.</li>
<li><strong>Test Mood Blending</strong>: Verify that mood blending rules create realistic emotional transitions.</li>
<li><strong>Adjust Adaptation Rates</strong>: Tune persona adaptation rates to match desired responsiveness to emotional changes.</li>
</ol>
<p>By following these best practices, developers can create emotionally intelligent agents that exhibit stable, consistent, and realistic emotional responses that enhance the overall believability and effectiveness of the AI system.</p>
<p><strong>Referenced Files in This Document</strong></p>
<ul>
<li><a>emotional_intellegence.py</a> - <em>Updated with enhanced mood dynamics and emotional event logging</em></li>
<li><a>mood_processor.py</a> - <em>Updated with improved JSON extraction and safer LLM integration</em></li>
<li><a>persona.json</a> - <em>Expanded with additional personas and adaptation rates</em></li>
<li><a>config.json</a> - <em>Enhanced with primary/secondary emotion categories and mood dynamics</em></li>
<li><a>conversational_ei.py</a> - <em>Integrated with conversational AI and user interest detection</em></li>
<li><a>system.py</a> - <em>Updated with state restoration and emotional memory integration</em></li>
<li><a>main.py</a> - <em>Added emotional context synchronization with RAVANA core system</em></li>
<li><a>ravana_bridge.py</a> - <em>Implemented emotional context update messaging</em></li>
</ul>
</div></article><div class="w-full md:w-64 flex-shrink-0"></div></div></main></div><footer class="bg-wiki-dark text-white p-4"><div class="container mx-auto text-center"><p>© <!-- -->2025<!-- --> RAVANA AGI System Documentation</p></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"doc":{"slug":"Emotional Intelligence","title":"Emotional Intelligence","content":"\u003ch1\u003eEmotional Intelligence\u003c/h1\u003e\n\u003ch2\u003eUpdate Summary\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eChanges Made\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUpdated \u003cstrong\u003eConversational AI Integration\u003c/strong\u003e section to reflect enhanced JSON parsing error logging in thought extraction\u003c/li\u003e\n\u003cli\u003eAdded detailed error logging information for JSONDecodeError in the ConversationalEmotionalIntelligence class\u003c/li\u003e\n\u003cli\u003eEnhanced documentation of debug-level logging for full LLM responses during thought extraction\u003c/li\u003e\n\u003cli\u003eUpdated code examples to reflect improved error handling and logging practices\u003c/li\u003e\n\u003cli\u003eAdded information about debug logging of full LLM responses for diagnostic purposes\u003c/li\u003e\n\u003cli\u003eUpdated section sources to reflect the specific files analyzed in this update\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eTable of Contents\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mood-modeling-and-tracking\"\u003eMood Modeling and Tracking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#moodprocessor-calculating-emotional-shifts\"\u003eMoodProcessor: Calculating Emotional Shifts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#emotionalintelligence-response-generation-and-behavior-influence\"\u003eEmotionalIntelligence: Response Generation and Behavior Influence\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#persona-management-and-personality-traits\"\u003ePersona Management and Personality Traits\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#integration-with-decision-making-and-memory\"\u003eIntegration with Decision-Making and Memory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#emotional-event-logging\"\u003eEmotional Event Logging\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#conversational-ai-integration\"\u003eConversational AI Integration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#emotional-context-synchronization\"\u003eEmotional Context Synchronization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mood-transition-logic-and-examples\"\u003eMood Transition Logic and Examples\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#common-issues-and-best-practices\"\u003eCommon Issues and Best Practices\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThe Emotional Intelligence system in the RAVANA framework models, tracks, and updates an AI agent's emotional state based on its actions and outcomes. This system enables the agent to exhibit nuanced, context-sensitive behavior by integrating mood states with decision-making, memory, and personality. The core components include the \u003ccode\u003eEmotionalIntelligence\u003c/code\u003e class for managing the overall emotional state, the \u003ccode\u003eMoodProcessor\u003c/code\u003e for calculating emotional shifts, and the \u003ccode\u003epersona.json\u003c/code\u003e configuration for defining personality traits. This document provides a comprehensive analysis of how these components work together to create a dynamic emotional model that influences the agent's behavior in a realistic and adaptive manner.\u003c/p\u003e\n\u003ch2\u003eMood Modeling and Tracking\u003c/h2\u003e\n\u003cp\u003eThe emotional state of the agent is represented as a \u003cstrong\u003emood vector\u003c/strong\u003e, a dictionary that maps each mood state to a floating-point intensity value. The system distinguishes between primary and secondary moods, which are defined in the configuration.\u003c/p\u003e\n\u003ch3\u003eEmotion Categories\u003c/h3\u003e\n\u003cp\u003eThe mood states are organized into primary emotion categories and secondary emotions, as defined in \u003ccode\u003econfig.json\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrimary Emotions:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eJoy-based\u003c/strong\u003e: \u003ccode\u003e[\"Confident\", \"Excited\", \"Inspired\", \"Satisfied\"]\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInterest-based\u003c/strong\u003e: \u003ccode\u003e[\"Curious\", \"Reflective\", \"Intrigued\", \"Engaged\"]\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSadness-based\u003c/strong\u003e: \u003ccode\u003e[\"Disappointed\", \"Bored\", \"Low Energy\", \"Melancholic\"]\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAnger-based\u003c/strong\u003e: \u003ccode\u003e[\"Frustrated\", \"Irritated\", \"Stuck\", \"Resentful\"]\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFear-based\u003c/strong\u003e: \u003ccode\u003e[\"Anxious\", \"Apprehensive\", \"Cautious\", \"Suspicious\"]\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSurprise-based\u003c/strong\u003e: \u003ccode\u003e[\"Astonished\", \"Bewildered\", \"Amazed\", \"Shocked\"]\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSecondary Emotions:\u003c/strong\u003e\n\u003ccode\u003e[\"Hopeful\", \"Grateful\", \"Proud\", \"Guilty\", \"Lonely\", \"Nostalgic\", \"Embarrassed\", \"Jealous\", \"Relieved\", \"Surprised\", \"Envious\", \"Peaceful\", \"Compassionate\", \"Confused\", \"Optimistic\", \"Pessimistic\"]\u003c/code\u003e\u003c/p\u003e\n\u003ch3\u003eMood Vector Initialization\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eself.ALL_MOODS = list(set(primary_emotions + extended_primary + secondary_emotions))\nself.mood_vector: Dict[str, float] = {mood: 0.0 for mood in self.ALL_MOODS}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe mood vector is updated in response to actions and outcomes, with values constrained to remain non-negative through the use of \u003ccode\u003emax(0.0, value)\u003c/code\u003e during updates.\u003c/p\u003e\n\u003ch3\u003eMood Decay\u003c/h3\u003e\n\u003cp\u003eTo simulate the natural fading of emotions over time, the system applies a decay factor to all mood values after each action result is processed. The default decay rate is \u003ccode\u003e0.05\u003c/code\u003e per update cycle, with enhanced decay for high-intensity moods above the stability threshold.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef decay_moods(self, decay: float = 0.05):\n    stability_threshold = self.config.get(\"mood_dynamics\", {}).get(\"stability_threshold\", 0.3)\n    for mood in self.mood_vector:\n        current_value = self.mood_vector[mood]\n        effective_decay = decay * 1.5 if current_value \u003e stability_threshold else decay\n        self.mood_vector[mood] = max(0.0, current_value - effective_decay)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eMood Blending\u003c/h3\u003e\n\u003cp\u003eThe system supports mood blending, where combinations of related moods can create more nuanced emotional states:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef blend_moods(self):\n    blend_rules = {\n        (\"Confident\", \"Curious\"): \"Inspired\",\n        (\"Frustrated\", \"Stuck\"): \"Resentful\",\n        (\"Anxious\", \"Cautious\"): \"Apprehensive\",\n        (\"Excited\", \"Satisfied\"): \"Proud\"\n    }\n    for (mood1, mood2), blended_mood in blend_rules.items():\n        if (mood1 in self.mood_vector and mood2 in self.mood_vector and \n            blended_mood in self.mood_vector):\n            if (self.mood_vector[mood1] \u003e threshold and \n                self.mood_vector[mood2] \u003e threshold):\n                blend_strength = (self.mood_vector[mood1] + self.mood_vector[mood2]) / 2\n                self.update_mood(blended_mood, blend_strength * 0.1)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003econfig.json\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eemotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eMoodProcessor: Calculating Emotional Shifts\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eMoodProcessor\u003c/code\u003e class is responsible for calculating how an agent's emotional state should change in response to specific actions or outcomes. It acts as an intermediary between raw action data and the emotional state update logic.\u003c/p\u003e\n\u003ch3\u003eProcessing Structured Action Results\u003c/h3\u003e\n\u003cp\u003eWhen a structured action result (a dictionary of boolean flags) is received, the \u003ccode\u003eMoodProcessor\u003c/code\u003e performs the following steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eApply mood decay to simulate emotional fading\u003c/li\u003e\n\u003cli\u003eLook up predefined mood updates in the configuration\u003c/li\u003e\n\u003cli\u003eApply direct or LLM-generated mood deltas based on triggers\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef process_action_result(self, action_result: dict):\n    logger.debug(f\"Processing action result: {action_result}\")\n    self.ei.decay_moods()\n    mood_updates = self.ei.config.get(\"mood_updates\", {})\n    for trigger, is_present in action_result.items():\n        if is_present and trigger in mood_updates:\n            update = mood_updates[trigger]\n            if \"prompt\" in update:\n                llm_based_update = self._get_llm_mood_update(update[\"prompt\"], self.ei.get_mood_vector(), action_result)\n                for mood, delta in llm_based_update.items():\n                    self.ei.update_mood(mood, delta)\n            else:\n                for mood, delta in update.items():\n                    self.ei.update_mood(mood, delta)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eNatural Language Processing with LLM\u003c/h3\u003e\n\u003cp\u003eFor nuanced emotional updates, the system can use a Large Language Model (LLM) to generate mood deltas based on a prompt. This allows for context-sensitive emotional responses that consider both the current mood and the nature of the action.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _get_llm_mood_update(self, prompt_template: str, current_mood: Dict[str, float], action_result: dict) -\u003e Dict[str, float]:\n    prompt = f\"\"\"\nYou are an AI's emotional core. Your task is to update the AI's mood based on its recent action.\nAnalyze the action result and the AI's current emotional state to determine a nuanced mood update.\n\n**Current Mood:**\n{json.dumps(current_mood, indent=2)}\n\n**Recent Emotional Events:**\n{json.dumps([{\n    \"timestamp\": event.timestamp.isoformat(),\n    \"triggers\": event.triggers,\n    \"intensity\": event.intensity\n} for event in self.ei.emotional_events[-3:]], indent=2)}\n\n**Action Result:**\n{json.dumps(action_result, indent=2)}\n\n**All Possible Moods:**\n{json.dumps(self.ei.ALL_MOODS, indent=2)}\n\n**Instructions:**\n{prompt_template}\n\n**Your JSON Response (only a JSON object with mood deltas, e.g., {{\"Confident\": 0.1, \"Frustrated\": -0.05}}):**\n\"\"\"\n    llm_response = safe_call_llm(prompt, timeout=30, retries=3)\n    return self._extract_json_from_response(llm_response)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eEnhanced JSON Extraction\u003c/h3\u003e\n\u003cp\u003eThe system implements multiple fallback strategies for extracting JSON from LLM responses, ensuring robustness against malformed outputs:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _extract_json_from_response(self, response: str) -\u003e Dict:\n    if not response or not response.strip():\n        return {}\n        \n    # Strategy 1: Parse entire response as JSON\n    try:\n        return json.loads(response)\n    except json.JSONDecodeError:\n        pass\n        \n    # Strategy 2: Extract JSON from markdown code blocks\n    json_match = re.search(r'```(?:json)?\\s*({.*?})\\s*```', response, re.DOTALL)\n    if json_match:\n        try:\n            return json.loads(json_match.group(1))\n        except json.JSONDecodeError:\n            pass\n            \n    # Strategy 3: Extract any JSON-like structure\n    json_match = re.search(r'({.*})', response, re.DOTALL)\n    if json_match:\n        try:\n            return json.loads(json_match.group(1))\n        except json.JSONDecodeError:\n            pass\n            \n    # Strategy 4: Clean and parse response\n    cleaned_response = re.sub(r'^[^{]*', '', response)\n    cleaned_response = re.sub(r'[^}]*$', '', cleaned_response)\n    if cleaned_response:\n        try:\n            return json.loads(cleaned_response)\n        except json.JSONDecodeError:\n            pass\n            \n    return {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emood_processor.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ellm.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eEmotionalIntelligence: Response Generation and Behavior Influence\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eEmotionalIntelligence\u003c/code\u003e class serves as the central controller for the emotional system, managing the mood vector, persona settings, and behavioral influences.\u003c/p\u003e\n\u003ch3\u003eCore Methods\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eupdate_mood(mood: str, delta: float)\u003c/code\u003e\u003c/strong\u003e: Updates a specific mood with a delta value, applying the current persona's multiplier and momentum effects.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eget_dominant_mood()\u003c/code\u003e\u003c/strong\u003e: Returns the mood with the highest intensity value.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eget_mood_vector()\u003c/code\u003e\u003c/strong\u003e: Returns a copy of the current mood vector.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003einfluence_behavior()\u003c/code\u003e\u003c/strong\u003e: Returns behavior modifiers based on the dominant mood.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eget_emotional_context()\u003c/code\u003e\u003c/strong\u003e: Returns comprehensive emotional context including recent events.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eBehavior Influence Mechanism\u003c/h3\u003e\n\u003cp\u003eThe dominant mood directly influences the agent's decision-making through behavior modifiers. These modifiers are retrieved from the configuration based on the current dominant mood.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef influence_behavior(self) -\u003e dict:\n    mood = self.get_dominant_mood()\n    return self.config.get(\"behavior_influences\", {}).get(mood, {})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThese behavior modifiers are then used by other system components to adjust decision-making strategies, risk assessment, and action selection.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eemotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003ePersona Management and Personality Traits\u003c/h2\u003e\n\u003cp\u003ePersonality traits are defined in the \u003ccode\u003epersona.json\u003c/code\u003e file and influence how the agent responds emotionally to events.\u003c/p\u003e\n\u003ch3\u003ePersona Configuration Structure\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \"personas\": {\n        \"Optimistic\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.5,\n                \"Curious\": 1.2,\n                \"Frustrated\": 0.5,\n                \"Stuck\": 0.7,\n                \"Low Energy\": 0.8,\n                \"Inspired\": 1.4,\n                \"Satisfied\": 1.3,\n                \"Anxious\": 0.6\n            },\n            \"description\": \"Sees the glass as half full. Bounces back from setbacks quickly.\",\n            \"adaptation_rate\": 0.1\n        },\n        \"Pessimistic\": {\n            \"mood_multipliers\": {\n                \"Confident\": 0.8,\n                \"Curious\": 0.9,\n                \"Frustrated\": 1.5,\n                \"Stuck\": 1.3,\n                \"Low Energy\": 1.2,\n                \"Disappointed\": 1.4,\n                \"Anxious\": 1.3,\n                \"Suspicious\": 1.2\n            },\n            \"description\": \"Tends to expect negative outcomes and is more affected by failures.\",\n            \"adaptation_rate\": 0.05\n        },\n        \"Analytical\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.1,\n                \"Curious\": 1.8,\n                \"Frustrated\": 0.8,\n                \"Stuck\": 0.9,\n                \"Low Energy\": 1.0,\n                \"Intrigued\": 1.5,\n                \"Bewildered\": 1.2\n            },\n            \"description\": \"Driven by data and logic. Less prone to strong emotional swings.\",\n            \"adaptation_rate\": 0.15\n        },\n        \"Creative\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.2,\n                \"Curious\": 1.6,\n                \"Frustrated\": 1.1,\n                \"Stuck\": 1.2,\n                \"Low Energy\": 1.1,\n                \"Inspired\": 1.7,\n                \"Bored\": 1.3\n            },\n            \"description\": \"Values novelty and exploration. Can get frustrated by rigid tasks.\",\n            \"adaptation_rate\": 0.2\n        },\n        \"Balanced\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.0,\n                \"Curious\": 1.0,\n                \"Frustrated\": 1.0,\n                \"Stuck\": 1.0,\n                \"Low Energy\": 1.0,\n                \"Inspired\": 1.0,\n                \"Disappointed\": 1.0,\n                \"Anxious\": 1.0\n            },\n            \"description\": \"Maintains equilibrium across emotional states with moderate responses.\",\n            \"adaptation_rate\": 0.1\n        },\n        \"Empathetic\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.1,\n                \"Curious\": 1.3,\n                \"Frustrated\": 1.2,\n                \"Stuck\": 1.1,\n                \"Low Energy\": 1.0,\n                \"Grateful\": 1.5,\n                \"Compassionate\": 1.4,\n                \"Anxious\": 1.1\n            },\n            \"description\": \"Highly attuned to emotional context and responsive to others' feelings.\",\n            \"adaptation_rate\": 0.18\n        }\n    },\n    \"default_persona\": \"Balanced\"\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003ePersonality Influence on Mood\u003c/h3\u003e\n\u003cp\u003eWhen a mood is updated, the current persona's multiplier for that mood is applied:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef update_mood(self, mood: str, delta: float):\n    if mood in self.mood_vector:\n        multiplier = self.persona.get(\"mood_multipliers\", {}).get(mood, 1.0)\n        adjusted_delta = (delta * multiplier) + momentum_effect\n        new_value = max(0.0, self.mood_vector[mood] + adjusted_delta)\n        self.mood_vector[mood] = new_value * self.damping_factor\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe system also includes an adaptation rate parameter that controls how quickly the persona responds to emotional changes.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003epersona.json\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eemotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eIntegration with Decision-Making and Memory\u003c/h2\u003e\n\u003cp\u003eThe emotional intelligence system is tightly integrated with other core components of the agent architecture.\u003c/p\u003e\n\u003ch3\u003eDecision-Making Integration\u003c/h3\u003e\n\u003cp\u003eThe emotional state influences decision-making through behavior modifiers. In the core system loop, after processing an action outcome, the system updates the mood and retrieves behavior modifiers:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def _update_mood_and_reflect(self, action_output: Any):\n    self.emotional_intelligence.process_action_natural(str(action_output))\n    self.shared_state.mood = self.emotional_intelligence.get_mood_vector()\n    self.shared_state.mood_history.append(self.shared_state.mood)\n    \n    self.behavior_modifiers = self.emotional_intelligence.influence_behavior()\n    if self.behavior_modifiers:\n        logger.info(f\"Generated behavior modifiers for next loop: {self.behavior_modifiers}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThese behavior modifiers can then influence various aspects of decision-making, such as risk aversion, exploration tendency, or confidence levels.\u003c/p\u003e\n\u003ch3\u003eState Restoration\u003c/h3\u003e\n\u003cp\u003eThe system supports state restoration, preserving emotional state across restarts:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eif \"mood\" in agi_state and hasattr(self, 'emotional_intelligence'):\n    try:\n        self.emotional_intelligence.set_mood_vector(agi_state[\"mood\"])\n        logger.info(\"Restored previous mood state\")\n    except Exception as e:\n        logger.warning(f\"Could not restore mood state: {e}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eMemory Integration\u003c/h3\u003e\n\u003cp\u003eEmotional states are stored in the agent's memory system through emotional tagging. The current mood vector is saved alongside interactions in the shared state:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eself.shared_state.mood = self.emotional_intelligence.get_mood_vector()\nself.shared_state.mood_history.append(self.shared_state.mood)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis allows the agent to recall not just what happened, but also how it felt at the time, enabling more nuanced reflection and learning from past experiences.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003esystem.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eEmotional Event Logging\u003c/h2\u003e\n\u003cp\u003eThe system maintains a log of emotional events to track the evolution of the agent's emotional state over time.\u003c/p\u003e\n\u003ch3\u003eEmotional Event Structure\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass EmotionalEvent:\n    def __init__(self, timestamp, mood_changes, triggers, context, intensity):\n        self.timestamp = timestamp\n        self.mood_changes = mood_changes\n        self.triggers = triggers\n        self.context = context\n        self.intensity = intensity\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eEvent Logging Process\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef log_emotional_event(self, mood_changes: Dict[str, float], \n                       triggers: List[str], context: str):\n    intensity = sum(abs(change) for change in mood_changes.values())\n    event = EmotionalEvent(\n        timestamp=datetime.now(),\n        mood_changes=mood_changes,\n        triggers=triggers,\n        context=context,\n        intensity=intensity\n    )\n    self.emotional_events.append(event)\n    \n    # Keep only recent events (last 24 hours)\n    cutoff_time = datetime.now() - timedelta(hours=24)\n    self.emotional_events = [\n        event for event in self.emotional_events \n        if event.timestamp \u003e cutoff_time\n    ]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eEmotional Context Retrieval\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef get_emotional_context(self) -\u003e Dict[str, any]:\n    return {\n        \"dominant_mood\": self.get_dominant_mood(),\n        \"mood_vector\": self.get_mood_vector(),\n        \"recent_events\": [\n            {\n                \"timestamp\": event.timestamp.isoformat(),\n                \"triggers\": event.triggers,\n                \"intensity\": event.intensity\n            }\n            for event in self.emotional_events[-5:]  # Last 5 events\n        ]\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eemotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eConversational AI Integration\u003c/h2\u003e\n\u003cp\u003eThe emotional intelligence system is integrated with the conversational AI module to provide emotionally-aware responses.\u003c/p\u003e\n\u003ch3\u003eConversational Emotional Intelligence\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ConversationalEmotionalIntelligence:\n    def __init__(self, config_path: str = \"modules/emotional_intellegence/config.json\", \n                 persona_path: str = \"modules/emotional_intellegence/persona.json\"):\n        self.base_ei = EmotionalIntelligence(config_path, persona_path)\n        self.current_conversation_context = {}\n        self.user_interests = {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eUser Interest Detection\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _detect_user_interests(self, message: str) -\u003e List[str]:\n    interest_keywords = {\n        \"technology\": [\"technology\", \"tech\", \"computer\", \"software\", \"programming\", \"code\", \"AI\", \"artificial intelligence\"],\n        \"science\": [\"science\", \"physics\", \"chemistry\", \"biology\", \"research\", \"experiment\", \"study\", \"scientific\"],\n        \"philosophy\": [\"philosophy\", \"thought\", \"think\", \"mind\", \"consciousness\", \"meaning\", \"ethics\", \"morality\"],\n        \"creativity\": [\"creative\", \"art\", \"music\", \"design\", \"innovation\", \"invent\", \"imagine\", \"create\"],\n        \"problem_solving\": [\"problem\", \"solve\", \"solution\", \"challenge\", \"puzzle\", \"fix\", \"troubleshoot\"],\n        \"learning\": [\"learn\", \"study\", \"education\", \"knowledge\", \"understand\", \"explain\", \"teach\", \"skill\"],\n        \"entertainment\": [\"movie\", \"film\", \"tv\", \"show\", \"game\", \"entertainment\", \"fun\", \"enjoy\"],\n        \"business\": [\"business\", \"startup\", \"entrepreneur\", \"market\", \"finance\", \"investment\", \"career\"],\n        \"health\": [\"health\", \"fitness\", \"exercise\", \"wellness\", \"medical\", \"mental health\", \"nutrition\"],\n        \"travel\": [\"travel\", \"vacation\", \"trip\", \"destination\", \"culture\", \"explore\", \"adventure\"]\n    }\n    \n    message_lower = message.lower()\n    interests = []\n    for interest, keywords in interest_keywords.items():\n        for keyword in keywords:\n            if re.search(r'\\b' + re.escape(keyword) + r'\\b', message_lower):\n                interests.append(interest)\n                break\n                    \n    return list(set(interests))\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eThought Extraction\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef extract_thoughts_from_conversation(self, user_message: str, ai_response: str, \n                                     emotional_context: Dict[str, Any]) -\u003e List[Dict[str, Any]]:\n    extraction_prompt = f\"\"\"\nYou are an advanced AI assistant with the ability to extract meaningful thoughts and insights from conversations.\nAnalyze the following conversation and extract any valuable thoughts, insights, or ideas that could be useful\nfor the main RAVANA system to consider.\n\n**Conversation:**\nUser: {user_message}\nAI: {ai_response}\n\n**Emotional Context:**\n{json.dumps(emotional_context, indent=2)}\n\n**Instructions:**\n1. Identify any implicit goals or intentions expressed by the user\n2. Extract knowledge gaps or learning opportunities from the user's expertise\n3. Identify emotional context and user needs for personalized responses\n4. Find collaborative task opportunities based on user interests\n5. Extract hypotheses about RAVANA's performance that could be tested\n6. Identify key topics and themes for chat history summarization\n\n**Response Format:**\nReturn a JSON array of thought objects with the following structure:\n[\n  {{\n    \"thought_type\": \"insight|goal_suggestion|clarification_request|collaboration_proposal|reflection_trigger|knowledge_gap\",\n    \"content\": \"The actual thought content\",\n    \"priority\": \"low|medium|high|critical\",\n    \"emotional_context\": {{\n      \"dominant_mood\": \"string\",\n      \"mood_vector\": {{}},\n      \"intensity\": 0.0\n    }},\n    \"metadata\": {{\n      \"topic\": \"string\",\n      \"relevance_to_goals\": 0.0-1.0,\n      \"learning_potential\": 0.0-1.0\n    }}\n  }}\n]\n\nReturn only the JSON array, nothing else.\n\"\"\"\n    response = safe_call_llm(extraction_prompt, timeout=30, retries=3)\n    try:\n        thoughts = json.loads(response)\n        if isinstance(thoughts, list):\n            return thoughts\n    except json.JSONDecodeError as e:\n        logger.warning(f\"Failed to parse thoughts from LLM response. JSON decode error: {str(e)[:100]}...\")\n        logger.debug(f\"Full LLM response: {response}\")\n    return []\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003econversational_ei.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eEmotional Context Synchronization\u003c/h2\u003e\n\u003cp\u003eThe system has been enhanced with improved connectivity management and error handling to ensure reliable synchronization of emotional context between the Conversational AI module and the RAVANA core system.\u003c/p\u003e\n\u003ch3\u003eImplementation Details\u003c/h3\u003e\n\u003cp\u003eThe synchronization process is implemented in the \u003ccode\u003emain.py\u003c/code\u003e file of the conversational_ai module, specifically in the \u003ccode\u003e_synchronize_emotional_context\u003c/code\u003e method:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _synchronize_emotional_context(self, user_id: str, emotional_context: Dict[str, Any]):\n    \"\"\"\n    Synchronize emotional context with the RAVANA core system.\n    \n    Args:\n        user_id: The user identifier\n        emotional_context: The emotional context to synchronize\n    \"\"\"\n    # Add user identifier to the emotional context\n    emotional_context[\"user_id\"] = user_id\n    \n    # Send emotional context to RAVANA through the communication bridge\n    self.ravana_communicator.send_emotional_context_to_ravana(emotional_context)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eCommunication Protocol\u003c/h3\u003e\n\u003cp\u003eThe emotional context is transmitted using a dedicated message type \"emotional_context_update\" through the RAVANA communication bridge:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef send_emotional_context_to_ravana(self, emotional_data: Dict[str, Any]):\n    \"\"\"\n    Send emotional context to RAVANA.\n    \n    Args:\n        emotional_data: Emotional context data to send to RAVANA\n    \"\"\"\n    if self._shutdown.is_set():\n        return\n    try:\n        # Add metadata\n        emotional_message = {\n            \"type\": \"emotional_context_update\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"source\": \"conversational_ai\",\n            \"destination\": \"main_system\",\n            \"content\": emotional_data\n        }\n        \n        # In a real implementation, this would be sent to RAVANA through IPC\n        # For now, we'll add it to the message queue\n        if not self._shutdown.is_set():\n            asyncio.create_task(self.message_queue.put(emotional_message))\n        \n        logger.info(f\"Emotional context sent to RAVANA for user {emotional_data.get('user_id', 'unknown')}\")\n        \n    except Exception as e:\n        if not self._shutdown.is_set():\n            logger.error(f\"Error sending emotional context to RAVANA: {e}\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eIntegration Flow\u003c/h3\u003e\n\u003cp\u003eThe emotional context synchronization is integrated into the main message processing flow:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWhen a user message is received, it is processed to extract emotional context\u003c/li\u003e\n\u003cli\u003eThe emotional context is used to generate an appropriate response\u003c/li\u003e\n\u003cli\u003eThe emotional context is then synchronized with the RAVANA core system\u003c/li\u003e\n\u003cli\u003eThe response is sent back to the user\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def handle_user_message(self, message: str, user_id: str, platform: str = None):\n    \"\"\"Handle a user message from any platform.\"\"\"\n    try:\n        # Create context for the message\n        context = {\n            \"user_id\": user_id,\n            \"platform\": platform,\n            \"timestamp\": datetime.now().isoformat()\n        }\n        \n        # Process the message to get emotional context\n        emotional_context = self.emotional_intelligence.process_user_message(message, context)\n        \n        # Generate response using emotional context\n        response = self.emotional_intelligence.generate_response(message, emotional_context)\n        \n        # Store conversation in memory\n        await self.memory_interface.store_conversation(message, response, emotional_context)\n        \n        # Extract thoughts from the conversation\n        thoughts = self.emotional_intelligence.extract_thoughts_from_conversation(\n            message, response, emotional_context\n        )\n        \n        # Send thoughts to RAVANA\n        for thought in thoughts:\n            self.ravana_communicator.send_thought_to_ravana(thought)\n        \n        # Synchronize emotional context with RAVANA core system\n        self._synchronize_emotional_context(user_id, emotional_context)\n        \n        # Return the response\n        return response\n        \n    except Exception as e:\n        logger.error(f\"Error handling user message: {e}\")\n        logger.error(f\"Traceback: {traceback.format_exc()}\")\n        return \"I'm having trouble processing your message right now.\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis enhancement ensures that the emotional state of the AI agent is consistently maintained across both the conversational interface and the core reasoning system, enabling more coherent and contextually appropriate interactions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emain.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eravana_bridge.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eMood Transition Logic and Examples\u003c/h2\u003e\n\u003ch3\u003eExample Mood Transitions\u003c/h3\u003e\n\u003cp\u003eUsing the example from the configuration:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\"The agent discovered a new topic about quantum computing.\"\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTriggers: \u003ccode\u003e{\"new_discovery\": true}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eMood update: \u003ccode\u003e{\"Curious\": 0.2, \"Excited\": 0.15, \"Inspired\": 0.1}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eResult: Increased curiosity, excitement, and inspiration\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\"Task completed successfully.\"\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTriggers: \u003ccode\u003e{\"task_completed\": true}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eMood update: \u003ccode\u003e{\"Confident\": 0.25, \"Satisfied\": 0.2, \"Content\": 0.1}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eResult: Increased confidence and satisfaction\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\"An error occurred while processing the data.\"\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTriggers: \u003ccode\u003e{\"error_occurred\": true}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eMood update: \u003ccode\u003e{\"Frustrated\": 0.3, \"Stuck\": 0.2, \"Anxious\": 0.1}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eResult: Increased frustration, feeling stuck, and anxiety\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePersona Effects Example\u003c/h3\u003e\n\u003cp\u003eWhen switching from \"Optimistic\" to \"Pessimistic\" persona:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe same \"task_completed\" event would produce a smaller increase in \"Confident\" (multiplied by 0.8 instead of 1.5)\u003c/li\u003e\n\u003cli\u003eThe same \"error_occurred\" event would produce a larger increase in \"Frustrated\" (multiplied by 1.5 instead of 0.5)\u003c/li\u003e\n\u003cli\u003eThis creates a systematically more negative emotional response pattern\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCommon Issues and Best Practices\u003c/h2\u003e\n\u003ch3\u003eCommon Issues\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eMood Instability\u003c/strong\u003e: Rapid mood swings can occur if decay rates are too low or update deltas are too high.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInconsistent Emotional Responses\u003c/strong\u003e: May result from ambiguous trigger definitions or poorly calibrated LLM prompts.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePersona Drift\u003c/strong\u003e: The agent's behavior may become inconsistent if personas are changed too frequently without proper transition logic.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eJSON Parsing Failures\u003c/strong\u003e: LLM responses may not be valid JSON, requiring robust fallback strategies.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eBest Practices for Tuning\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eBalance Decay and Update Rates\u003c/strong\u003e: Ensure decay is sufficient to prevent mood saturation but not so high that emotions disappear too quickly.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCalibrate Multipliers\u003c/strong\u003e: Test persona multipliers to ensure they produce meaningful but not extreme behavioral differences.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDefine Clear Triggers\u003c/strong\u003e: Ensure trigger definitions are specific and non-overlapping to avoid ambiguous classification.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMonitor Mood History\u003c/strong\u003e: Track mood vectors over time to identify patterns of instability or stagnation.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eValidate LLM Outputs\u003c/strong\u003e: Implement robust error handling for LLM-based mood updates, including multiple fallback parsing strategies.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest Mood Blending\u003c/strong\u003e: Verify that mood blending rules create realistic emotional transitions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAdjust Adaptation Rates\u003c/strong\u003e: Tune persona adaptation rates to match desired responsiveness to emotional changes.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBy following these best practices, developers can create emotionally intelligent agents that exhibit stable, consistent, and realistic emotional responses that enhance the overall believability and effectiveness of the AI system.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReferenced Files in This Document\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eemotional_intellegence.py\u003c/a\u003e - \u003cem\u003eUpdated with enhanced mood dynamics and emotional event logging\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emood_processor.py\u003c/a\u003e - \u003cem\u003eUpdated with improved JSON extraction and safer LLM integration\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003epersona.json\u003c/a\u003e - \u003cem\u003eExpanded with additional personas and adaptation rates\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003econfig.json\u003c/a\u003e - \u003cem\u003eEnhanced with primary/secondary emotion categories and mood dynamics\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003econversational_ei.py\u003c/a\u003e - \u003cem\u003eIntegrated with conversational AI and user interest detection\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003esystem.py\u003c/a\u003e - \u003cem\u003eUpdated with state restoration and emotional memory integration\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emain.py\u003c/a\u003e - \u003cem\u003eAdded emotional context synchronization with RAVANA core system\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eravana_bridge.py\u003c/a\u003e - \u003cem\u003eImplemented emotional context update messaging\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n"},"docs":[{"slug":"Action System","title":"Action System"},{"slug":"API Reference","title":"API Reference"},{"slug":"Architecture \u0026 Design","title":"Architecture \u0026 Design"},{"slug":"Configuration","title":"Configuration"},{"slug":"Conversational AI Communication Framework","title":"Conversational AI Communication Framework"},{"slug":"Core System","title":"Core System"},{"slug":"Database Schema","title":"Database Schema"},{"slug":"Decision-Making System","title":"Decision-Making System"},{"slug":"Deployment \u0026 Operations","title":"Deployment \u0026 Operations"},{"slug":"Development Guide","title":"Development Guide"},{"slug":"Emotional Intelligence","title":"Emotional Intelligence"},{"slug":"Enhanced Snake Agent","title":"Enhanced Snake Agent"},{"slug":"Enhanced Snake Agent Architecture","title":"Enhanced Snake Agent Architecture"},{"slug":"Graceful Shutdown","title":"Graceful Shutdown"},{"slug":"LLM Integration","title":"LLM Integration"},{"slug":"Memory Systems","title":"Memory Systems"},{"slug":"Multi-Modal Memory","title":"Multi-Modal Memory"},{"slug":"Project Overview","title":"Project Overview"},{"slug":"Self-Improvement","title":"Self-Improvement"},{"slug":"Services","title":"Services"},{"slug":"Snake Agent Configuration","title":"Snake Agent Configuration"},{"slug":"Specialized Modules-57f9b30b-b165-48d3-8e89-196940d26190","title":"Specialized Modules"},{"slug":"Specialized Modules","title":"Specialized Modules"}]},"__N_SSG":true},"page":"/docs/[slug]","query":{"slug":"Emotional Intelligence"},"buildId":"QHWQNiRZOuW15nbk5-ngt","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>