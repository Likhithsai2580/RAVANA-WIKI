<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta charSet="utf-8"/><title>Decision-Making System<!-- --> - RAVANA AGI Documentation</title><meta name="description" content="Documentation for Decision-Making System"/><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/aa7d986e9c238cc1.css" as="style"/><link rel="stylesheet" href="/_next/static/css/aa7d986e9c238cc1.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js" defer="" data-nscript="beforeInteractive"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js" defer="" data-nscript="beforeInteractive"></script><script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.0/dist/mermaid.min.js" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-eb143115b8bf2786.js" defer=""></script><script src="/_next/static/chunks/pages/_app-a41459f5c0b49356.js" defer=""></script><script src="/_next/static/chunks/664-d254d21a6fe56bff.js" defer=""></script><script src="/_next/static/chunks/pages/docs/%5Bslug%5D-37d587d3c8e56222.js" defer=""></script><script src="/_next/static/QHWQNiRZOuW15nbk5-ngt/_buildManifest.js" defer=""></script><script src="/_next/static/QHWQNiRZOuW15nbk5-ngt/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="min-h-screen flex flex-col"><div class="min-h-screen flex flex-col"><header class="bg-wiki-blue text-white p-4 shadow-md"><div class="container mx-auto flex justify-between items-center"><h1 class="text-2xl font-bold">RAVANA AGI Documentation</h1><nav><ul class="flex space-x-4"><li><a class="hover:underline" href="/">Home</a></li></ul></nav></div></header><div class="flex-grow container mx-auto p-4 flex flex-col md:flex-row gap-6"><div class="w-full md:w-64 flex-shrink-0"><nav class="w-full md:w-64 flex-shrink-0"><div class="bg-white rounded-lg shadow p-4 sticky top-4"><h3 class="font-bold text-lg mb-3">Documentation</h3><ul class="space-y-1"><li class="mb-3"><div class="font-semibold text-gray-700">A</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Action%20System">Action System</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/API%20Reference">API Reference</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Architecture%20&amp;%20Design">Architecture &amp; Design</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">C</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Configuration">Configuration</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Conversational%20AI%20Communication%20Framework">Conversational AI Communication Framework</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Core%20System">Core System</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">D</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Database%20Schema">Database Schema</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 bg-wiki-blue text-white" href="/docs/Decision-Making%20System">Decision-Making System</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Deployment%20&amp;%20Operations">Deployment &amp; Operations</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Development%20Guide">Development Guide</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">E</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Emotional%20Intelligence">Emotional Intelligence</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Enhanced%20Snake%20Agent">Enhanced Snake Agent</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Enhanced%20Snake%20Agent%20Architecture">Enhanced Snake Agent Architecture</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">G</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Graceful%20Shutdown">Graceful Shutdown</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">L</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/LLM%20Integration">LLM Integration</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">M</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Memory%20Systems">Memory Systems</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Multi-Modal%20Memory">Multi-Modal Memory</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">P</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Project%20Overview">Project Overview</a></li></ul></li><li class="mb-3"><div class="font-semibold text-gray-700">S</div><ul class="ml-2 mt-1 space-y-1"><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Self-Improvement">Self-Improvement</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Services">Services</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Snake%20Agent%20Configuration">Snake Agent Configuration</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Specialized%20Modules-57f9b30b-b165-48d3-8e89-196940d26190">Specialized Modules</a></li><li><a class="block py-1 px-2 rounded hover:bg-gray-100 text-gray-600" href="/docs/Specialized%20Modules">Specialized Modules</a></li></ul></li></ul></div></nav></div><main class="flex-grow"><nav class="mb-4 text-sm"><ol class="list-none p-0 inline-flex"><li class="flex items-center"><a class="text-wiki-blue hover:underline" href="/">Home</a><svg class="fill-current w-3 h-3 mx-3" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"></path></svg></li><li class="flex items-center"><span class="text-gray-500">Decision-Making System</span></li></ol></nav><div class="flex flex-col md:flex-row gap-6"><article class="prose max-w-none bg-white p-6 rounded-lg shadow flex-grow"><h1>Decision-Making System</h1><div><h1>Decision-Making System</h1>
<h2>Table of Contents</h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#project-structure">Project Structure</a></li>
<li><a href="#core-components">Core Components</a></li>
<li><a href="#architecture-overview">Architecture Overview</a></li>
<li><a href="#detailed-component-analysis">Detailed Component Analysis</a></li>
<li><a href="#dependency-analysis">Dependency Analysis</a></li>
<li><a href="#performance-considerations">Performance Considerations</a></li>
<li><a href="#troubleshooting-guide">Troubleshooting Guide</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2>Introduction</h2>
<p>This document provides a comprehensive overview of the decision-making system within the RAVANA AGI framework. The system is designed to enable autonomous, goal-driven behavior through a sophisticated integration of planning, hypothesis testing, LLM-based reasoning, and external data sources. It operates on a continuous loop from situation recognition to action execution, incorporating emotional state, memory, and learning to adapt over time. The architecture emphasizes structured planning, confidence-aware decisions, and robust fallback mechanisms to handle uncertainty and avoid stuck states.</p>
<h2>Project Structure</h2>
<p>The decision-making system is distributed across several modules and core components within the RAVANA repository. The primary logic resides in the <code>modules/decision_engine</code> directory, which contains the <code>decision_maker.py</code> and <code>planner.py</code> files for core decision and planning logic. The <code>core/llm.py</code> file provides the interface to multiple LLM providers, which is central to the decision-making process. State management is handled by <code>core/state.py</code>, while external data integration is facilitated by modules like <code>event_detection</code> and services like <code>data_service.py</code>. The overall structure is modular, allowing for independent development and testing of components like emotional intelligence, curiosity, and memory.</p>
<pre><code class="language-mermaid">graph TD
subgraph "Core System"
State[core/state.py&#x3C;br/>SharedState]
LLM[core/llm.py&#x3C;br/>LLM Interface]
System[core/system.py&#x3C;br/>AGISystem]
end
subgraph "Decision Engine"
Planner[modules/decision_engine/planner.py&#x3C;br/>GoalPlanner]
DecisionMaker[modules/decision_engine/decision_maker.py&#x3C;br/>Decision Logic]
end
subgraph "Supporting Modules"
EmotionalIntelligence[modules/emotional_intellegence/emotional_intellegence.py&#x3C;br/>Mood &#x26; Behavior]
EventDetection[modules/event_detection/event_detector.py&#x3C;br/>Event Detection]
AdaptiveLearning[modules/adaptive_learning/learning_engine.py&#x3C;br/>Learning Engine]
SituationGenerator[modules/situation_generator/situation_generator.py&#x3C;br/>Situation Creation]
end
subgraph "Services"
DataService[services/data_service.py&#x3C;br/>Data &#x26; Event Handling]
end
System --> State
System --> LLM
System --> Planner
System --> DecisionMaker
System --> EmotionalIntelligence
System --> AdaptiveLearning
System --> SituationGenerator
System --> DataService
DataService --> EventDetection
</code></pre>
<p><strong>Diagram sources</strong></p>
<ul>
<li><a>core/state.py</a></li>
<li><a>core/llm.py</a></li>
<li><a>modules/decision_engine/planner.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
<li><a>modules/emotional_intellegence/emotional_intellegence.py</a></li>
<li><a>modules/event_detection/event_detector.py</a></li>
<li><a>services/data_service.py</a></li>
<li><a>modules/adaptive_learning/learning_engine.py</a></li>
<li><a>modules/situation_generator/situation_generator.py</a></li>
<li><a>core/system.py</a></li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/state.py</a></li>
<li><a>core/llm.py</a></li>
<li><a>modules/decision_engine/planner.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
<li><a>modules/emotional_intellegence/emotional_intellegence.py</a></li>
<li><a>modules/event_detection/event_detector.py</a></li>
<li><a>services/data_service.py</a></li>
<li><a>modules/adaptive_learning/learning_engine.py</a></li>
<li><a>modules/situation_generator/situation_generator.py</a></li>
<li><a>core/system.py</a></li>
</ul>
<h2>Core Components</h2>
<p>The core components of the decision-making system are the <code>GoalPlanner</code>, the <code>DecisionMaker</code>, and the <code>SharedState</code>. The <code>GoalPlanner</code> manages a hierarchy of long-term goals, breaking them down into sub-goals and tasks. The <code>DecisionMaker</code> uses LLM input to analyze situations, evaluate options, and generate actions based on the current state, goals, and hypotheses. The <code>SharedState</code> acts as a central repository for the system's mood, current situation, recent memories, and other contextual data, ensuring all components have a consistent view of the agent's internal and external world. These components work in concert, with the <code>DecisionMaker</code> relying on the <code>GoalPlanner</code> for strategic direction and the <code>SharedState</code> for contextual awareness.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/decision_engine/planner.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
<li><a>core/state.py</a></li>
</ul>
<h2>Architecture Overview</h2>
<p>The decision-making architecture is a goal-driven loop that integrates multiple cognitive functions. The process begins with the <code>SituationGenerator</code> creating a new situation, which could be based on external events, internal curiosity, or subconscious processing. This situation is then fed into the <code>DecisionMaker</code>, which uses an LLM to generate a decision. The LLM prompt includes the current situation, the agent's mood, relevant memories, available actions, and its long-term goals. The <code>DecisionMaker</code> evaluates the LLM's response, extracts a structured decision, and returns an action for execution. After the action is executed, the system updates its mood, records the outcome for learning, and retrieves new memories, closing the loop. This architecture allows for flexible, context-aware decision-making that can adapt to changing circumstances.</p>
<pre><code class="language-mermaid">sequenceDiagram
participant SG as SituationGenerator
participant DM as DecisionMaker
participant LLM as LLM
participant AM as ActionManager
participant EI as EmotionalIntelligence
participant AL as AdaptiveLearning
participant SS as SharedState
SG->>DM : Generate Situation
activate DM
DM->>LLM : Send Prompt with State
activate LLM
LLM-->>DM : Return Raw Response
deactivate LLM
DM->>DM : Extract Decision
DM-->>AM : Execute Action
activate AM
AM-->>DM : Return Result
deactivate AM
DM->>EI : Process Result
EI-->>SS : Update Mood
DM->>AL : Record Outcome
DM->>SS : Update State
deactivate DM
</code></pre>
<p><strong>Diagram sources</strong></p>
<ul>
<li><a>modules/situation_generator/situation_generator.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
<li><a>core/llm.py</a></li>
<li><a>core/system.py</a></li>
<li><a>modules/adaptive_learning/learning_engine.py</a></li>
</ul>
<h2>Detailed Component Analysis</h2>
<h3>Goal-Driven Architecture and Planning Mechanisms</h3>
<p>The system employs a hierarchical goal-driven architecture. The <code>GoalPlanner</code> class manages a collection of goals stored in an in-memory dictionary. Goals are created using the <code>plan_from_context</code> function, which takes a natural language description and converts it into a structured goal object with a unique ID, title, description, and status. The planner supports breaking down high-level goals into sub-goals, creating a tree-like structure. For example, a goal like "Learn reinforcement learning basics" can be decomposed into sub-goals such as "Understand Q-learning" and "Implement a DQN agent." The <code>get_goals</code> method allows the decision-maker to retrieve all active goals, which are then used to guide the decision-making process. This hierarchical approach enables the system to manage complex, long-term objectives by focusing on one actionable task at a time.</p>
<pre><code class="language-mermaid">classDiagram
class GoalPlanner {
+get_goal(goal_id : str) Dict[str, Any]
+get_goals(status : str) List[Dict[str, Any]]
+add_sub_goal(parent_id : str, description : str) str
+update_goal_status(goal_id : str, status : str) bool
}
class Goal {
+id : str
+title : str
+description : str
+timeframe : str
+status : str
+sub_goals : List[Dict[str, Any]]
+tasks : List[Dict[str, Any]]
+context : str
}
GoalPlanner --> Goal : "manages"
</code></pre>
<p><strong>Diagram sources</strong></p>
<ul>
<li><a>modules/decision_engine/planner.py</a></li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/decision_engine/planner.py</a></li>
</ul>
<h3>Hypothesis Testing and Experimentation</h3>
<p>The system can generate and test hypotheses as part of its self-improvement cycle. The <code>goal_driven_decision_maker_loop</code> function checks for opportunities to start an experiment, with a 10% probability if no experiment is active. It calls <code>generate_hypothesis</code> from the <code>agent_self_reflection</code> module to create a new hypothesis based on the current state. If a hypothesis is generated, the decision-maker returns a decision with the action <code>initiate_experiment</code>, which triggers the creation of a test situation. The system can also analyze the outcome of a completed experiment by calling <code>analyze_experiment_outcome</code>. The <code>agi_experimentation_engine</code> function in <code>llm.py</code> provides a unified framework for experimentation, which can involve generating and executing Python code, performing online validation with search, and providing a final verdict on the hypothesis. This closed-loop process allows the agent to learn from its own actions and refine its understanding of the world.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>modules/decision_engine/decision_maker.py</a></li>
<li><a>core/llm.py</a></li>
</ul>
<h3>Decision Evaluation with LLM Input</h3>
<p>The <code>decision_maker_loop</code> function in <code>llm.py</code> is responsible for evaluating options using LLM input. It constructs a comprehensive prompt that includes the current situation, emotional state, relevant memories, external knowledge (RAG), and available actions. The prompt instructs the LLM to perform a deep analysis, create a strategic plan, assess its confidence, provide a reasoning chain, and specify the first action. The LLM is expected to respond with a JSON object containing keys like <code>analysis</code>, <code>plan</code>, <code>action</code>, <code>params</code>, <code>confidence</code>, and <code>reasoning</code>. The <code>extract_decision</code> function parses this response, handling cases where the JSON is malformed by returning a default structure with an error message. The confidence score (a float between 0.0 and 1.0) is used by the system to gauge the reliability of the decision. This structured approach ensures that the LLM's output is predictable and can be reliably integrated into the agent's action loop.</p>
<pre><code class="language-mermaid">flowchart TD
Start([Start Decision Loop]) --> PrepareContext["Prepare Context&#x3C;br/>(Situation, Mood, Memory, RAG)"]
PrepareContext --> ConstructPrompt["Construct LLM Prompt"]
ConstructPrompt --> CallLLM["Call LLM with safe_call_llm"]
CallLLM --> ExtractDecision["Extract Decision with extract_decision"]
ExtractDecision --> ParseJSON{"Valid JSON?"}
ParseJSON --> |Yes| UseData["Use analysis, plan, action, confidence"]
ParseJSON --> |No| Fallback["Use fallback plan, log error"]
UseData --> ReturnDecision["Return Decision"]
Fallback --> ReturnDecision
ReturnDecision --> End([End])
</code></pre>
<p><strong>Diagram sources</strong></p>
<ul>
<li><a>core/llm.py</a></li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/llm.py</a></li>
</ul>
<h3>Integration with External Data</h3>
<p>The system integrates external data through search results and event detection. The <code>call_gemini_with_search</code> function in <code>llm.py</code> enables the LLM to perform Google searches, with results being added to a <code>search_result_manager</code>. This allows the agent to access up-to-date information for its decisions. The <code>event_detection</code> module processes a stream of text (e.g., news articles) to detect significant events. It uses an embedding model to cluster similar documents and a sentiment classifier to filter out irrelevant or negative content. The <code>data_service.py</code> module periodically fetches articles from configured feeds and runs them through the event detector, saving detected events to the database. These events can then influence the <code>SituationGenerator</code>, creating situations that respond to real-world developments. This integration ensures the agent's decisions are informed by current events and external knowledge.</p>
<pre><code class="language-mermaid">sequenceDiagram
participant DS as DataService
participant ED as EventDetector
participant DB as Database
DS->>ED : fetch_and_save_articles()
ED->>ED : process_data_for_events(texts)
ED->>ED : filter_content()
ED->>ED : get_embeddings()
ED->>ED : cluster_documents()
ED->>ED : generate_event_alerts()
ED-->>DS : return events
DS->>DB : save events to database
</code></pre>
<p><strong>Diagram sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
<li><a>modules/event_detection/event_detector.py</a></li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>services/data_service.py</a></li>
<li><a>modules/event_detection/event_detector.py</a></li>
</ul>
<h3>Workflow from Situation Recognition to Action Selection</h3>
<p>The complete workflow begins with situation recognition. The <code>AGISystem</code>'s main loop calls <code>_generate_situation</code>, which uses the <code>SituationGenerator</code> to create a new situation based on the current state, curiosity topics, and behavior modifiers. This situation is then passed to the <code>decision_maker_loop</code>, which constructs a prompt and sends it to an LLM. The LLM's response is parsed into a decision object. The <code>ActionManager</code> then executes the specified action, such as writing a file or logging a message. After execution, the system updates the agent's mood based on the action's outcome, records the decision and its result for future learning, and retrieves relevant memories for the next cycle. The <code>current_plan</code> is also managed; if the decision contains a multi-step plan, the remaining steps are stored for future execution. This end-to-end workflow enables the agent to operate autonomously, continuously making decisions and taking actions.</p>
<pre><code class="language-mermaid">flowchart LR
A[Situation Recognition] --> B[Decision Making]
B --> C[Action Selection]
C --> D[Action Execution]
D --> E[Mood Update]
E --> F[Learning &#x26; Memory]
F --> A
</code></pre>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
<li><a>core/system.py</a></li>
<li><a>core/llm.py</a></li>
</ul>
<h3>Handling Uncertainty and Confidence Scores</h3>
<p>The system handles uncertainty through explicit confidence scores and fallback strategies. The LLM is instructed to include a <code>confidence</code> field in its response, a float between 0.0 and 1.0. This score is used by the system to prioritize high-confidence decisions and to trigger fallback mechanisms when confidence is low. The <code>extract_decision</code> function includes a default confidence of 0.5 if the field is missing. The decision structure also includes a <code>fallback_plan</code> field, which specifies what to do if the primary action fails. The <code>safe_call_llm</code> function implements retry logic with exponential backoff, attempting up to three times before failing. The <code>is_lazy_llm_response</code> function can detect generic or unhelpful responses, allowing the system to retry with a different prompt or provider. This multi-layered approach ensures robust operation even when the LLM is uncertain or produces a poor response.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/llm.py</a></li>
<li><a>core/llm.py</a></li>
</ul>
<h3>Integration with Emotional State and Memory Systems</h3>
<p>The decision-making process is deeply integrated with the agent's emotional state and memory systems. The <code>SharedState</code> object contains the current <code>mood</code> vector and a list of <code>recent_memories</code>. These are included in the LLM prompt, allowing the agent's decisions to be influenced by its current emotional state and past experiences. After an action is executed, the <code>EmotionalIntelligence</code> module processes the outcome to update the mood vector. For example, a successful action might increase <code>happy</code> and <code>confident</code>, while an error might increase <code>frustrated</code>. The updated mood is then stored in the <code>SharedState</code>. The <code>AdaptiveLearningEngine</code> records each decision and its outcome, building a history that can be analyzed to improve future decisions. This integration creates a cohesive cognitive architecture where emotion, memory, and learning all contribute to more intelligent and adaptive behavior.</p>
<pre><code class="language-mermaid">classDiagram
class SharedState {
+mood : Dict[str, float]
+recent_memories : List[Dict[str, Any]]
+current_situation : Dict[str, Any]
+get_state_summary() str
}
class EmotionalIntelligence {
+process_action_natural(output : str)
+get_mood_vector() Dict[str, float]
+influence_behavior() Dict[str, Any]
}
class AdaptiveLearningEngine {
+record_decision_outcome(decision : Dict, outcome : Any, success : bool)
+analyze_decision_patterns() Dict[str, Any]
}
SharedState &#x3C;.. EmotionalIntelligence : "updates"
SharedState &#x3C;.. AdaptiveLearningEngine : "uses"
</code></pre>
<p><strong>Diagram sources</strong></p>
<ul>
<li><a>core/state.py</a></li>
<li><a>modules/emotional_intellegence/emotional_intellegence.py</a></li>
<li><a>modules/adaptive_learning/learning_engine.py</a></li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/state.py</a></li>
<li><a>core/system.py</a></li>
<li><a>modules/emotional_intellegence/emotional_intellegence.py</a></li>
<li><a>modules/adaptive_learning/learning_engine.py</a></li>
</ul>
<h2>Dependency Analysis</h2>
<p>The decision-making system has a clear dependency hierarchy. The top-level <code>AGISystem</code> class depends on all other components, orchestrating their interactions. The <code>DecisionMaker</code> depends on <code>llm.py</code> for LLM calls, <code>planner.py</code> for goal management, and <code>state.py</code> for contextual data. The <code>SituationGenerator</code> depends on the <code>emotional_intellegence</code> and <code>curiosity_trigger</code> modules to create contextually relevant situations. The <code>data_service.py</code> module depends on <code>event_detector.py</code> for event processing and the database models for persistence. There are no circular dependencies, and the use of well-defined interfaces (e.g., the LLM prompt format) allows for loose coupling between components. This modular design makes the system easy to extend and maintain.</p>
<pre><code class="language-mermaid">graph TD
AGISystem --> DecisionMaker
AGISystem --> SituationGenerator
AGISystem --> EmotionalIntelligence
AGISystem --> AdaptiveLearning
AGISystem --> DataService
AGISystem --> SharedState
DecisionMaker --> LLM
DecisionMaker --> Planner
DecisionMaker --> SharedState
SituationGenerator --> EmotionalIntelligence
SituationGenerator --> CuriosityTrigger
DataService --> EventDetector
DataService --> Database
</code></pre>
<p><strong>Diagram sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
</ul>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/system.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
</ul>
<h2>Performance Considerations</h2>
<p>The system's performance is primarily constrained by LLM call latency and the complexity of the decision-making loop. The <code>safe_call_llm</code> function includes a 30-second timeout and retry logic, which can add significant delay if the LLM is slow or unresponsive. To mitigate this, the system uses a fast local LLM as a fallback and caches repeated actions in the <code>EnhancedActionManager</code>. The <code>SituationGenerator</code> and <code>EventDetector</code> are computationally intensive due to the use of embedding models and clustering algorithms, but these are run asynchronously and not on every decision loop. The in-memory storage of goals and state ensures fast access, but could become a bottleneck if the number of goals grows very large. Overall, the system is designed for quality of decision over speed, prioritizing thorough analysis and robustness.</p>
<h2>Troubleshooting Guide</h2>
<p>Common issues in the decision-making system include decision loops, stuck states, and suboptimal planning. A decision loop can occur if the agent repeatedly generates the same situation and takes the same action without progress. This can be mitigated by ensuring the <code>AdaptiveLearningEngine</code> is properly recording outcomes and adjusting behavior. A stuck state might happen if the LLM consistently returns low-confidence decisions or errors. Checking the LLM provider configuration and fallback mechanisms in <code>llm.py</code> is essential. Suboptimal planning can result from poor goal decomposition or inadequate memory retrieval. Reviewing the <code>GoalPlanner</code> logic and the <code>memory_service</code> configuration can help. For debugging, enable verbose logging and inspect the <code>decision_history</code> and <code>mood_history</code> in the <code>SharedState</code>. If the agent is not generating new hypotheses, verify that the <code>agent_self_reflection</code> module is loaded and functioning.</p>
<p><strong>Section sources</strong></p>
<ul>
<li><a>core/llm.py</a></li>
<li><a>modules/adaptive_learning/learning_engine.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
</ul>
<h2>Conclusion</h2>
<p>The RAVANA decision-making system is a sophisticated, goal-driven architecture that leverages LLMs for high-level reasoning while maintaining robust control through structured planning and state management. Its integration of emotion, memory, and learning creates a cohesive cognitive model capable of autonomous, adaptive behavior. The system's modular design and clear interfaces make it extensible and maintainable. By handling uncertainty through confidence scores and fallback strategies, and by continuously learning from its experiences, the agent is well-equipped to operate effectively in complex and dynamic environments. Future improvements could include more sophisticated goal prioritization and deeper integration of the learning engine into the decision loop.</p>
<p><strong>Referenced Files in This Document</strong></p>
<ul>
<li><a>core/llm.py</a></li>
<li><a>core/state.py</a></li>
<li><a>modules/decision_engine/decision_maker.py</a></li>
<li><a>modules/decision_engine/planner.py</a></li>
<li><a>modules/adaptive_learning/learning_engine.py</a></li>
<li><a>modules/event_detection/event_detector.py</a></li>
<li><a>services/data_service.py</a></li>
<li><a>core/system.py</a></li>
<li><a>modules/emotional_intellegence/emotional_intellegence.py</a></li>
<li><a>modules/situation_generator/situation_generator.py</a></li>
</ul>
</div></article><div class="w-full md:w-64 flex-shrink-0"></div></div></main></div><footer class="bg-wiki-dark text-white p-4"><div class="container mx-auto text-center"><p>© <!-- -->2025<!-- --> RAVANA AGI System Documentation</p></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"doc":{"slug":"Decision-Making System","title":"Decision-Making System","content":"\u003ch1\u003eDecision-Making System\u003c/h1\u003e\n\u003ch2\u003eTable of Contents\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#project-structure\"\u003eProject Structure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#core-components\"\u003eCore Components\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#architecture-overview\"\u003eArchitecture Overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#detailed-component-analysis\"\u003eDetailed Component Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dependency-analysis\"\u003eDependency Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#performance-considerations\"\u003ePerformance Considerations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#troubleshooting-guide\"\u003eTroubleshooting Guide\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#conclusion\"\u003eConclusion\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThis document provides a comprehensive overview of the decision-making system within the RAVANA AGI framework. The system is designed to enable autonomous, goal-driven behavior through a sophisticated integration of planning, hypothesis testing, LLM-based reasoning, and external data sources. It operates on a continuous loop from situation recognition to action execution, incorporating emotional state, memory, and learning to adapt over time. The architecture emphasizes structured planning, confidence-aware decisions, and robust fallback mechanisms to handle uncertainty and avoid stuck states.\u003c/p\u003e\n\u003ch2\u003eProject Structure\u003c/h2\u003e\n\u003cp\u003eThe decision-making system is distributed across several modules and core components within the RAVANA repository. The primary logic resides in the \u003ccode\u003emodules/decision_engine\u003c/code\u003e directory, which contains the \u003ccode\u003edecision_maker.py\u003c/code\u003e and \u003ccode\u003eplanner.py\u003c/code\u003e files for core decision and planning logic. The \u003ccode\u003ecore/llm.py\u003c/code\u003e file provides the interface to multiple LLM providers, which is central to the decision-making process. State management is handled by \u003ccode\u003ecore/state.py\u003c/code\u003e, while external data integration is facilitated by modules like \u003ccode\u003eevent_detection\u003c/code\u003e and services like \u003ccode\u003edata_service.py\u003c/code\u003e. The overall structure is modular, allowing for independent development and testing of components like emotional intelligence, curiosity, and memory.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003egraph TD\nsubgraph \"Core System\"\nState[core/state.py\u0026#x3C;br/\u003eSharedState]\nLLM[core/llm.py\u0026#x3C;br/\u003eLLM Interface]\nSystem[core/system.py\u0026#x3C;br/\u003eAGISystem]\nend\nsubgraph \"Decision Engine\"\nPlanner[modules/decision_engine/planner.py\u0026#x3C;br/\u003eGoalPlanner]\nDecisionMaker[modules/decision_engine/decision_maker.py\u0026#x3C;br/\u003eDecision Logic]\nend\nsubgraph \"Supporting Modules\"\nEmotionalIntelligence[modules/emotional_intellegence/emotional_intellegence.py\u0026#x3C;br/\u003eMood \u0026#x26; Behavior]\nEventDetection[modules/event_detection/event_detector.py\u0026#x3C;br/\u003eEvent Detection]\nAdaptiveLearning[modules/adaptive_learning/learning_engine.py\u0026#x3C;br/\u003eLearning Engine]\nSituationGenerator[modules/situation_generator/situation_generator.py\u0026#x3C;br/\u003eSituation Creation]\nend\nsubgraph \"Services\"\nDataService[services/data_service.py\u0026#x3C;br/\u003eData \u0026#x26; Event Handling]\nend\nSystem --\u003e State\nSystem --\u003e LLM\nSystem --\u003e Planner\nSystem --\u003e DecisionMaker\nSystem --\u003e EmotionalIntelligence\nSystem --\u003e AdaptiveLearning\nSystem --\u003e SituationGenerator\nSystem --\u003e DataService\nDataService --\u003e EventDetection\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDiagram sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/state.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/planner.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/emotional_intellegence/emotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/event_detection/event_detector.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/adaptive_learning/learning_engine.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/situation_generator/situation_generator.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/state.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/planner.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/emotional_intellegence/emotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/event_detection/event_detector.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/adaptive_learning/learning_engine.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/situation_generator/situation_generator.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCore Components\u003c/h2\u003e\n\u003cp\u003eThe core components of the decision-making system are the \u003ccode\u003eGoalPlanner\u003c/code\u003e, the \u003ccode\u003eDecisionMaker\u003c/code\u003e, and the \u003ccode\u003eSharedState\u003c/code\u003e. The \u003ccode\u003eGoalPlanner\u003c/code\u003e manages a hierarchy of long-term goals, breaking them down into sub-goals and tasks. The \u003ccode\u003eDecisionMaker\u003c/code\u003e uses LLM input to analyze situations, evaluate options, and generate actions based on the current state, goals, and hypotheses. The \u003ccode\u003eSharedState\u003c/code\u003e acts as a central repository for the system's mood, current situation, recent memories, and other contextual data, ensuring all components have a consistent view of the agent's internal and external world. These components work in concert, with the \u003ccode\u003eDecisionMaker\u003c/code\u003e relying on the \u003ccode\u003eGoalPlanner\u003c/code\u003e for strategic direction and the \u003ccode\u003eSharedState\u003c/code\u003e for contextual awareness.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/planner.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/state.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eArchitecture Overview\u003c/h2\u003e\n\u003cp\u003eThe decision-making architecture is a goal-driven loop that integrates multiple cognitive functions. The process begins with the \u003ccode\u003eSituationGenerator\u003c/code\u003e creating a new situation, which could be based on external events, internal curiosity, or subconscious processing. This situation is then fed into the \u003ccode\u003eDecisionMaker\u003c/code\u003e, which uses an LLM to generate a decision. The LLM prompt includes the current situation, the agent's mood, relevant memories, available actions, and its long-term goals. The \u003ccode\u003eDecisionMaker\u003c/code\u003e evaluates the LLM's response, extracts a structured decision, and returns an action for execution. After the action is executed, the system updates its mood, records the outcome for learning, and retrieves new memories, closing the loop. This architecture allows for flexible, context-aware decision-making that can adapt to changing circumstances.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003esequenceDiagram\nparticipant SG as SituationGenerator\nparticipant DM as DecisionMaker\nparticipant LLM as LLM\nparticipant AM as ActionManager\nparticipant EI as EmotionalIntelligence\nparticipant AL as AdaptiveLearning\nparticipant SS as SharedState\nSG-\u003e\u003eDM : Generate Situation\nactivate DM\nDM-\u003e\u003eLLM : Send Prompt with State\nactivate LLM\nLLM--\u003e\u003eDM : Return Raw Response\ndeactivate LLM\nDM-\u003e\u003eDM : Extract Decision\nDM--\u003e\u003eAM : Execute Action\nactivate AM\nAM--\u003e\u003eDM : Return Result\ndeactivate AM\nDM-\u003e\u003eEI : Process Result\nEI--\u003e\u003eSS : Update Mood\nDM-\u003e\u003eAL : Record Outcome\nDM-\u003e\u003eSS : Update State\ndeactivate DM\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDiagram sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/situation_generator/situation_generator.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/adaptive_learning/learning_engine.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eDetailed Component Analysis\u003c/h2\u003e\n\u003ch3\u003eGoal-Driven Architecture and Planning Mechanisms\u003c/h3\u003e\n\u003cp\u003eThe system employs a hierarchical goal-driven architecture. The \u003ccode\u003eGoalPlanner\u003c/code\u003e class manages a collection of goals stored in an in-memory dictionary. Goals are created using the \u003ccode\u003eplan_from_context\u003c/code\u003e function, which takes a natural language description and converts it into a structured goal object with a unique ID, title, description, and status. The planner supports breaking down high-level goals into sub-goals, creating a tree-like structure. For example, a goal like \"Learn reinforcement learning basics\" can be decomposed into sub-goals such as \"Understand Q-learning\" and \"Implement a DQN agent.\" The \u003ccode\u003eget_goals\u003c/code\u003e method allows the decision-maker to retrieve all active goals, which are then used to guide the decision-making process. This hierarchical approach enables the system to manage complex, long-term objectives by focusing on one actionable task at a time.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003eclassDiagram\nclass GoalPlanner {\n+get_goal(goal_id : str) Dict[str, Any]\n+get_goals(status : str) List[Dict[str, Any]]\n+add_sub_goal(parent_id : str, description : str) str\n+update_goal_status(goal_id : str, status : str) bool\n}\nclass Goal {\n+id : str\n+title : str\n+description : str\n+timeframe : str\n+status : str\n+sub_goals : List[Dict[str, Any]]\n+tasks : List[Dict[str, Any]]\n+context : str\n}\nGoalPlanner --\u003e Goal : \"manages\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDiagram sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/planner.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/planner.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHypothesis Testing and Experimentation\u003c/h3\u003e\n\u003cp\u003eThe system can generate and test hypotheses as part of its self-improvement cycle. The \u003ccode\u003egoal_driven_decision_maker_loop\u003c/code\u003e function checks for opportunities to start an experiment, with a 10% probability if no experiment is active. It calls \u003ccode\u003egenerate_hypothesis\u003c/code\u003e from the \u003ccode\u003eagent_self_reflection\u003c/code\u003e module to create a new hypothesis based on the current state. If a hypothesis is generated, the decision-maker returns a decision with the action \u003ccode\u003einitiate_experiment\u003c/code\u003e, which triggers the creation of a test situation. The system can also analyze the outcome of a completed experiment by calling \u003ccode\u003eanalyze_experiment_outcome\u003c/code\u003e. The \u003ccode\u003eagi_experimentation_engine\u003c/code\u003e function in \u003ccode\u003ellm.py\u003c/code\u003e provides a unified framework for experimentation, which can involve generating and executing Python code, performing online validation with search, and providing a final verdict on the hypothesis. This closed-loop process allows the agent to learn from its own actions and refine its understanding of the world.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eDecision Evaluation with LLM Input\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003edecision_maker_loop\u003c/code\u003e function in \u003ccode\u003ellm.py\u003c/code\u003e is responsible for evaluating options using LLM input. It constructs a comprehensive prompt that includes the current situation, emotional state, relevant memories, external knowledge (RAG), and available actions. The prompt instructs the LLM to perform a deep analysis, create a strategic plan, assess its confidence, provide a reasoning chain, and specify the first action. The LLM is expected to respond with a JSON object containing keys like \u003ccode\u003eanalysis\u003c/code\u003e, \u003ccode\u003eplan\u003c/code\u003e, \u003ccode\u003eaction\u003c/code\u003e, \u003ccode\u003eparams\u003c/code\u003e, \u003ccode\u003econfidence\u003c/code\u003e, and \u003ccode\u003ereasoning\u003c/code\u003e. The \u003ccode\u003eextract_decision\u003c/code\u003e function parses this response, handling cases where the JSON is malformed by returning a default structure with an error message. The confidence score (a float between 0.0 and 1.0) is used by the system to gauge the reliability of the decision. This structured approach ensures that the LLM's output is predictable and can be reliably integrated into the agent's action loop.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003eflowchart TD\nStart([Start Decision Loop]) --\u003e PrepareContext[\"Prepare Context\u0026#x3C;br/\u003e(Situation, Mood, Memory, RAG)\"]\nPrepareContext --\u003e ConstructPrompt[\"Construct LLM Prompt\"]\nConstructPrompt --\u003e CallLLM[\"Call LLM with safe_call_llm\"]\nCallLLM --\u003e ExtractDecision[\"Extract Decision with extract_decision\"]\nExtractDecision --\u003e ParseJSON{\"Valid JSON?\"}\nParseJSON --\u003e |Yes| UseData[\"Use analysis, plan, action, confidence\"]\nParseJSON --\u003e |No| Fallback[\"Use fallback plan, log error\"]\nUseData --\u003e ReturnDecision[\"Return Decision\"]\nFallback --\u003e ReturnDecision\nReturnDecision --\u003e End([End])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDiagram sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eIntegration with External Data\u003c/h3\u003e\n\u003cp\u003eThe system integrates external data through search results and event detection. The \u003ccode\u003ecall_gemini_with_search\u003c/code\u003e function in \u003ccode\u003ellm.py\u003c/code\u003e enables the LLM to perform Google searches, with results being added to a \u003ccode\u003esearch_result_manager\u003c/code\u003e. This allows the agent to access up-to-date information for its decisions. The \u003ccode\u003eevent_detection\u003c/code\u003e module processes a stream of text (e.g., news articles) to detect significant events. It uses an embedding model to cluster similar documents and a sentiment classifier to filter out irrelevant or negative content. The \u003ccode\u003edata_service.py\u003c/code\u003e module periodically fetches articles from configured feeds and runs them through the event detector, saving detected events to the database. These events can then influence the \u003ccode\u003eSituationGenerator\u003c/code\u003e, creating situations that respond to real-world developments. This integration ensures the agent's decisions are informed by current events and external knowledge.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003esequenceDiagram\nparticipant DS as DataService\nparticipant ED as EventDetector\nparticipant DB as Database\nDS-\u003e\u003eED : fetch_and_save_articles()\nED-\u003e\u003eED : process_data_for_events(texts)\nED-\u003e\u003eED : filter_content()\nED-\u003e\u003eED : get_embeddings()\nED-\u003e\u003eED : cluster_documents()\nED-\u003e\u003eED : generate_event_alerts()\nED--\u003e\u003eDS : return events\nDS-\u003e\u003eDB : save events to database\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDiagram sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/event_detection/event_detector.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/event_detection/event_detector.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eWorkflow from Situation Recognition to Action Selection\u003c/h3\u003e\n\u003cp\u003eThe complete workflow begins with situation recognition. The \u003ccode\u003eAGISystem\u003c/code\u003e's main loop calls \u003ccode\u003e_generate_situation\u003c/code\u003e, which uses the \u003ccode\u003eSituationGenerator\u003c/code\u003e to create a new situation based on the current state, curiosity topics, and behavior modifiers. This situation is then passed to the \u003ccode\u003edecision_maker_loop\u003c/code\u003e, which constructs a prompt and sends it to an LLM. The LLM's response is parsed into a decision object. The \u003ccode\u003eActionManager\u003c/code\u003e then executes the specified action, such as writing a file or logging a message. After execution, the system updates the agent's mood based on the action's outcome, records the decision and its result for future learning, and retrieves relevant memories for the next cycle. The \u003ccode\u003ecurrent_plan\u003c/code\u003e is also managed; if the decision contains a multi-step plan, the remaining steps are stored for future execution. This end-to-end workflow enables the agent to operate autonomously, continuously making decisions and taking actions.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003eflowchart LR\nA[Situation Recognition] --\u003e B[Decision Making]\nB --\u003e C[Action Selection]\nC --\u003e D[Action Execution]\nD --\u003e E[Mood Update]\nE --\u003e F[Learning \u0026#x26; Memory]\nF --\u003e A\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHandling Uncertainty and Confidence Scores\u003c/h3\u003e\n\u003cp\u003eThe system handles uncertainty through explicit confidence scores and fallback strategies. The LLM is instructed to include a \u003ccode\u003econfidence\u003c/code\u003e field in its response, a float between 0.0 and 1.0. This score is used by the system to prioritize high-confidence decisions and to trigger fallback mechanisms when confidence is low. The \u003ccode\u003eextract_decision\u003c/code\u003e function includes a default confidence of 0.5 if the field is missing. The decision structure also includes a \u003ccode\u003efallback_plan\u003c/code\u003e field, which specifies what to do if the primary action fails. The \u003ccode\u003esafe_call_llm\u003c/code\u003e function implements retry logic with exponential backoff, attempting up to three times before failing. The \u003ccode\u003eis_lazy_llm_response\u003c/code\u003e function can detect generic or unhelpful responses, allowing the system to retry with a different prompt or provider. This multi-layered approach ensures robust operation even when the LLM is uncertain or produces a poor response.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eIntegration with Emotional State and Memory Systems\u003c/h3\u003e\n\u003cp\u003eThe decision-making process is deeply integrated with the agent's emotional state and memory systems. The \u003ccode\u003eSharedState\u003c/code\u003e object contains the current \u003ccode\u003emood\u003c/code\u003e vector and a list of \u003ccode\u003erecent_memories\u003c/code\u003e. These are included in the LLM prompt, allowing the agent's decisions to be influenced by its current emotional state and past experiences. After an action is executed, the \u003ccode\u003eEmotionalIntelligence\u003c/code\u003e module processes the outcome to update the mood vector. For example, a successful action might increase \u003ccode\u003ehappy\u003c/code\u003e and \u003ccode\u003econfident\u003c/code\u003e, while an error might increase \u003ccode\u003efrustrated\u003c/code\u003e. The updated mood is then stored in the \u003ccode\u003eSharedState\u003c/code\u003e. The \u003ccode\u003eAdaptiveLearningEngine\u003c/code\u003e records each decision and its outcome, building a history that can be analyzed to improve future decisions. This integration creates a cohesive cognitive architecture where emotion, memory, and learning all contribute to more intelligent and adaptive behavior.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003eclassDiagram\nclass SharedState {\n+mood : Dict[str, float]\n+recent_memories : List[Dict[str, Any]]\n+current_situation : Dict[str, Any]\n+get_state_summary() str\n}\nclass EmotionalIntelligence {\n+process_action_natural(output : str)\n+get_mood_vector() Dict[str, float]\n+influence_behavior() Dict[str, Any]\n}\nclass AdaptiveLearningEngine {\n+record_decision_outcome(decision : Dict, outcome : Any, success : bool)\n+analyze_decision_patterns() Dict[str, Any]\n}\nSharedState \u0026#x3C;.. EmotionalIntelligence : \"updates\"\nSharedState \u0026#x3C;.. AdaptiveLearningEngine : \"uses\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDiagram sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/state.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/emotional_intellegence/emotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/adaptive_learning/learning_engine.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/state.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/emotional_intellegence/emotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/adaptive_learning/learning_engine.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eDependency Analysis\u003c/h2\u003e\n\u003cp\u003eThe decision-making system has a clear dependency hierarchy. The top-level \u003ccode\u003eAGISystem\u003c/code\u003e class depends on all other components, orchestrating their interactions. The \u003ccode\u003eDecisionMaker\u003c/code\u003e depends on \u003ccode\u003ellm.py\u003c/code\u003e for LLM calls, \u003ccode\u003eplanner.py\u003c/code\u003e for goal management, and \u003ccode\u003estate.py\u003c/code\u003e for contextual data. The \u003ccode\u003eSituationGenerator\u003c/code\u003e depends on the \u003ccode\u003eemotional_intellegence\u003c/code\u003e and \u003ccode\u003ecuriosity_trigger\u003c/code\u003e modules to create contextually relevant situations. The \u003ccode\u003edata_service.py\u003c/code\u003e module depends on \u003ccode\u003eevent_detector.py\u003c/code\u003e for event processing and the database models for persistence. There are no circular dependencies, and the use of well-defined interfaces (e.g., the LLM prompt format) allows for loose coupling between components. This modular design makes the system easy to extend and maintain.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003egraph TD\nAGISystem --\u003e DecisionMaker\nAGISystem --\u003e SituationGenerator\nAGISystem --\u003e EmotionalIntelligence\nAGISystem --\u003e AdaptiveLearning\nAGISystem --\u003e DataService\nAGISystem --\u003e SharedState\nDecisionMaker --\u003e LLM\nDecisionMaker --\u003e Planner\nDecisionMaker --\u003e SharedState\nSituationGenerator --\u003e EmotionalIntelligence\nSituationGenerator --\u003e CuriosityTrigger\nDataService --\u003e EventDetector\nDataService --\u003e Database\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eDiagram sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003ePerformance Considerations\u003c/h2\u003e\n\u003cp\u003eThe system's performance is primarily constrained by LLM call latency and the complexity of the decision-making loop. The \u003ccode\u003esafe_call_llm\u003c/code\u003e function includes a 30-second timeout and retry logic, which can add significant delay if the LLM is slow or unresponsive. To mitigate this, the system uses a fast local LLM as a fallback and caches repeated actions in the \u003ccode\u003eEnhancedActionManager\u003c/code\u003e. The \u003ccode\u003eSituationGenerator\u003c/code\u003e and \u003ccode\u003eEventDetector\u003c/code\u003e are computationally intensive due to the use of embedding models and clustering algorithms, but these are run asynchronously and not on every decision loop. The in-memory storage of goals and state ensures fast access, but could become a bottleneck if the number of goals grows very large. Overall, the system is designed for quality of decision over speed, prioritizing thorough analysis and robustness.\u003c/p\u003e\n\u003ch2\u003eTroubleshooting Guide\u003c/h2\u003e\n\u003cp\u003eCommon issues in the decision-making system include decision loops, stuck states, and suboptimal planning. A decision loop can occur if the agent repeatedly generates the same situation and takes the same action without progress. This can be mitigated by ensuring the \u003ccode\u003eAdaptiveLearningEngine\u003c/code\u003e is properly recording outcomes and adjusting behavior. A stuck state might happen if the LLM consistently returns low-confidence decisions or errors. Checking the LLM provider configuration and fallback mechanisms in \u003ccode\u003ellm.py\u003c/code\u003e is essential. Suboptimal planning can result from poor goal decomposition or inadequate memory retrieval. Reviewing the \u003ccode\u003eGoalPlanner\u003c/code\u003e logic and the \u003ccode\u003ememory_service\u003c/code\u003e configuration can help. For debugging, enable verbose logging and inspect the \u003ccode\u003edecision_history\u003c/code\u003e and \u003ccode\u003emood_history\u003c/code\u003e in the \u003ccode\u003eSharedState\u003c/code\u003e. If the agent is not generating new hypotheses, verify that the \u003ccode\u003eagent_self_reflection\u003c/code\u003e module is loaded and functioning.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSection sources\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/adaptive_learning/learning_engine.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThe RAVANA decision-making system is a sophisticated, goal-driven architecture that leverages LLMs for high-level reasoning while maintaining robust control through structured planning and state management. Its integration of emotion, memory, and learning creates a cohesive cognitive model capable of autonomous, adaptive behavior. The system's modular design and clear interfaces make it extensible and maintainable. By handling uncertainty through confidence scores and fallback strategies, and by continuously learning from its experiences, the agent is well-equipped to operate effectively in complex and dynamic environments. Future improvements could include more sophisticated goal prioritization and deeper integration of the learning engine into the decision loop.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReferenced Files in This Document\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca\u003ecore/llm.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/state.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/decision_maker.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/decision_engine/planner.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/adaptive_learning/learning_engine.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/event_detection/event_detector.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003eservices/data_service.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003ecore/system.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/emotional_intellegence/emotional_intellegence.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\u003emodules/situation_generator/situation_generator.py\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n"},"docs":[{"slug":"Action System","title":"Action System"},{"slug":"API Reference","title":"API Reference"},{"slug":"Architecture \u0026 Design","title":"Architecture \u0026 Design"},{"slug":"Configuration","title":"Configuration"},{"slug":"Conversational AI Communication Framework","title":"Conversational AI Communication Framework"},{"slug":"Core System","title":"Core System"},{"slug":"Database Schema","title":"Database Schema"},{"slug":"Decision-Making System","title":"Decision-Making System"},{"slug":"Deployment \u0026 Operations","title":"Deployment \u0026 Operations"},{"slug":"Development Guide","title":"Development Guide"},{"slug":"Emotional Intelligence","title":"Emotional Intelligence"},{"slug":"Enhanced Snake Agent","title":"Enhanced Snake Agent"},{"slug":"Enhanced Snake Agent Architecture","title":"Enhanced Snake Agent Architecture"},{"slug":"Graceful Shutdown","title":"Graceful Shutdown"},{"slug":"LLM Integration","title":"LLM Integration"},{"slug":"Memory Systems","title":"Memory Systems"},{"slug":"Multi-Modal Memory","title":"Multi-Modal Memory"},{"slug":"Project Overview","title":"Project Overview"},{"slug":"Self-Improvement","title":"Self-Improvement"},{"slug":"Services","title":"Services"},{"slug":"Snake Agent Configuration","title":"Snake Agent Configuration"},{"slug":"Specialized Modules-57f9b30b-b165-48d3-8e89-196940d26190","title":"Specialized Modules"},{"slug":"Specialized Modules","title":"Specialized Modules"}]},"__N_SSG":true},"page":"/docs/[slug]","query":{"slug":"Decision-Making System"},"buildId":"QHWQNiRZOuW15nbk5-ngt","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>