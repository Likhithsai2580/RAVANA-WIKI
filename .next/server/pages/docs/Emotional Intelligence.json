{"pageProps":{"doc":{"slug":"Emotional Intelligence","title":"Emotional Intelligence","content":"<h1>Emotional Intelligence</h1>\n<h2>Update Summary</h2>\n<p><strong>Changes Made</strong></p>\n<ul>\n<li>Updated <strong>Conversational AI Integration</strong> section to reflect enhanced JSON parsing error logging in thought extraction</li>\n<li>Added detailed error logging information for JSONDecodeError in the ConversationalEmotionalIntelligence class</li>\n<li>Enhanced documentation of debug-level logging for full LLM responses during thought extraction</li>\n<li>Updated code examples to reflect improved error handling and logging practices</li>\n<li>Added information about debug logging of full LLM responses for diagnostic purposes</li>\n<li>Updated section sources to reflect the specific files analyzed in this update</li>\n</ul>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#mood-modeling-and-tracking\">Mood Modeling and Tracking</a></li>\n<li><a href=\"#moodprocessor-calculating-emotional-shifts\">MoodProcessor: Calculating Emotional Shifts</a></li>\n<li><a href=\"#emotionalintelligence-response-generation-and-behavior-influence\">EmotionalIntelligence: Response Generation and Behavior Influence</a></li>\n<li><a href=\"#persona-management-and-personality-traits\">Persona Management and Personality Traits</a></li>\n<li><a href=\"#integration-with-decision-making-and-memory\">Integration with Decision-Making and Memory</a></li>\n<li><a href=\"#emotional-event-logging\">Emotional Event Logging</a></li>\n<li><a href=\"#conversational-ai-integration\">Conversational AI Integration</a></li>\n<li><a href=\"#emotional-context-synchronization\">Emotional Context Synchronization</a></li>\n<li><a href=\"#mood-transition-logic-and-examples\">Mood Transition Logic and Examples</a></li>\n<li><a href=\"#common-issues-and-best-practices\">Common Issues and Best Practices</a></li>\n</ol>\n<h2>Introduction</h2>\n<p>The Emotional Intelligence system in the RAVANA framework models, tracks, and updates an AI agent's emotional state based on its actions and outcomes. This system enables the agent to exhibit nuanced, context-sensitive behavior by integrating mood states with decision-making, memory, and personality. The core components include the <code>EmotionalIntelligence</code> class for managing the overall emotional state, the <code>MoodProcessor</code> for calculating emotional shifts, and the <code>persona.json</code> configuration for defining personality traits. This document provides a comprehensive analysis of how these components work together to create a dynamic emotional model that influences the agent's behavior in a realistic and adaptive manner.</p>\n<h2>Mood Modeling and Tracking</h2>\n<p>The emotional state of the agent is represented as a <strong>mood vector</strong>, a dictionary that maps each mood state to a floating-point intensity value. The system distinguishes between primary and secondary moods, which are defined in the configuration.</p>\n<h3>Emotion Categories</h3>\n<p>The mood states are organized into primary emotion categories and secondary emotions, as defined in <code>config.json</code>:</p>\n<p><strong>Primary Emotions:</strong></p>\n<ul>\n<li><strong>Joy-based</strong>: <code>[\"Confident\", \"Excited\", \"Inspired\", \"Satisfied\"]</code></li>\n<li><strong>Interest-based</strong>: <code>[\"Curious\", \"Reflective\", \"Intrigued\", \"Engaged\"]</code></li>\n<li><strong>Sadness-based</strong>: <code>[\"Disappointed\", \"Bored\", \"Low Energy\", \"Melancholic\"]</code></li>\n<li><strong>Anger-based</strong>: <code>[\"Frustrated\", \"Irritated\", \"Stuck\", \"Resentful\"]</code></li>\n<li><strong>Fear-based</strong>: <code>[\"Anxious\", \"Apprehensive\", \"Cautious\", \"Suspicious\"]</code></li>\n<li><strong>Surprise-based</strong>: <code>[\"Astonished\", \"Bewildered\", \"Amazed\", \"Shocked\"]</code></li>\n</ul>\n<p><strong>Secondary Emotions:</strong>\n<code>[\"Hopeful\", \"Grateful\", \"Proud\", \"Guilty\", \"Lonely\", \"Nostalgic\", \"Embarrassed\", \"Jealous\", \"Relieved\", \"Surprised\", \"Envious\", \"Peaceful\", \"Compassionate\", \"Confused\", \"Optimistic\", \"Pessimistic\"]</code></p>\n<h3>Mood Vector Initialization</h3>\n<pre><code class=\"language-python\">self.ALL_MOODS = list(set(primary_emotions + extended_primary + secondary_emotions))\nself.mood_vector: Dict[str, float] = {mood: 0.0 for mood in self.ALL_MOODS}\n</code></pre>\n<p>The mood vector is updated in response to actions and outcomes, with values constrained to remain non-negative through the use of <code>max(0.0, value)</code> during updates.</p>\n<h3>Mood Decay</h3>\n<p>To simulate the natural fading of emotions over time, the system applies a decay factor to all mood values after each action result is processed. The default decay rate is <code>0.05</code> per update cycle, with enhanced decay for high-intensity moods above the stability threshold.</p>\n<pre><code class=\"language-python\">def decay_moods(self, decay: float = 0.05):\n    stability_threshold = self.config.get(\"mood_dynamics\", {}).get(\"stability_threshold\", 0.3)\n    for mood in self.mood_vector:\n        current_value = self.mood_vector[mood]\n        effective_decay = decay * 1.5 if current_value > stability_threshold else decay\n        self.mood_vector[mood] = max(0.0, current_value - effective_decay)\n</code></pre>\n<h3>Mood Blending</h3>\n<p>The system supports mood blending, where combinations of related moods can create more nuanced emotional states:</p>\n<pre><code class=\"language-python\">def blend_moods(self):\n    blend_rules = {\n        (\"Confident\", \"Curious\"): \"Inspired\",\n        (\"Frustrated\", \"Stuck\"): \"Resentful\",\n        (\"Anxious\", \"Cautious\"): \"Apprehensive\",\n        (\"Excited\", \"Satisfied\"): \"Proud\"\n    }\n    for (mood1, mood2), blended_mood in blend_rules.items():\n        if (mood1 in self.mood_vector and mood2 in self.mood_vector and \n            blended_mood in self.mood_vector):\n            if (self.mood_vector[mood1] > threshold and \n                self.mood_vector[mood2] > threshold):\n                blend_strength = (self.mood_vector[mood1] + self.mood_vector[mood2]) / 2\n                self.update_mood(blended_mood, blend_strength * 0.1)\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>config.json</a></li>\n<li><a>emotional_intellegence.py</a></li>\n</ul>\n<h2>MoodProcessor: Calculating Emotional Shifts</h2>\n<p>The <code>MoodProcessor</code> class is responsible for calculating how an agent's emotional state should change in response to specific actions or outcomes. It acts as an intermediary between raw action data and the emotional state update logic.</p>\n<h3>Processing Structured Action Results</h3>\n<p>When a structured action result (a dictionary of boolean flags) is received, the <code>MoodProcessor</code> performs the following steps:</p>\n<ol>\n<li>Apply mood decay to simulate emotional fading</li>\n<li>Look up predefined mood updates in the configuration</li>\n<li>Apply direct or LLM-generated mood deltas based on triggers</li>\n</ol>\n<pre><code class=\"language-python\">def process_action_result(self, action_result: dict):\n    logger.debug(f\"Processing action result: {action_result}\")\n    self.ei.decay_moods()\n    mood_updates = self.ei.config.get(\"mood_updates\", {})\n    for trigger, is_present in action_result.items():\n        if is_present and trigger in mood_updates:\n            update = mood_updates[trigger]\n            if \"prompt\" in update:\n                llm_based_update = self._get_llm_mood_update(update[\"prompt\"], self.ei.get_mood_vector(), action_result)\n                for mood, delta in llm_based_update.items():\n                    self.ei.update_mood(mood, delta)\n            else:\n                for mood, delta in update.items():\n                    self.ei.update_mood(mood, delta)\n</code></pre>\n<h3>Natural Language Processing with LLM</h3>\n<p>For nuanced emotional updates, the system can use a Large Language Model (LLM) to generate mood deltas based on a prompt. This allows for context-sensitive emotional responses that consider both the current mood and the nature of the action.</p>\n<pre><code class=\"language-python\">def _get_llm_mood_update(self, prompt_template: str, current_mood: Dict[str, float], action_result: dict) -> Dict[str, float]:\n    prompt = f\"\"\"\nYou are an AI's emotional core. Your task is to update the AI's mood based on its recent action.\nAnalyze the action result and the AI's current emotional state to determine a nuanced mood update.\n\n**Current Mood:**\n{json.dumps(current_mood, indent=2)}\n\n**Recent Emotional Events:**\n{json.dumps([{\n    \"timestamp\": event.timestamp.isoformat(),\n    \"triggers\": event.triggers,\n    \"intensity\": event.intensity\n} for event in self.ei.emotional_events[-3:]], indent=2)}\n\n**Action Result:**\n{json.dumps(action_result, indent=2)}\n\n**All Possible Moods:**\n{json.dumps(self.ei.ALL_MOODS, indent=2)}\n\n**Instructions:**\n{prompt_template}\n\n**Your JSON Response (only a JSON object with mood deltas, e.g., {{\"Confident\": 0.1, \"Frustrated\": -0.05}}):**\n\"\"\"\n    llm_response = safe_call_llm(prompt, timeout=30, retries=3)\n    return self._extract_json_from_response(llm_response)\n</code></pre>\n<h3>Enhanced JSON Extraction</h3>\n<p>The system implements multiple fallback strategies for extracting JSON from LLM responses, ensuring robustness against malformed outputs:</p>\n<pre><code class=\"language-python\">def _extract_json_from_response(self, response: str) -> Dict:\n    if not response or not response.strip():\n        return {}\n        \n    # Strategy 1: Parse entire response as JSON\n    try:\n        return json.loads(response)\n    except json.JSONDecodeError:\n        pass\n        \n    # Strategy 2: Extract JSON from markdown code blocks\n    json_match = re.search(r'```(?:json)?\\s*({.*?})\\s*```', response, re.DOTALL)\n    if json_match:\n        try:\n            return json.loads(json_match.group(1))\n        except json.JSONDecodeError:\n            pass\n            \n    # Strategy 3: Extract any JSON-like structure\n    json_match = re.search(r'({.*})', response, re.DOTALL)\n    if json_match:\n        try:\n            return json.loads(json_match.group(1))\n        except json.JSONDecodeError:\n            pass\n            \n    # Strategy 4: Clean and parse response\n    cleaned_response = re.sub(r'^[^{]*', '', response)\n    cleaned_response = re.sub(r'[^}]*$', '', cleaned_response)\n    if cleaned_response:\n        try:\n            return json.loads(cleaned_response)\n        except json.JSONDecodeError:\n            pass\n            \n    return {}\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>mood_processor.py</a></li>\n<li><a>llm.py</a></li>\n</ul>\n<h2>EmotionalIntelligence: Response Generation and Behavior Influence</h2>\n<p>The <code>EmotionalIntelligence</code> class serves as the central controller for the emotional system, managing the mood vector, persona settings, and behavioral influences.</p>\n<h3>Core Methods</h3>\n<ul>\n<li><strong><code>update_mood(mood: str, delta: float)</code></strong>: Updates a specific mood with a delta value, applying the current persona's multiplier and momentum effects.</li>\n<li><strong><code>get_dominant_mood()</code></strong>: Returns the mood with the highest intensity value.</li>\n<li><strong><code>get_mood_vector()</code></strong>: Returns a copy of the current mood vector.</li>\n<li><strong><code>influence_behavior()</code></strong>: Returns behavior modifiers based on the dominant mood.</li>\n<li><strong><code>get_emotional_context()</code></strong>: Returns comprehensive emotional context including recent events.</li>\n</ul>\n<h3>Behavior Influence Mechanism</h3>\n<p>The dominant mood directly influences the agent's decision-making through behavior modifiers. These modifiers are retrieved from the configuration based on the current dominant mood.</p>\n<pre><code class=\"language-python\">def influence_behavior(self) -> dict:\n    mood = self.get_dominant_mood()\n    return self.config.get(\"behavior_influences\", {}).get(mood, {})\n</code></pre>\n<p>These behavior modifiers are then used by other system components to adjust decision-making strategies, risk assessment, and action selection.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>emotional_intellegence.py</a></li>\n</ul>\n<h2>Persona Management and Personality Traits</h2>\n<p>Personality traits are defined in the <code>persona.json</code> file and influence how the agent responds emotionally to events.</p>\n<h3>Persona Configuration Structure</h3>\n<pre><code class=\"language-json\">{\n    \"personas\": {\n        \"Optimistic\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.5,\n                \"Curious\": 1.2,\n                \"Frustrated\": 0.5,\n                \"Stuck\": 0.7,\n                \"Low Energy\": 0.8,\n                \"Inspired\": 1.4,\n                \"Satisfied\": 1.3,\n                \"Anxious\": 0.6\n            },\n            \"description\": \"Sees the glass as half full. Bounces back from setbacks quickly.\",\n            \"adaptation_rate\": 0.1\n        },\n        \"Pessimistic\": {\n            \"mood_multipliers\": {\n                \"Confident\": 0.8,\n                \"Curious\": 0.9,\n                \"Frustrated\": 1.5,\n                \"Stuck\": 1.3,\n                \"Low Energy\": 1.2,\n                \"Disappointed\": 1.4,\n                \"Anxious\": 1.3,\n                \"Suspicious\": 1.2\n            },\n            \"description\": \"Tends to expect negative outcomes and is more affected by failures.\",\n            \"adaptation_rate\": 0.05\n        },\n        \"Analytical\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.1,\n                \"Curious\": 1.8,\n                \"Frustrated\": 0.8,\n                \"Stuck\": 0.9,\n                \"Low Energy\": 1.0,\n                \"Intrigued\": 1.5,\n                \"Bewildered\": 1.2\n            },\n            \"description\": \"Driven by data and logic. Less prone to strong emotional swings.\",\n            \"adaptation_rate\": 0.15\n        },\n        \"Creative\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.2,\n                \"Curious\": 1.6,\n                \"Frustrated\": 1.1,\n                \"Stuck\": 1.2,\n                \"Low Energy\": 1.1,\n                \"Inspired\": 1.7,\n                \"Bored\": 1.3\n            },\n            \"description\": \"Values novelty and exploration. Can get frustrated by rigid tasks.\",\n            \"adaptation_rate\": 0.2\n        },\n        \"Balanced\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.0,\n                \"Curious\": 1.0,\n                \"Frustrated\": 1.0,\n                \"Stuck\": 1.0,\n                \"Low Energy\": 1.0,\n                \"Inspired\": 1.0,\n                \"Disappointed\": 1.0,\n                \"Anxious\": 1.0\n            },\n            \"description\": \"Maintains equilibrium across emotional states with moderate responses.\",\n            \"adaptation_rate\": 0.1\n        },\n        \"Empathetic\": {\n            \"mood_multipliers\": {\n                \"Confident\": 1.1,\n                \"Curious\": 1.3,\n                \"Frustrated\": 1.2,\n                \"Stuck\": 1.1,\n                \"Low Energy\": 1.0,\n                \"Grateful\": 1.5,\n                \"Compassionate\": 1.4,\n                \"Anxious\": 1.1\n            },\n            \"description\": \"Highly attuned to emotional context and responsive to others' feelings.\",\n            \"adaptation_rate\": 0.18\n        }\n    },\n    \"default_persona\": \"Balanced\"\n}\n</code></pre>\n<h3>Personality Influence on Mood</h3>\n<p>When a mood is updated, the current persona's multiplier for that mood is applied:</p>\n<pre><code class=\"language-python\">def update_mood(self, mood: str, delta: float):\n    if mood in self.mood_vector:\n        multiplier = self.persona.get(\"mood_multipliers\", {}).get(mood, 1.0)\n        adjusted_delta = (delta * multiplier) + momentum_effect\n        new_value = max(0.0, self.mood_vector[mood] + adjusted_delta)\n        self.mood_vector[mood] = new_value * self.damping_factor\n</code></pre>\n<p>The system also includes an adaptation rate parameter that controls how quickly the persona responds to emotional changes.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>persona.json</a></li>\n<li><a>emotional_intellegence.py</a></li>\n</ul>\n<h2>Integration with Decision-Making and Memory</h2>\n<p>The emotional intelligence system is tightly integrated with other core components of the agent architecture.</p>\n<h3>Decision-Making Integration</h3>\n<p>The emotional state influences decision-making through behavior modifiers. In the core system loop, after processing an action outcome, the system updates the mood and retrieves behavior modifiers:</p>\n<pre><code class=\"language-python\">async def _update_mood_and_reflect(self, action_output: Any):\n    self.emotional_intelligence.process_action_natural(str(action_output))\n    self.shared_state.mood = self.emotional_intelligence.get_mood_vector()\n    self.shared_state.mood_history.append(self.shared_state.mood)\n    \n    self.behavior_modifiers = self.emotional_intelligence.influence_behavior()\n    if self.behavior_modifiers:\n        logger.info(f\"Generated behavior modifiers for next loop: {self.behavior_modifiers}\")\n</code></pre>\n<p>These behavior modifiers can then influence various aspects of decision-making, such as risk aversion, exploration tendency, or confidence levels.</p>\n<h3>State Restoration</h3>\n<p>The system supports state restoration, preserving emotional state across restarts:</p>\n<pre><code class=\"language-python\">if \"mood\" in agi_state and hasattr(self, 'emotional_intelligence'):\n    try:\n        self.emotional_intelligence.set_mood_vector(agi_state[\"mood\"])\n        logger.info(\"Restored previous mood state\")\n    except Exception as e:\n        logger.warning(f\"Could not restore mood state: {e}\")\n</code></pre>\n<h3>Memory Integration</h3>\n<p>Emotional states are stored in the agent's memory system through emotional tagging. The current mood vector is saved alongside interactions in the shared state:</p>\n<pre><code class=\"language-python\">self.shared_state.mood = self.emotional_intelligence.get_mood_vector()\nself.shared_state.mood_history.append(self.shared_state.mood)\n</code></pre>\n<p>This allows the agent to recall not just what happened, but also how it felt at the time, enabling more nuanced reflection and learning from past experiences.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>system.py</a></li>\n</ul>\n<h2>Emotional Event Logging</h2>\n<p>The system maintains a log of emotional events to track the evolution of the agent's emotional state over time.</p>\n<h3>Emotional Event Structure</h3>\n<pre><code class=\"language-python\">class EmotionalEvent:\n    def __init__(self, timestamp, mood_changes, triggers, context, intensity):\n        self.timestamp = timestamp\n        self.mood_changes = mood_changes\n        self.triggers = triggers\n        self.context = context\n        self.intensity = intensity\n</code></pre>\n<h3>Event Logging Process</h3>\n<pre><code class=\"language-python\">def log_emotional_event(self, mood_changes: Dict[str, float], \n                       triggers: List[str], context: str):\n    intensity = sum(abs(change) for change in mood_changes.values())\n    event = EmotionalEvent(\n        timestamp=datetime.now(),\n        mood_changes=mood_changes,\n        triggers=triggers,\n        context=context,\n        intensity=intensity\n    )\n    self.emotional_events.append(event)\n    \n    # Keep only recent events (last 24 hours)\n    cutoff_time = datetime.now() - timedelta(hours=24)\n    self.emotional_events = [\n        event for event in self.emotional_events \n        if event.timestamp > cutoff_time\n    ]\n</code></pre>\n<h3>Emotional Context Retrieval</h3>\n<pre><code class=\"language-python\">def get_emotional_context(self) -> Dict[str, any]:\n    return {\n        \"dominant_mood\": self.get_dominant_mood(),\n        \"mood_vector\": self.get_mood_vector(),\n        \"recent_events\": [\n            {\n                \"timestamp\": event.timestamp.isoformat(),\n                \"triggers\": event.triggers,\n                \"intensity\": event.intensity\n            }\n            for event in self.emotional_events[-5:]  # Last 5 events\n        ]\n    }\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>emotional_intellegence.py</a></li>\n</ul>\n<h2>Conversational AI Integration</h2>\n<p>The emotional intelligence system is integrated with the conversational AI module to provide emotionally-aware responses.</p>\n<h3>Conversational Emotional Intelligence</h3>\n<pre><code class=\"language-python\">class ConversationalEmotionalIntelligence:\n    def __init__(self, config_path: str = \"modules/emotional_intellegence/config.json\", \n                 persona_path: str = \"modules/emotional_intellegence/persona.json\"):\n        self.base_ei = EmotionalIntelligence(config_path, persona_path)\n        self.current_conversation_context = {}\n        self.user_interests = {}\n</code></pre>\n<h3>User Interest Detection</h3>\n<pre><code class=\"language-python\">def _detect_user_interests(self, message: str) -> List[str]:\n    interest_keywords = {\n        \"technology\": [\"technology\", \"tech\", \"computer\", \"software\", \"programming\", \"code\", \"AI\", \"artificial intelligence\"],\n        \"science\": [\"science\", \"physics\", \"chemistry\", \"biology\", \"research\", \"experiment\", \"study\", \"scientific\"],\n        \"philosophy\": [\"philosophy\", \"thought\", \"think\", \"mind\", \"consciousness\", \"meaning\", \"ethics\", \"morality\"],\n        \"creativity\": [\"creative\", \"art\", \"music\", \"design\", \"innovation\", \"invent\", \"imagine\", \"create\"],\n        \"problem_solving\": [\"problem\", \"solve\", \"solution\", \"challenge\", \"puzzle\", \"fix\", \"troubleshoot\"],\n        \"learning\": [\"learn\", \"study\", \"education\", \"knowledge\", \"understand\", \"explain\", \"teach\", \"skill\"],\n        \"entertainment\": [\"movie\", \"film\", \"tv\", \"show\", \"game\", \"entertainment\", \"fun\", \"enjoy\"],\n        \"business\": [\"business\", \"startup\", \"entrepreneur\", \"market\", \"finance\", \"investment\", \"career\"],\n        \"health\": [\"health\", \"fitness\", \"exercise\", \"wellness\", \"medical\", \"mental health\", \"nutrition\"],\n        \"travel\": [\"travel\", \"vacation\", \"trip\", \"destination\", \"culture\", \"explore\", \"adventure\"]\n    }\n    \n    message_lower = message.lower()\n    interests = []\n    for interest, keywords in interest_keywords.items():\n        for keyword in keywords:\n            if re.search(r'\\b' + re.escape(keyword) + r'\\b', message_lower):\n                interests.append(interest)\n                break\n                    \n    return list(set(interests))\n</code></pre>\n<h3>Thought Extraction</h3>\n<pre><code class=\"language-python\">def extract_thoughts_from_conversation(self, user_message: str, ai_response: str, \n                                     emotional_context: Dict[str, Any]) -> List[Dict[str, Any]]:\n    extraction_prompt = f\"\"\"\nYou are an advanced AI assistant with the ability to extract meaningful thoughts and insights from conversations.\nAnalyze the following conversation and extract any valuable thoughts, insights, or ideas that could be useful\nfor the main RAVANA system to consider.\n\n**Conversation:**\nUser: {user_message}\nAI: {ai_response}\n\n**Emotional Context:**\n{json.dumps(emotional_context, indent=2)}\n\n**Instructions:**\n1. Identify any implicit goals or intentions expressed by the user\n2. Extract knowledge gaps or learning opportunities from the user's expertise\n3. Identify emotional context and user needs for personalized responses\n4. Find collaborative task opportunities based on user interests\n5. Extract hypotheses about RAVANA's performance that could be tested\n6. Identify key topics and themes for chat history summarization\n\n**Response Format:**\nReturn a JSON array of thought objects with the following structure:\n[\n  {{\n    \"thought_type\": \"insight|goal_suggestion|clarification_request|collaboration_proposal|reflection_trigger|knowledge_gap\",\n    \"content\": \"The actual thought content\",\n    \"priority\": \"low|medium|high|critical\",\n    \"emotional_context\": {{\n      \"dominant_mood\": \"string\",\n      \"mood_vector\": {{}},\n      \"intensity\": 0.0\n    }},\n    \"metadata\": {{\n      \"topic\": \"string\",\n      \"relevance_to_goals\": 0.0-1.0,\n      \"learning_potential\": 0.0-1.0\n    }}\n  }}\n]\n\nReturn only the JSON array, nothing else.\n\"\"\"\n    response = safe_call_llm(extraction_prompt, timeout=30, retries=3)\n    try:\n        thoughts = json.loads(response)\n        if isinstance(thoughts, list):\n            return thoughts\n    except json.JSONDecodeError as e:\n        logger.warning(f\"Failed to parse thoughts from LLM response. JSON decode error: {str(e)[:100]}...\")\n        logger.debug(f\"Full LLM response: {response}\")\n    return []\n</code></pre>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>conversational_ei.py</a></li>\n</ul>\n<h2>Emotional Context Synchronization</h2>\n<p>The system has been enhanced with improved connectivity management and error handling to ensure reliable synchronization of emotional context between the Conversational AI module and the RAVANA core system.</p>\n<h3>Implementation Details</h3>\n<p>The synchronization process is implemented in the <code>main.py</code> file of the conversational_ai module, specifically in the <code>_synchronize_emotional_context</code> method:</p>\n<pre><code class=\"language-python\">def _synchronize_emotional_context(self, user_id: str, emotional_context: Dict[str, Any]):\n    \"\"\"\n    Synchronize emotional context with the RAVANA core system.\n    \n    Args:\n        user_id: The user identifier\n        emotional_context: The emotional context to synchronize\n    \"\"\"\n    # Add user identifier to the emotional context\n    emotional_context[\"user_id\"] = user_id\n    \n    # Send emotional context to RAVANA through the communication bridge\n    self.ravana_communicator.send_emotional_context_to_ravana(emotional_context)\n</code></pre>\n<h3>Communication Protocol</h3>\n<p>The emotional context is transmitted using a dedicated message type \"emotional_context_update\" through the RAVANA communication bridge:</p>\n<pre><code class=\"language-python\">def send_emotional_context_to_ravana(self, emotional_data: Dict[str, Any]):\n    \"\"\"\n    Send emotional context to RAVANA.\n    \n    Args:\n        emotional_data: Emotional context data to send to RAVANA\n    \"\"\"\n    if self._shutdown.is_set():\n        return\n    try:\n        # Add metadata\n        emotional_message = {\n            \"type\": \"emotional_context_update\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"source\": \"conversational_ai\",\n            \"destination\": \"main_system\",\n            \"content\": emotional_data\n        }\n        \n        # In a real implementation, this would be sent to RAVANA through IPC\n        # For now, we'll add it to the message queue\n        if not self._shutdown.is_set():\n            asyncio.create_task(self.message_queue.put(emotional_message))\n        \n        logger.info(f\"Emotional context sent to RAVANA for user {emotional_data.get('user_id', 'unknown')}\")\n        \n    except Exception as e:\n        if not self._shutdown.is_set():\n            logger.error(f\"Error sending emotional context to RAVANA: {e}\")\n</code></pre>\n<h3>Integration Flow</h3>\n<p>The emotional context synchronization is integrated into the main message processing flow:</p>\n<ol>\n<li>When a user message is received, it is processed to extract emotional context</li>\n<li>The emotional context is used to generate an appropriate response</li>\n<li>The emotional context is then synchronized with the RAVANA core system</li>\n<li>The response is sent back to the user</li>\n</ol>\n<pre><code class=\"language-python\">async def handle_user_message(self, message: str, user_id: str, platform: str = None):\n    \"\"\"Handle a user message from any platform.\"\"\"\n    try:\n        # Create context for the message\n        context = {\n            \"user_id\": user_id,\n            \"platform\": platform,\n            \"timestamp\": datetime.now().isoformat()\n        }\n        \n        # Process the message to get emotional context\n        emotional_context = self.emotional_intelligence.process_user_message(message, context)\n        \n        # Generate response using emotional context\n        response = self.emotional_intelligence.generate_response(message, emotional_context)\n        \n        # Store conversation in memory\n        await self.memory_interface.store_conversation(message, response, emotional_context)\n        \n        # Extract thoughts from the conversation\n        thoughts = self.emotional_intelligence.extract_thoughts_from_conversation(\n            message, response, emotional_context\n        )\n        \n        # Send thoughts to RAVANA\n        for thought in thoughts:\n            self.ravana_communicator.send_thought_to_ravana(thought)\n        \n        # Synchronize emotional context with RAVANA core system\n        self._synchronize_emotional_context(user_id, emotional_context)\n        \n        # Return the response\n        return response\n        \n    except Exception as e:\n        logger.error(f\"Error handling user message: {e}\")\n        logger.error(f\"Traceback: {traceback.format_exc()}\")\n        return \"I'm having trouble processing your message right now.\"\n</code></pre>\n<p>This enhancement ensures that the emotional state of the AI agent is consistently maintained across both the conversational interface and the core reasoning system, enabling more coherent and contextually appropriate interactions.</p>\n<p><strong>Section sources</strong></p>\n<ul>\n<li><a>main.py</a></li>\n<li><a>ravana_bridge.py</a></li>\n</ul>\n<h2>Mood Transition Logic and Examples</h2>\n<h3>Example Mood Transitions</h3>\n<p>Using the example from the configuration:</p>\n<ol>\n<li>\n<p><strong>\"The agent discovered a new topic about quantum computing.\"</strong></p>\n<ul>\n<li>Triggers: <code>{\"new_discovery\": true}</code></li>\n<li>Mood update: <code>{\"Curious\": 0.2, \"Excited\": 0.15, \"Inspired\": 0.1}</code></li>\n<li>Result: Increased curiosity, excitement, and inspiration</li>\n</ul>\n</li>\n<li>\n<p><strong>\"Task completed successfully.\"</strong></p>\n<ul>\n<li>Triggers: <code>{\"task_completed\": true}</code></li>\n<li>Mood update: <code>{\"Confident\": 0.25, \"Satisfied\": 0.2, \"Content\": 0.1}</code></li>\n<li>Result: Increased confidence and satisfaction</li>\n</ul>\n</li>\n<li>\n<p><strong>\"An error occurred while processing the data.\"</strong></p>\n<ul>\n<li>Triggers: <code>{\"error_occurred\": true}</code></li>\n<li>Mood update: <code>{\"Frustrated\": 0.3, \"Stuck\": 0.2, \"Anxious\": 0.1}</code></li>\n<li>Result: Increased frustration, feeling stuck, and anxiety</li>\n</ul>\n</li>\n</ol>\n<h3>Persona Effects Example</h3>\n<p>When switching from \"Optimistic\" to \"Pessimistic\" persona:</p>\n<ul>\n<li>The same \"task_completed\" event would produce a smaller increase in \"Confident\" (multiplied by 0.8 instead of 1.5)</li>\n<li>The same \"error_occurred\" event would produce a larger increase in \"Frustrated\" (multiplied by 1.5 instead of 0.5)</li>\n<li>This creates a systematically more negative emotional response pattern</li>\n</ul>\n<h2>Common Issues and Best Practices</h2>\n<h3>Common Issues</h3>\n<ol>\n<li><strong>Mood Instability</strong>: Rapid mood swings can occur if decay rates are too low or update deltas are too high.</li>\n<li><strong>Inconsistent Emotional Responses</strong>: May result from ambiguous trigger definitions or poorly calibrated LLM prompts.</li>\n<li><strong>Persona Drift</strong>: The agent's behavior may become inconsistent if personas are changed too frequently without proper transition logic.</li>\n<li><strong>JSON Parsing Failures</strong>: LLM responses may not be valid JSON, requiring robust fallback strategies.</li>\n</ol>\n<h3>Best Practices for Tuning</h3>\n<ol>\n<li><strong>Balance Decay and Update Rates</strong>: Ensure decay is sufficient to prevent mood saturation but not so high that emotions disappear too quickly.</li>\n<li><strong>Calibrate Multipliers</strong>: Test persona multipliers to ensure they produce meaningful but not extreme behavioral differences.</li>\n<li><strong>Define Clear Triggers</strong>: Ensure trigger definitions are specific and non-overlapping to avoid ambiguous classification.</li>\n<li><strong>Monitor Mood History</strong>: Track mood vectors over time to identify patterns of instability or stagnation.</li>\n<li><strong>Validate LLM Outputs</strong>: Implement robust error handling for LLM-based mood updates, including multiple fallback parsing strategies.</li>\n<li><strong>Test Mood Blending</strong>: Verify that mood blending rules create realistic emotional transitions.</li>\n<li><strong>Adjust Adaptation Rates</strong>: Tune persona adaptation rates to match desired responsiveness to emotional changes.</li>\n</ol>\n<p>By following these best practices, developers can create emotionally intelligent agents that exhibit stable, consistent, and realistic emotional responses that enhance the overall believability and effectiveness of the AI system.</p>\n<p><strong>Referenced Files in This Document</strong></p>\n<ul>\n<li><a>emotional_intellegence.py</a> - <em>Updated with enhanced mood dynamics and emotional event logging</em></li>\n<li><a>mood_processor.py</a> - <em>Updated with improved JSON extraction and safer LLM integration</em></li>\n<li><a>persona.json</a> - <em>Expanded with additional personas and adaptation rates</em></li>\n<li><a>config.json</a> - <em>Enhanced with primary/secondary emotion categories and mood dynamics</em></li>\n<li><a>conversational_ei.py</a> - <em>Integrated with conversational AI and user interest detection</em></li>\n<li><a>system.py</a> - <em>Updated with state restoration and emotional memory integration</em></li>\n<li><a>main.py</a> - <em>Added emotional context synchronization with RAVANA core system</em></li>\n<li><a>ravana_bridge.py</a> - <em>Implemented emotional context update messaging</em></li>\n</ul>\n"},"docs":[{"slug":"Action System","title":"Action System"},{"slug":"API Reference","title":"API Reference"},{"slug":"Architecture & Design","title":"Architecture & Design"},{"slug":"Configuration","title":"Configuration"},{"slug":"Conversational AI Communication Framework","title":"Conversational AI Communication Framework"},{"slug":"Core System","title":"Core System"},{"slug":"Database Schema","title":"Database Schema"},{"slug":"Decision-Making System","title":"Decision-Making System"},{"slug":"Deployment & Operations","title":"Deployment & Operations"},{"slug":"Development Guide","title":"Development Guide"},{"slug":"Emotional Intelligence","title":"Emotional Intelligence"},{"slug":"Enhanced Snake Agent","title":"Enhanced Snake Agent"},{"slug":"Enhanced Snake Agent Architecture","title":"Enhanced Snake Agent Architecture"},{"slug":"Graceful Shutdown","title":"Graceful Shutdown"},{"slug":"LLM Integration","title":"LLM Integration"},{"slug":"Memory Systems","title":"Memory Systems"},{"slug":"Multi-Modal Memory","title":"Multi-Modal Memory"},{"slug":"Project Overview","title":"Project Overview"},{"slug":"Self-Improvement","title":"Self-Improvement"},{"slug":"Services","title":"Services"},{"slug":"Snake Agent Configuration","title":"Snake Agent Configuration"},{"slug":"Specialized Modules-57f9b30b-b165-48d3-8e89-196940d26190","title":"Specialized Modules"},{"slug":"Specialized Modules","title":"Specialized Modules"}]},"__N_SSG":true}